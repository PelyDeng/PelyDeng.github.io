{"meta":{"title":"牧场小站","subtitle":"","description":"IT 小站， 记录美好码园生活","author":"Peilin Deng","url":"https://pdyun.cc","root":"/"},"pages":[{"title":"关于我","date":"2021-08-06T12:56:57.000Z","updated":"2021-08-07T08:23:50.870Z","comments":false,"path":"about/index.html","permalink":"https://pdyun.cc/about/index.html","excerpt":"","text":"正在播放《每天一遍，可莉完蛋》 ●━───────00:04 ⇆ ᐊ Ⅱ ᐅ ↻ 念两句诗 挑选中... jinrishici.load(function(result) { poem.innerHTML = result.data.content info.innerHTML = '【' + result.data.origin.dynasty + '】' + result.data.origin.author + '《' + result.data.origin.title + '》' document.getElementById(\"poem\").value(poem); document.getElementById(\"info\").value(info); });"},{"title":"所有分类","date":"2021-08-06T12:55:40.000Z","updated":"2021-08-07T05:19:51.774Z","comments":false,"path":"categories/index.html","permalink":"https://pdyun.cc/categories/index.html","excerpt":"","text":""},{"title":"标签页","date":"2021-08-06T12:56:28.000Z","updated":"2021-08-07T05:20:48.804Z","comments":false,"path":"tags/index.html","permalink":"https://pdyun.cc/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Lock 锁及原理分析","slug":"Lock-锁及原理分析","date":"2022-03-04T08:58:00.000Z","updated":"2022-03-05T03:26:58.696Z","comments":true,"path":"2022/03/04/Lock-锁及原理分析/","link":"","permalink":"https://pdyun.cc/2022/03/04/Lock-%E9%94%81%E5%8F%8A%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","excerpt":"","text":"下图所示，在不同的CPU架构中，为了避免因为指令重排序、或者缓存一致性问题，都提供了不同的内存屏障指令。同时，在不同的操作系统中，也都会实现封装一个内存屏障的实现。 那么，我们写的Java线程，如何能够在不同的硬件、不同操作系统下，仍然能够保证线程安全性呢？这就要引出JMM（Java 内存模型），它就是为了屏蔽操作系统和硬件的差异，让一套代码在不同平台下都能达到线程安全的访问目的。 一、什么是JMM那什么是JMM呢？ 首先，我们都知道Java程序是运行在Java虚拟机上的，同时我们也知道， JVM是一个跨语言跨平台的实 现，也就是Write Once、 Run Anywhere。 那么JVM如何实现在不同平台上都能达到线程安全的目的呢？所以这个时候JMM出来了， Java内存模型 （Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范 Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中 保存了这个线程中用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而 不能直接读写主内存。 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行，流程图如下： 再总结一下： JMM定义了共享内存中多线程程序读写操作的行为规范：在虚拟机中把共享变量存储到内存以及从内存中取出共享变量的底层实现细节。 目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题 本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。 实际上，如果大家认真听了前面的内容，不难发现JMM的整个模型实际上和CPU高速缓存和内存交互的模型是一致的，因为不管软件怎么设计，最终还是由硬件来执行。而这个抽象模型的意义就在于，它可以针对不同平台来保证并发场景下的可见性问题。 1234inline void OrderAccess::loadload() &#123; acquire(); &#125;inline void OrderAccess::storestore() &#123; release(); &#125;inline void OrderAccess::loadstore() &#123; acquire(); &#125;inline void OrderAccess::storeload() &#123; fence(); &#125; orderAccess_linux_x86.inline 12345678910inline void OrderAccess::fence() &#123; if (os::is_MP()) &#123; // always use locked addl since mfence is sometimes expensive #ifdef AMD64 __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;); # else __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;); #endif &#125;&#125; orderAccess_linux_sparc.inline 123inline void OrderAccess::fence() &#123; __asm__ volatile (&quot;membar #StoreLoad&quot; : : :);&#125; OrderAccess::storeload(); ACC_VOLATILE bool is_volatile () const { return (_flags &amp; JVM_ACC_VOLATILE ) != 0; } 二、总结可见性导致的原因 CPU的高速缓存 指令重排序 并不是所有的程序指令都会存在可见性或者指令重排序问题。 三、Happens-Before模型前面说了这么多，都是为了讲解清楚，到底是什么原因导致了在多线程环境下的可见性和有序性问题。 并且也了解了volatile解决可见性问题的本质。 那么有没有哪些情况是，不需要通过增加volatile关键字，也能保证在多线程环境下的可见性和有序性的呢？ 从JDK1.5开始，引入了一个happens-before的概念来阐述多个线程操作共享变量的可见性问题。所以我们可以认为在JMM中，如果一个操作执行的结果需要对另一个操作课件，那么这两个操作必须要存在happens-before关系。这两个操作可以是同一个线程，也可以是不同的线程。 程序顺序规则一个线程中的每个操作，happens-before这个线程中的任意后续操作，可以简单认为是as-if-serial。 as-if-serial的意思是，不管怎么重排序，单线程的程序的执行结果不能改变。 处理器不能对存在依赖关系的操作进行重排序，因为重排序会改变程序的执行结果。 对于没有依赖关系的指令，即便是重排序，也不会改变在单线程环境下的执行结果。 具体来看下面这段代码，A和B允许重排序，但是C是不允许重排，因为存在依赖关系。根据as-if-serial语义，在单线程环境下， 不管怎么重排序，最终执行的结果都不会发生变化 123int a=2; //A int b=2; //B int c=a*b; //C 传递性规则仍然看下面这段代码，根据程序顺序规则可以知道，这三者之间存在一个happens-before关系。 123int a=2; //A int b=2; //B int c=a*b; //C A happens-before B。 B happens-before C。 A happens-before C。 这三个happens-before关系，就是根据happens-before的传递性推导出来的。很多同学这个时候又有疑惑了，不是说，A和B之间允许重排序吗？那是不是A happens-before B不一定存在，也可能是B可以重排序在A之前执行呢？ 没错，确实是这样，JMM不要求A一定要在B之前执行，但是他要求的是前一个操作的执行结果对后一个操作可见。这里操作A的执行结果不需要对操作B可见，并且重排序操作A和操作B后的执行结果与A happens-before B顺序执行的结果一直，这种情况下，是允许重排序的。 volatile变量规则对于volatile修饰的变量的写操作，一定happens-before后续对于volatile变量的读操作，这个是因为volatile底层通过内存屏障机制防止了指令重排，这个规则前面已经分析得很透彻了，所以没什么问题，我们再来观察如下代码，基于前面两种规则再结合volatile规则来分析下面这个代码的执行顺序， 假设两个线程A和B，分别访问writer方法和reader方法，那么它将会出现以下可见性规则。 12345678910111213public class VolatileExample &#123; int a=0; volatile Boolean flag=false; public void writer()&#123; a=1; //1 flag=true; //2 &#125; public void reader()&#123; if(flag)&#123; //3 int i=a; //4 &#125; &#125;&#125; 1 happens before 2、 3 happens before 4， 这个是程序顺序规则 2 happens before 3、 是由volatile规则产生的，对一个volatile变量的读，总能看到任意线程对这个volatile变量的写入。 1 happens before 4， 基于传递性规则以及volatile的内存屏障策略共同保证 那么最终结论是，如果在线程B执行reader方法时，如果flag为true，那么意味着 i=1成立。 这里有同学可能会有疑问说，你前面讲的程序顺序规则中，在单线程中，如果两个指令之间不存在依赖关系，是允许重排序的，也就是1 和 2的顺序可以重排，那么是不是意味着最终4输出的结果是0呢? 这里也是因为volatile修饰的重排序规则的存在，导致1和2是不允许重排序的，在volatile重排序规则表中，如果第一操作是普通变量的读/写，第二个操作是volatile的写，那么这两个操作之间不允许重排序 volatile 重排序规则表 监视器锁规则一个线程对于一个锁的释放锁操作，一定happens-before与后续线程对这个锁的加锁操作。 123456789int x=10;synchronized (this) &#123; // 此处自动加锁 // x 是共享变量 , 初始值 =10 if (this.x &lt; 12) &#123; this.x = 12; &#125;&#125;// 此处自动解锁 假设x的初始值是10，线程A执行完代码块后，x的值会变成12，执行完成之后会释放锁。线程B进入代 码块时，能够看到线程A对x的写操作，也就是B线程能够看到x=12。 start规则如果线程A执行操作ThreadB.start(),那么线程A的ThreadB.start()之前的操作happens-before线程B中的任意操作。 12345678910111213public StartDemo&#123; int x=0; Thread t1 = new Thread(()-&gt;&#123; // 主线程调用 t1.start() 之前 // 所有对共享变量的修改，此处皆可见 // 此例中，x==10 &#125; ); // 此处对共享变量 x修改 x = 10; // 主线程启动子线程 t1.start();&#125; join规则join规则，如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于 线程A从ThreadB.join()操作成功的返回。 123456789101112Thread t1 = new Thread(()-&gt;&#123; // 此处对共享变量 x 修改 x= 100;&#125;);// 例如此处对共享变量修改，// 则这个修改结果对线程 t1 可见// 主线程启动子线程t1.start();t1.join()// 子线程所有对共享变量的修改// 在主线程调用 t1.join() 之后皆可见// 此例中，x==100 四、DCL问题//instance=new DCLExample(); 为对象分配内存 初始化对象 把内存空间的地址复制给对象的引用 指令重排序后 为对象分配内存 把内存空间的地址复制给对象的引用 初始化对象(还没有执行的时候。 造成不完整对象 五、J.U.CJava.util.Concurrent 六、Lock -&gt;synchronized锁是用来解决线程安全问题的 七、AbstractQueuedSynchronizer(AQS)什么是AQS 共享锁 互斥锁 AQS 是一种抽象的队列同步器, 它是java除了synchroized之外自带的一种锁机制, 底层使用了大量的CAS进行互斥. AQS原理以ReentrantLock为例, 在我们执行lock()方法进行上锁的时候, 如果有多个线程同时访问上锁的资源, 其底层会对AQS中的共享变量state进行一个CAS操作, 该操作是具有原子性, 如果线程A通过CAS将state状态修改成功就会获取到锁, 并记录一个共享变量设为A线程独享,则线程B尝试获取锁时由于锁状态state已经发生改变不再为0, 则就会把线程B存入一个FIFO的双向链表中, 该链表主要存储的是没有获取到锁的线程, 然后将里面的线程阻塞, 等到线程A释放锁完毕之后, 再唤醒队列中等待的线程. 由于AQS是自旋锁, 在等待唤醒的时候, 会不停的使用while(cas())的方式, 不停的尝试获取锁. AQS中为什么采用双向链表，它和单向链表相比，有什么优势？ASQ中使用双向链表更容易访问相邻的节点. 八、ReentrantLock重入锁 -&gt; 互斥锁 ReentrantLock的实现原理满足线程的互斥特性 意味着同一个时刻，只允许一个线程进入到加锁的代码中。 -&gt; 多线程环境下，线程的顺序访问。 锁的设计猜想（如果我们自己去实现） 一定会设计到锁的抢占 ， 需要有一个标记来实现互斥。 全局变量（0，1） 抢占到了锁，怎么处理（不需要处理.） 没抢占到锁，怎么处理 需要等待（让处于排队中的线程，如果没有抢占到锁，则直接先阻塞-&gt;释放CPU资源）。 如何让线程等待？ wait/notify(线程通信的机制，无法指定唤醒某个线程) LockSupport.park/unpark（阻塞一个指定的线程，唤醒一个指定的线程） Condition 需要排队（允许有N个线程被阻塞，此时线程处于活跃状态）。 通过一个数据结构，把这N个排队的线程存储起来。 抢占到锁的释放过程，如何处理 LockSupport.unpark() -&gt; 唤醒处于队列中的指定线程.\\ 锁抢占的公平性（是否允许插队） 公平 非公平 ReentrantLock的实现原理分析","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://pdyun.cc/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"Peilin Deng"},{"title":"线程安全可见性问题","slug":"线程安全可见性问题","date":"2022-03-04T08:42:00.000Z","updated":"2022-03-04T12:06:05.237Z","comments":true,"path":"2022/03/04/线程安全可见性问题/","link":"","permalink":"https://pdyun.cc/2022/03/04/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%AF%E8%A7%81%E6%80%A7%E9%97%AE%E9%A2%98/","excerpt":"","text":"一、线程安全 - 可见性、有序性这个案例比较简单，就是t1线程中用到了stop这个属性，接在在main线程中修改了 stop 这个属性的值来使得t1线程结束，但是t1线程并没有按照期望的结果执行。 12345678910111213141516public class VolatileDemo &#123; public static Boolean stop=false; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread(()-&gt;&#123; int i=0; while(!stop)&#123; i++; &#125; &#125; ); t1.start(); System.out.println(&quot;begin start thread&quot;); Thread.sleep(1000); stop=true; &#125;&#125; 二、volatile解决可见性问题有volatile变量修饰的共享变量进行写操作的时候会使用CPU提供的Lock前缀指令。在CPU级别的功能如下： 将当前处理器缓存行的数据写回到系统内存 这个写回内存的操作会告知在其他CPU你们拿到的变量是无效的下一次使用时候要重新共享内存拿。 而volatile实现可见性问题的本质就是使用lock指令实现了内存屏障 在上面的程序中，可以增加 volatile这个关键字来解决，代码如下： 12345678910111213141516public class VolatileDemo &#123; public volatile static Boolean stop=false; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread(()-&gt;&#123; int i=0; while(!stop)&#123; i++; &#125; &#125; ); t1.start(); System.out.println(&quot;begin start thread&quot;); Thread.sleep(1000); stop=true; &#125;&#125; 三、为了提升处理性能所做的优化在整个计算机的发展历程中，除了CPU、内存以及I/O设备不断迭代升级来提升计算机处理性能之外， 还有一个非常核心的矛盾点，就是这三者在处理速度的差异。 CPU的计算速度是非常快的，其次是内 存、最后是IO设备（比如磁盘），也就是CPU的计算速度远远高于内存以及磁盘设备的I/O速度。 如下图所示，计算机是利用CPU进行数据运算的，但是CPU只能对内存中的数据进行运算，对于磁盘中 的数据，必须要先读取到内存，CPU才能进行运算，也就是CPU和内存之间无法避免的出现了IO操作。 而cpu的运算速度远远高于内存的IO速度，比如在一台2.4GHz的cpu上，每秒能处理2.4x109次，每次 处理的数据量，如果是64位操作系统，那么意味着每次能处理64位数据量。 虽然CPU从单核升级到多核甚至到超线程技术在最大化的提高CPU的处理性能，但是仅仅提升CPU性能 是不够的，如果内存和磁盘的处理性能没有跟上，就意味着整体的计算效率取决于最慢的设备，为了平 衡这三者之间的速度差异，最大化的利用CPU。 所以在硬件层面、操作系统层面、编译器层面做出了很 多的优化 CPU增加了高速缓存 操作系统增加了进程、线程。通过CPU的时间片切换最大化的提升CPU的使用率 编译器的指令优化，更合理的去利用好CPU的高速缓存 每一种优化，都会带来相应的问题，而这些问题是导致线程安全性问题的根源，那接下来我们逐步去了 解这些优化的本质和带来的问题。 四、CPU层面的缓存CPU在做计算时，和内存的IO操作是无法避免的，而这个IO过程相对于CPU的计算速度来说是非常耗时，基于这样一个问题，所以在CPU层面设计了高速缓存，这个缓存行可以缓存存储在内存中的数据，CPU每次会先从缓存行中读取需要运算的数据，如果缓存行中不存在该数据，才会从内存中加载，通过 这样一个机制可以减少CPU和内存的交互开销从而提升CPU的利用率。 对于主流的x86平台，cpu的缓存行（cache）分为L1、 L2、 L3总共3级。 五、缓存一致性问题CPU高速缓存的出现，虽然提升了CPU的利用率，但是同时也带来了另外一个问题–缓存一致性问题，这个一致性问题体现在。 在多线程环境中，当多个线程并行执行加载同一块内存数据时，由于每个CPU都有自己独立的L1、 L2缓存，所以每个CPU的这部分缓存空间都会缓存到相同的数据，并且每个CPU执行相关指令时，彼此之间不可见，就会导致缓存的一致性问题，据图流程如下图所示： 六、缓存一致性协议为了达到数据访问的一致，需要各个处理器在访问缓存时遵循一些协议，在读写时根据协议来操作，常见的协议有MSI，MESI，MOSI等。最常见的就是MESI协议。接下来给大家简单讲解一下MESI。 MESI表示缓存行的四种状态，分别是 M(Modify[ ˈ mɒdɪfaɪ]) 表示共享数据只缓存在当前CPU缓存中，并且是被修改状态，也就是缓存的 数据和主内存中的数据不一致\\ E(Exclusive[ɪkˈskluːsɪv]) 表示缓存的独占状态，数据只缓存在当前CPU缓存中，并且没有被修改 S(Shared[ʃerd]) 表示数据可能被多个CPU缓存，并且各个缓存中的数据和主内存数据一致 I(Invalid[ ˈɪnvəlɪd]) 表示缓存已经失效 在CPU的缓存行中，每一个Cache一定会处于以下三种状态之一 Shared Exclusive Invalid 七、指令重排序代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class SeqExample &#123; private volatile static int x=0,y=0; private volatile static int a=0,b=0; public static void main(String[] args) throws InterruptedException &#123; int i=0; for (;;)&#123; i++; x=0; y=0; a=0; b=0; Thread t1=new Thread(()-&gt;&#123; a=1; x=b; // x=b; a=1; &#125; ); Thread t2=new Thread(()-&gt;&#123; b=1; y=a; // y=a; b=1; &#125; ); /** * 可能的结果： * 1和1 * 0和1 * 1和0 * ---- * 0和0 */ t1.start(); t2.start(); t1.join(); t2.join(); String result=&quot;第&quot;+i+&quot;次(&quot;+x+&quot;,&quot;+y+&quot;)&quot;; if(x==0&amp;&amp;y==0)&#123; System.out.println(result); break; &#125; else&#123; &#125; &#125; &#125;&#125; 八、伪共享代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class CacheLineExample implements Runnable&#123; public final static long ITERATIONS = 500L * 1000L * 100L; private int arrayIndex = 0; private static ValueNoPadding[] longs; public CacheLineExample(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; for (int i = 1; i &lt; 10; i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTest(i); System.out.println(i + &quot; Threads, duration = &quot; + (System.currentTimeMillis() - start)); &#125; &#125; private static void runTest(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longs = new ValueNoPadding[NUM_THREADS]; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new ValueNoPadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new CacheLineExample(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; @Override public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = 0L; &#125; &#125; public final static class ValuePadding &#123; protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14; protected long p15; &#125; @Contended //实现对齐填充 public final static class ValueNoPadding &#123; // protected long p1, p2, p3, p4, p5, p6, p7; //8字节 protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15; &#125;&#125; 九、内存屏障CPU在性能优化道路上导致的顺序一致性问题，在CPU层面无法被解决，原因是CPU只是一个运算工具，它只接收指令并且执行指令，并不清楚当前执行的整个逻辑中是否存在不能优化的问题，也就是说硬件层面也无法优化这种顺序一致性带来的可见性问题。 因此，在CPU层面提供了写屏障、读屏障、全屏障这样的指令，在x86架构中，这三种指令分别是SFENCE、LFENCE、MFENCE指令， sfence：也就是save fence，写屏障指令。在sfence指令前的写操作必须在sfence指令后的写操作前完成。 lfence：也就是load fence，读屏障指令。在lfence指令前的读操作必须在lfence指令后的读操作前完成。 mfence：也就是modify/mix，混合屏障指令，在mfence前得读写操作必须在mfence指令后的读写操作前完成。 在Linux系统中，将这三种指令分别封装成了, smp_wmb-写屏障 、smp_rmb-读屏障、smp_mb-读写屏障 三个方法","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://pdyun.cc/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"Peilin Deng"},{"title":"Synchronized 同步锁","slug":"Synchronized-同步锁","date":"2022-03-03T15:38:00.000Z","updated":"2022-03-03T16:16:51.391Z","comments":true,"path":"2022/03/03/Synchronized-同步锁/","link":"","permalink":"https://pdyun.cc/2022/03/03/Synchronized-%E5%90%8C%E6%AD%A5%E9%94%81/","excerpt":"","text":"一、并发编程带来的安全性挑战之同步锁如果多个线程在做同一件事情的时候。 原子性 Synchronized ， AtomicXXX、 Lock、 可见性 Synchronized ， volatile 有序性 Synchronized ， volatile 原子性问题在下面的案例中，演示了两个线程分别去去调用 demo.incr方法来对 i 这个变量进行叠加，预期结果 应该是20000，但是实际结果却是小于等于20000的值。 1234567891011121314151617181920212223242526272829public class Demo &#123; int i = 0; public void incr()&#123; i++; &#125; public static void main(String[] args) &#123; Demo demo = new Demo(); Thread[] threads=new Thread[2]; for (int j = 0;j&lt;2;j++) &#123; threads[j]=new Thread(() -&gt; &#123; // 创建两个线程 for (int k=0;k&lt;10000;k++) &#123; // 每个线程跑10000次 demo.incr(); &#125; &#125; ); threads[j].start(); &#125; try &#123; threads[0].join(); threads[1].join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(demo.i); &#125;&#125; 问题的原因这个就是典型的线程安全问题中原子性问题的体现。那什么是原子性呢？在上面这段代码中，count++是属于Java高级语言中的编程指令，而这些指令最终可能会有多条CPU指 令来组成，而count++最终会生成3条指令，通过 javap -v xxx.class 查看字节码指令如下。 1234567891011public incr()VL0LINENUMBER 13 L0ALOAD 0DUP// 访问变量i// 将整形常量1放入操作数栈// 把操作数栈中的常量1出栈并相加，将相加的结果放入操作数栈PUTFIELD com/gupaoedu/pb/Demo.i : I // 访问类字段（类变量） ，复制给Demo.i这个变量 这三个操作，如果要满足原子性，那么就需要保证某个线程在执行这个指令时，不允许其他线程干扰，然后实际上，确实会存在这个问题。 图解问题本质前面我们说过，一个CPU核心在同一时刻只能执行一个线程，如果线程数量远远大于CPU核心数，就会 发生线程的切换，这个切换动作可以发生在任何一条CPU指令执行完之前。 对于 i++这三个cpu指令来说，如果线程A在执行指令1之后，做了线程切换，假设切换到线程B，线程B 同样执行CPU指令，执行的顺序如下图所示。就会导致最终的结果是1，而不是2. 这就是在多线程环境下，存在的原子性问题，那么，怎么解决这个问题呢？ 大家认真观察上面这个图，表面上是多个线程对于同一个变量的操作，实际上是count++这行代码，它 不是原子的。所以才导致在多线程环境下出现这样一个问题。 也就是说，我们只需要保证，count++这个指令在运行期间，在同一时刻只能由一个线程来访问，就可以解决问题。这就需要引出到今天的课程内容，同步锁Synchronized Synchronized的基本应用synchronized有三种方式来加锁，不同的修饰类型，代表锁的控制粒度： 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁 静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 锁的实现模型理解Synchronized到底帮我们做了什么，为什么能够解决原子性呢？ 在没有加锁之前，多个线程去调用incr()方法时，没有任何限制，都是可以同时拿到这个i的值进行++操 作，但是当加了Synchronized锁之后，线程A和B就由并行执行变成了串行执行。 二、Synchronized的原理Synchronized 是如何实现锁的，以及锁的信息是存储在哪里？ 就拿上面分析的图来说，线程A抢到锁了，线程B怎么知道当前锁被抢占了，这个地方一定会有一个标记来实现，而且这个标记一定是存储在某个地方。 Markword对象头这就要引出Markword对象头这个概念了，它是对象头的意思，简单理解，就是一个对象，在JVM内存中的布局或者存储的形式。 jdk8u: markOop.hpp 在Hotspot虚拟机中，对象在内存中的存储布局，可以分为三个区域: **对象头(Header)、实例数据(Instance Data)、对齐填充(Padding)**。 mark-word：对象标记字段占4个字节，用于存储一些列的标记位，比如：哈希值、轻量级锁的标 记位，偏向锁标记位、分代年龄等。 Klass Pointer： Class对象的类型指针，Jdk1.8默认开启指针压缩后为4字节，关闭指针压缩（ -XX:-UseCompressedOops ）后，长度为8字节。其指向的位置是对象对应的Class对象（其对应的 元数据对象）的内存地址。 对象实际数据：包括对象的所有成员变量，大小由各个成员变量决定，比如： byte占1个字节8比特位、int占4个字节32比特位。 对齐：最后这段空间补全并非必须，仅仅为了起到占位符的作用。由于HotSpot虚拟机的内存管理 系统要求对象起始地址必须是8字节的整数倍，所以对象头正好是8字节的倍数。因此当对象实例 数据部分没有对齐的话，就需要通过对齐填充来补全。 通过ClassLayout打印对象头为了让大家更加直观的看到对象的存储和实现，我们可以使用JOL查看对象的内存布局。 添加Jol依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 编写测试代码，在不加锁的情况下，对象头的信息打印 12345678public class Demo &#123; Object o=new Object(); public static void main(String[] args) &#123; Demo demo=new Demo(); //o这个对象，在内存中是如何存储和布局的。 System.out.println(ClassLayout.parseInstance(demo).toPrintable()); &#125;&#125; 输出内容如下 三、关于Synchronized锁的升级Jdk1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。 这么设计的目的，其实是为了减少重量级锁带来的性能开销，尽可能的在无锁状态下解决线程并发问题，其中偏向锁和轻量级锁的底层实现是基于自旋锁，它相对于重量级锁来说，算是一种无锁的实现。 默认情况下是偏向锁是开启状态，偏向的线程ID是0，偏向一个Anonymous BiasedLock 如果有线程去抢占锁，那么这个时候线程会先去抢占偏向锁，也就是把markword的线程ID改为当 前抢占锁的线程ID的过程 如果有线程竞争，这个时候会撤销偏向锁，升级到轻量级锁，线程在自己的线程栈帧中会创建一个 LockRecord ，用CAS操作把markword设置为指向自己这个线程的LR的指针，设置成功后表示抢 占到锁。 如果竞争加剧，比如有线程超过10次自旋（-XX:PreBlockSpin参数配置），或者自旋线程数超过 CPU核心数的一般，在1.6之后，加入了自适应自旋Adapative Self Spinning. JVM会根据上次竞争 的情况来自动控制自旋的时间。 升级到重量级锁，向操作系统申请资源， Linux Mutex ，然后线程被挂起进入到等待队列。 轻量级锁的获取及原理接下来，我们通过下面的例子来演示一下，通过加锁之后继续打印对象布局信息，来关注对象头里面的变化。 1234567891011public class Demo &#123; Object o=new Object(); public static void main(String[] args) &#123; Demo demo=new Demo(); //o这个对象，在内存中是如何存储和布局的。 System.out.println(ClassLayout.parseInstance(demo).toPrintable()); synchronized (demo)&#123; System.out.println(ClassLayout.parseInstance(demo).toPrintable()); &#125; &#125;&#125; 得到的对象布局信息如下 这里很多同学会有疑惑，不是说锁的升级是基于线程竞争情况，来实现从偏向锁到轻量级锁再 到重量级锁的升级的吗？可是为什么这里明明没有竞争，它的锁的标记是轻量级锁呢？ 偏向锁的获取及原理默认情况下，偏向锁的开启是有个延迟，默认是4秒。为什么这么设计呢？ 因为JVM虚拟机自己有一些默认启动的线程，这些线程里面有很多的Synchronized代码，这些 Synchronized 代码启动的时候就会触发竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁的升级和撤销，效率较低。 通过下面这个JVM参数可以讲延迟设置为0. 1-XX:BiasedLockingStartupDelay=0 再次运行下面的代码。 1234567891011public class Demo &#123; Object o=new Object(); public static void main(String[] args) &#123; Demo demo=new Demo(); //o这个对象，在内存中是如何存储和布局的。 System.out.println(ClassLayout.parseInstance(demo).toPrintable()); synchronized (demo)&#123; System.out.println(ClassLayout.parseInstance(demo).toPrintable()); &#125; &#125;&#125; 得到如下的对象布局，可以看到对象头中的的高位第一个字节最后三位数为**[101]**，表示当前为偏向锁状态。 这里的第一个对象和第二个对象的锁状态都是101，是因为偏向锁打开状态下，默认会有配置匿名的对象获得偏向锁。 重量级锁的获取在竞争比较激烈的情况下，线程一直无法获得锁的时候，就会升级到重量级锁。 仔细观察下面的案例，通过两个线程来模拟竞争的场景。 123456789101112131415public static void main(String[] args) &#123; Demo testDemo = new Demo(); Thread t1 = new Thread(() -&gt; &#123; synchronized (testDemo)&#123; System.out.println(&quot;t1 lock ing&quot;); System.out.println(ClassLayout.parseInstance(testDemo).toPrintable()); &#125; &#125; ); t1.start(); synchronized (testDemo)&#123; System.out.println(&quot;main lock ing&quot;); System.out.println(ClassLayout.parseInstance(testDemo).toPrintable()); &#125;&#125; 四、CASCAS这个在Synchronized底层用得非常多，它的全称有两种 Compare and swap Compare and exchange 就是比较并交换的意思。它可以保证在多线程环境下对于一个变量修改的原子性。CAS的原理很简单，包含三个值 当前内存值(V)、预期原来的值(E)以及期待更新的值(N)。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://pdyun.cc/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"Peilin Deng"},{"title":"多线程基本原理","slug":"多线程基本原理","date":"2022-03-03T15:08:00.000Z","updated":"2022-03-03T16:36:38.683Z","comments":true,"path":"2022/03/03/多线程基本原理/","link":"","permalink":"https://pdyun.cc/2022/03/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/","excerpt":"","text":"一、多线程的基本原理线程的start方法，实际上底层做了很多事情，具体的实现简图如下，画得不一定工整，但是能够表达大概意思就行。 OS调度算法有很多，比如先来先服务调度算法（FIFO）、最短优先（就是对短作业的优先调度）、时间片轮转调度等 线程的运行状态先来了解线程的运行状态， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ThreadStatus &#123; public static void main(String[] args) &#123; //TIME_WAITING new Thread(()-&gt;&#123; while(true)&#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; ,&quot;timewaiting&quot;).start(); //WAITING，线程在ThreadStatus类锁上通过wait进行等待 new Thread(()-&gt;&#123; while(true)&#123; synchronized (ThreadStatus.class)&#123; try &#123; ThreadStatus.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; ,&quot;Waiting&quot;).start(); //线程在ThreadStatus加锁后，不会释放锁 new Thread(new BlockedDemo(),&quot;BlockDemo-01&quot;).start(); new Thread(new BlockedDemo(),&quot;BlockDemo-02&quot;).start(); &#125; static class BlockedDemo extends Thread&#123; public void run()&#123; synchronized (BlockedDemo.class)&#123; while(true)&#123; try &#123; TimeUnit.SECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 运行上述示例，打开终端命令，输入”jps”（显示当前所有Java进程pid）；根据获取到的pid， 通过 jstack pid ，可以打印指定Java进程ID的堆栈信息通过堆栈信息，可以看到线程的运行状态 线程的状态通过上面这段代码可以看到，线程在运行过程中，会存在几种不同的状态，一般来说，在Java中，线程的状态一共是6种状态，分别是 NEW：初始状态，线程被构建，但是还没有调用start方法 RUNNABLED：运行状态，JAVA线程把操作系统中的就绪和运行两种状态统一称为“运行中” BLOCKED：阻塞状态，表示线程进入等待状态,也就是线程因为某种原因放弃了CPU使用权，阻塞也分为几种情况 Ø 等待阻塞：运行的线程执行wait方法，jvm会把当前线程放入到等待队列 Ø 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被其他线程锁占用了，那么jvm会把当前的线程放入到锁池中 Ø 其他阻塞：运行的线程执行Thread.sleep或者t.join方法，或者发出了I/O请求时，JVM会把当前线程设置为阻塞状态，当sleep结束、join线程终止、io处理完毕则线程恢复 WAITING: 等待状态 TIME_WAITING：超时等待状态，超时以后自动返回 TERMINATED：终止状态，表示当前线程执行完毕 二、线程的终止如何正确停止一个线程呢？这个问题要细聊，还是有很多东西可以说的。 我们知道Thread提供了线程的一些操作方法，比如stop、suspend等，这些方法可以终止一个线程或者挂起一个线程，但是这些方法都不建议大家使用。原因比较简单， 举个例子，假设一个线程中，有多个任务在执行，此时，如果调用stop方法去强行中断，那么这个时候相当于是发送一个指令告诉操作系统把这个线程结束掉，但是操作系统的这个结束动作完成不代表线程中的任务执行完成，很可能出现线程的任务执行了一般被强制中断，最终导致数据产生问题。这种行为类似于在linux系统中执行 kill -9类似，它是一种不安全的操作。 那么除了这种方法之外，还有什么方式可以实现线程的终止呢？要了解这个问题，我们首先需要知道，一个线程什么情况下算是终止了。 一个线程在什么情况下是执行结束了我们分析一下下面这段代码，通过start（）启动一个线程之后，本质上就是执行这个线程的run方法。那么如果这个线程在run方法执行完之前，一直处于运行状态，直到run方法中的指令执行完毕，那么这个线程就会被销毁 1234567public class MyThread extends Thread &#123; public void run() &#123; System.out.println(&quot;MyThread.run()&quot;); &#125;&#125;MyThread myThread1 = new MyThread();myThread1.start(); 在正常情况下，这个线程是不需要人为干预去结束的。如果要强制结束，只能走stop这个方法。 那在哪些情况下，线程的中断需要外部干预呢？ 线程中存在无限循环执行，比如while(true)循环 线程中存在一些阻塞的操作，比如sleep、wait、join等。 存在循环的线程假设存在如下场景，在run方法中，存在一个while循环，因为这个循环的存在使得这个run方法一直无法运行结束，这种情况下，如何终止呢？ 123456789public class MyThread extends Thread &#123; public void run() &#123; while(true)&#123; System.out.println(&quot;MyThread.run()&quot;); &#125; &#125;&#125;MyThread myThread1 = new MyThread();myThread1.start(); 按照我们开发的思维来说，首先要解决的就是，while(true)这个循环，必须要有一个结束条件，其次是 要在其他地方能够修改这个结束条件让该线程感知到变化。假设我们把while(true)改成while(ﬂag)，这个ﬂag可以作为共享变量被外部修改，修改之后使得循环条件无法被满足，从而退出循环并且结束线程。 这段逻辑其实非常简单，其实就是给了线程一个退出的条件，如果没有这个条件，那么线程将会一直运行。 实际上，在Java提供了一个 interrupt方法，这个方法就是实现线程中断操作的，它的作用和上面讲的 这个案例的作用一样。 interrupt方法当其他线程通过调用当前线程的interrupt方法，表示向当前线程打个招呼，告诉他可以中断线程的执行了，至于什么时候中断，取决于当前线程自己。 线程通过检查自身是否被中断来进行相应，可以通过isInterrupted()来判断是否被中断。 1234567891011121314151617public class InterruptDemo &#123; private static int i; public static void main(String[] args) throws InterruptedException &#123; Thread thread=new Thread(()-&gt;&#123; while(!Thread.currentThread().isInterrupted())&#123; //默认情况下 isInterrupted返回false、通过thread.interrupt变成了true i++; &#125; System.out.println(&quot;Num:&quot;+i); &#125; ,&quot;interruptDemo&quot;); thread.start(); TimeUnit.SECONDS.sleep(1); thread.interrupt(); //加和不加的效果 &#125;&#125; 这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅 处于阻塞状态下的线程中断另外一种情况，就是当线程处于阻塞状态下时，我想要中断这个线程，那怎么做呢？ 1234567891011121314151617181920public class InterruptDemo &#123; private static int i; public static void main(String[] args) throws InterruptedException &#123; Thread thread=new Thread(()-&gt;&#123; while(!Thread.currentThread().isInterrupted())&#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(&quot;Num:&quot;+i); &#125; ,&quot;interruptDemo&quot;); thread.start(); TimeUnit.SECONDS.sleep(1); thread.interrupt(); &#125;&#125; 从这个例子中反馈出一个问题，我们平时在线程中使用的sleep、 wait、join等操作，它都会抛出一个 InterruptedException 异常，为什么会抛出异常，是因为它在阻塞期间，必须要能够响应被其他线程发 起中断请求之后的一个响应，而这个响应是通过InterruptedException来体现的。 但是这里需要注意的是，在这个异常中如果不做任何处理的话，我们是无法去中断线程的，因为当前的 异常只是响应了外部对于这个线程的中断命令，同时，线程的中断状态也会复位，如果需要中断，则还 需要在catch中添加下面的代码 1234567891011121314151617181920212223public class InterruptDemo &#123; private static int i; public static void main(String[] args) throws InterruptedException &#123; Thread thread=new Thread(()-&gt;&#123; while(!Thread.currentThread().isInterrupted())&#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); Thread.currentThread().interrupt(); //再次中断 &#125; &#125; System.out.println(&quot;Num:&quot;+i); &#125; ,&quot;interruptDemo&quot;); thread.start(); TimeUnit.SECONDS.sleep(1); thread.interrupt(); System.out.println(thread.isInterrupted()); &#125;&#125; 所以，InterruptedException 异常的抛出并不意味着线程必须终止，而是提醒当前线程有中断的操作发生，至于接下来怎么处理取决于线程本身，比如 直接捕获异常不做任何处理 将异常往外抛出 停止当前线程，并打印异常信息 三、Thread Dump日志分析接下来给大家再讲点在工作中比较实用的一个内容。就是我们在使用线程的时候，如果出现问题，怎么 排查？比如说 CPU占用率很高，响应很慢 CPU占用率不高，但响应很慢 线程出现死锁的情况 演示代码为了更好的体现效果，我们通过以下代码进行演示。 编写一个java项目 1234567891011121314151617181920212223242526272829/** * 控制器接口层 **/@RestControllerpublic class ThreadController &#123; @GetMapping(&quot;/loop&quot;) public String dumpWhile()&#123; new Thread(new WhileThread()).start(); return &quot;ok&quot;; &#125; @GetMapping(&quot;/dead&quot;) public String dumpDeadLock()&#123; Thread a = new ThreadRunA(); Thread b = new ThreadRunB(); a.start(); b.start(); return &quot;ok&quot;; &#125;&#125;class WhileThread implements Runnable &#123; @Override public void run() &#123; while (true) &#123; System.out.println(&quot;Thread&quot;); &#125; &#125;&#125; 123456789101112131415161718192021/** * 线程A **/class ThreadRunA extends Thread &#123; @Override public void run() &#123; System.out.println(&quot;================A===================&quot;); synchronized (A.A) &#123; System.out.println(&quot;我要开始执行任务A。。。。&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (B.B) &#123; &#125; System.out.println(&quot;我在执行任务结束了A。。。。&quot; + Thread.currentThread().getName() + &quot;:&quot; + B.B.hashCode() + &quot;:&quot; + A.A.hashCode()); &#125; &#125;&#125; 1234567891011121314151617181920/** * 线程B **/class ThreadRunB extends Thread &#123; @Override public void run() &#123; System.out.println(&quot;================B===================&quot;); synchronized (B.B) &#123; System.out.println(&quot;我要开始执行任务B。。。。&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (A.A) &#123; &#125; System.out.println(&quot;我在执行任务结束了B。。。。&quot; + Thread.currentThread().getName() + &quot;:&quot; + B.B + &quot;:&quot; + A.A); &#125; &#125;&#125; 12nohup java -jar -Dserver.port=8088 thread-demo-0.0.1-SNAPSHOT.jar &gt; all.log &amp;//打成jar后运行 CPU占用率不高，但响应很慢通过 curl http://127.0.0.1:8088/dead 演示死锁的场景 查看死锁问题的操作步骤如下： 通过 jps命令，查看java进程的pid 通过 jstack 查看线程日志 如果存在死锁情况，Thread Dump 日志里面肯定会给出 Found one Java-level deadlock:信息。只要 找到这个信息就可以立马定位到问题并且去解决。 12345678Found one Java-level deadlock:=============================&quot;Thread-1&quot;: waiting to lock monitor 0x0000000026070c88 (object 0x00000007163b7d78, a java.lang.Integer), which is held by &quot;Thread-0&quot;&quot;Thread-0&quot;: waiting to lock monitor 0x00000000260735c8 (object 0x0000000716649aa8, a java.lang.Integer), which is held by &quot;Thread-1&quot; CPU占用率很高，响应很慢有的时候我们会发现CPU占用率很高，系统日志也看不出问题，那么这种情况下，我们需要去看一下运 行中的线程有没有异常。 执行 curl http://127.0.0.1:8088/loop这个方法，会出现一个线程死循环的情况。 通过 top -c 动态显示进程及占用资源的排行榜，从而找到占用CPU最高的进程PID，得到的 PID=80972 123PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND80972 root 20 0 7773456 296124 12904 S 100.2 1.8 0:38.83 java 然后再定位到对应的线程， top -H -p 80972 查找到该进程中最消耗CPU的线程，得到 PID=81122 123PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 81122 root 20 0 7773456 258504 12932 R 99.8 1.6 5:56.34 java 80972 root 20 0 7773456 258504 12932 S 0.0 1.6 0:00.00 java 通过 printf “0x%x\\n” 81122 命令，把对应的线程PID转化为16进制 12[root@localhost test]# printf &quot;0x%x\\n&quot; 81122 0x13ce2 截止执行这个命令 jstack 80972 | grep -A 20 0x13ce2 查看线程Dump日志，其中-A 20表示展示20行， 80972表示进程ID， 0x13ce2表示线程ID 从上述内容可以看出，是WhileThread.run方法中，执行的逻辑导致CPU占用过高。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://pdyun.cc/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"author":"Peilin Deng"},{"title":"Spring 相关面试答疑","slug":"Spring-相关面试题","date":"2022-02-25T07:57:00.000Z","updated":"2022-02-25T09:39:44.764Z","comments":true,"path":"2022/02/25/Spring-相关面试题/","link":"","permalink":"https://pdyun.cc/2022/02/25/Spring-%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"1. 使用 Spring 框架能给我们带来哪些好处? 简化开发, 解放双手 提供了内置的解决方案 BOP、IoC、AOP 声明式事务管理, TransactionManager 提供诸多的工具类, 围绕 Spring 生态, 比如 JdbcTemplate, BeanUtils 2. BeanFactory 和 ApplicationContext 有什么区别? ApplicationContext 是 BeanFactory 的实现类 BeanFactory 是顶层设计(抽象), 而 ApplicationContext 是 User Interface 功能会非常丰富, API是最全的, 一般会认为 ApplicationContext 就是 Ioc容器, 但是Ioc 的功能是在 DefaultListableBeanFactory 类中完成的, 但是有共同的接口 3. 请解释 Spring Bean 的生命周期 所谓生命周期, 从创建, 到调用, 到销毁 ( 作用域决定了生命周期的长短) 单例 Bean: 从容器的启动到 Spring容器的销毁, 如果是延迟加载的 Bean, 会在调用前创建 原型 Bean: 在调用前创建, 在调用后销毁. 4. Spring Bean 各作用域之间的区别? sigleton 作用域全局, 在任何地方可以通过 Ioc 拿到 prototype 作用域全局 request 在一次请求发起和结束之间 session 在一个 session 创建和失效之间, 根据配置的 session 失效时长 global-session 可以理解为容器中的一个应用 ( Spring 5 不再支持 ) 5. Spring 中的 Bean 是线程安全吗? 不一定, 要结合情况. spring 中的 Bean 是从IOC容器中获得的, IOC容器中的 Bean 是通过配置得到的,我们在配置 Bean 的时候, 如果该Bean 的 scope 为原型, 则每次都会创建一个新对象, 因此该 Bean 不存在线程之间的竞争, 所以不会存在线程安全的问题; 如果该 Bean 为单例, 所有线程会共享一个单例实例Bean , 所以可能会存在线程安全问题. 6. Spring 中用到了那些设计模式? 工厂模式、单例模式(容器式单例)、代理模式、享元模式、门面模式、适配器模式、委派模式、装饰器模式、责任链模式、解释器模式、策略模式、建造者模式、观察者模式、访问者模式 … 7. 讲述Spring 的基本实现思路 (见1. Spring 实现的基本思路 MarkDown … ) 8. Spring、SpringBoot、SpringCloud 有什么区别? Spring 是已有的生态, 继承了各种工具, 能完成我们日常开发的所有功能 SpringBoot 基于 Spring, 更加简化了开发, 官方层面提供了一套脚手架, 一键搭建, 节省时间, 我们只需要遵从约定, 就能体验到更加简便的开发, 实现零配置, 并且全面的去 Servlet 化, 能够自运行, 部署也更加简便.SpringCloud 基于 SpringBoot, 主要用于搭建分布式微服务, 集成了各种如 注册中心、服务发现、服务监控、配置中心、负载、熔断等… 打造一个微服务生态. 9. Spring 事务实现原理 Spring 事务管理分为编程式和声明式两种, 编程式事务指的是通过编码方式实现事务; 声明式事务基于 AOP before() -&gt; 从连接池获取 connection 连接 我们业务操作sql after() -&gt; 根据条件(捕获异常等…) 来决定 connection.commit 或者connection.rollback 10. BeanFactory 和 FactoryBean 的区别? BeanFactory 是 Ioc 容器的顶层设计, 用于从容器获取 Bean FactoryBean 用来构建 Bean 的一个包装类, 用于给容器创建 Bean 11. 项目中如何应用AOP? 声明式事务管理、做日志、权限等… 12. @Qualifier是干啥用的? 默认情况下，@Autowired 按类型装配 Spring Bean。如果容器中有多个相同类型的 bean，则框架将抛出 NoUniqueBeanDefinitionException， 以提示有多个满足条件的 bean 进行自动装配。 通过将 @Qualifier 注解与我们想要使用的特定 Spring bean 的名称一起进行装配，Spring 框架就能从多个相同类型并满足装配要求的 bean 中找到我们想要的，避免让Spring脑裂。 12345678@Componentpublic class FooService &#123; @Autowired @Qualifier(&quot;fooFormatter&quot;) private Formatter formatter; //todo &#125; 我们需要做的是@Component或者@Bean注解中声明的value属性以确定名称。其实我们也可以在 Formatter 实现类上使用 @Qualifier 注释，而不是在 @Component 或者 @Bean 中指定名称，也能达到相同的效果： 123456789101112131415@Component@Qualifier(&quot;fooFormatter&quot;)public class FooFormatter implements Formatter &#123; public String format() &#123; return &quot;foo&quot;; &#125;&#125; @Component@Qualifier(&quot;barFormatter&quot;)public class BarFormatter implements Formatter &#123; public String format() &#123; return &quot;bar&quot;; &#125; &#125; 13. 构造方法注入和设值注入有什么区别? 使用构造函数依赖注入时，Spring保证所有一个对象所有依赖的对象先实例化后，才实例化这个对象。（没有他们就没有我原则） 使用set方法依赖注入时，Spring首先实例化对象，然后才实例化所有依赖的对象 14. FileSystemResource 和 ClassPathResource 有何区别? 在FileSystemResource 中需要给出spring-config.xml文件在你项目中的相对路径或者绝对路径。 在ClassPathResource中spring会在ClassPath中自动搜寻配置文件，所以要把ClassPathResource 文件放在ClassPath下。 如果将spring-config.xml保存在了src文件夹下的话，只需给出配置文件的名称即可，因为src文件夹是默认。 简而言之，ClassPathResource在环境变量中读取配置文件，FileSystemResource在配置文件中读取配置文件。","categories":[{"name":"面试答疑","slug":"面试答疑","permalink":"https://pdyun.cc/categories/%E9%9D%A2%E8%AF%95%E7%AD%94%E7%96%91/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 循环依赖-AOP详解","slug":"Spring-循环依赖-AOP详解","date":"2022-02-24T11:10:00.000Z","updated":"2022-02-25T04:06:39.899Z","comments":true,"path":"2022/02/24/Spring-循环依赖-AOP详解/","link":"","permalink":"https://pdyun.cc/2022/02/24/Spring-%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96-AOP%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 核心类依赖图","slug":"Spring-核心类依赖图","date":"2022-02-24T03:13:00.000Z","updated":"2022-02-24T03:17:46.397Z","comments":true,"path":"2022/02/24/Spring-核心类依赖图/","link":"","permalink":"https://pdyun.cc/2022/02/24/Spring-%E6%A0%B8%E5%BF%83%E7%B1%BB%E4%BE%9D%E8%B5%96%E5%9B%BE/","excerpt":"","text":"BeanFactory 相关核心依赖","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"责任链模式","slug":"责任链模式","date":"2022-02-23T09:03:00.000Z","updated":"2022-02-23T09:23:33.921Z","comments":true,"path":"2022/02/23/责任链模式/","link":"","permalink":"https://pdyun.cc/2022/02/23/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一、定义责任链模式(Chain of Responseiblibity Pattrern) 是将链中每一个节点看做是一个对象, 每个节点处理的请求均不同, 且内部自动维护一个下一节点对象. 当一个请求从链式的首端发出时, 会沿着链的路径依次传递给每一个节点对象, 直至有对象处理这个请求为止. 属于行为型设计模式 二、适用场景 多个对象可以处理同一请求, 但具体由哪个对象处理则在运行时动态决定. 在不明确指定接收者的情况下, 向多个对象中的一个提交一个请求. 可动态指定一组对象处理请求. 三、java代码简单案例此处使用用户登录及认证做一个简单案例 使用责任链模式之前1234567891011121314151617181920212223/** * 用户实体类 */@Datapublic class User &#123; private String loginName; private String loginPass; private String roleName; public User(String loginName, String loginPass) &#123; this.loginName = loginName; this.loginPass = loginPass; &#125; @Override public String toString() &#123; return &quot;Member&#123;&quot; + &quot;loginName=&#x27;&quot; + loginName + &#x27;\\&#x27;&#x27; + &quot;, loginPass=&#x27;&quot; + loginPass + &#x27;\\&#x27;&#x27; + &quot;, roleName=&#x27;&quot; + roleName + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839/** * 用户业务实现类 */public class UserService &#123; public void login(String loginName,String loginPass)&#123; if(StringUtils.isEmpty(loginName) || StringUtils.isEmpty(loginPass))&#123; System.out.println(&quot;用户名和密码为空&quot;); return; &#125; System.out.println(&quot;用户名和密码不为空，可以往下执行&quot;); User user = checkExists(loginName,loginPass); if(null == user)&#123; System.out.println(&quot;用户不存在&quot;); return; &#125; System.out.println(&quot;登录成功！&quot;); if(!&quot;管理员&quot;.equals(user.getRoleName()))&#123; System.out.println(&quot;您不是管理员，没有操作权限&quot;); return; &#125; System.out.println(&quot;允许操作&quot;); &#125; private User checkExists(String loginName, String loginPass)&#123; User user = new User(loginName,loginPass); user.setRoleName(&quot;管理员&quot;); return user; &#125; public static void main(String[] args) &#123; UserService service = new UserService(); service.login(&quot;tom&quot;,&quot;666&quot;); &#125;&#125; 以上, 在实现用户登录业务逻辑的时候, 各种校验于代码中… 可能还会有其他的业务校验, 就会造成代码长度过大, 非常复杂. 使用责任链模式之后123456789101112131415161718192021222324252627282930/** * 业务处理接口, 结合了建造者模式 */public abstract class Handler&lt;T&gt; &#123; protected Handler&lt;T&gt; next; public void next(Handler next)&#123; this.next = next;&#125; public abstract void doHandler(User user); public static class Builder&lt;T&gt;&#123; private Handler&lt;T&gt; head; private Handler&lt;T&gt; tail; public Builder&lt;T&gt; addHandler(Handler handler)&#123; //do &#123; if (this.head == null) &#123; this.head = this.tail = handler; return this; &#125; this.tail.next(handler); this.tail = handler; //&#125;while (false);//真正框架中，如果是双向链表，会判断是否已经到了尾部 return this; &#125; public Handler&lt;T&gt; build()&#123; return this.head; &#125; &#125;&#125; 1234567891011121314/** * Handler实现类, 该Handler用于处理登录成功后的逻辑 */public class LoginHandler extends Handler &#123; public void doHandler(User user) &#123; System.out.println(&quot;登录成功！准备跳转首页...&quot;); // 登录成功后的业务逻辑...... if(null != next) &#123; next.doHandler(user); &#125; &#125;&#125; 123456789101112131415/** * 权限认证Handler实现类 */public class AuthHandler extends Handler &#123; public void doHandler(User user) &#123; if(!&quot;管理员&quot;.equals(user.getRoleName()))&#123; System.out.println(&quot;您不是管理员，没有操作权限&quot;); return; &#125; System.out.println(&quot;允许操作&quot;); if(null != next) &#123; next.doHandler(user); &#125; &#125;&#125; 12345678910111213141516/** * 用户名密码校验 */public class ValidateHandler extends Handler &#123; public void doHandler(User user) &#123; if(StringUtils.isEmpty(user.getLoginName()) || StringUtils.isEmpty(user.getLoginPass()))&#123; System.out.println(&quot;用户名和密码为空&quot;); return; &#125; System.out.println(&quot;用户名和密码不为空，可以往下执行&quot;); if(null != next) &#123; next.doHandler(user); &#125; &#125;&#125; 1234567891011121314151617181920/** * 用户Service层 */public class UserService &#123; public void login(String loginName,String loginPass)&#123; Handler.Builder builder = new Handler.Builder(); builder.addHandler(new ValidateHandler()) .addHandler(new LoginHandler()) .addHandler(new AuthHandler()); User user = new User(loginName, loginPass); user.setRoleName(&quot;管理员&quot;); builder.build().doHandler(user); //用过Netty的人，肯定见过 &#125;&#125; 测试类 123456public class Test &#123; public static void main(String[] args) &#123; UserService userService = new UserService(); userService.login(&quot;tom&quot;,&quot;666&quot;); &#125;&#125; 测试结果 12345------------------------------------------------------用户名和密码不为空，可以往下执行登录成功！允许操作------------------------------------------------------ 四、优点 将请求与处理解耦. 请求矗立着(节点对象) 只需关注自己感兴趣的请求进行处理即可, 对不感兴趣的请求, 直接转发给下一级节点对象. 具备链式传递处理请求功能, 请求发送者无需知晓链路结构, 只需等待请求处理结果. 链路结构灵活, 可以通过改变链路结构动态地新增或删减责任. 易于扩展新的请求处理类(节点), 符合开闭原则. 五、缺点 责任链太长或者处理时间过长, 会影响整体性能, 如果节点对象存在循环引用时, 会造成死循环, 导致系统崩溃.","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"行为型设计模式","slug":"行为型设计模式","permalink":"https://pdyun.cc/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"策略模式","slug":"策略模式","date":"2022-02-23T08:20:00.000Z","updated":"2022-02-23T08:21:22.622Z","comments":true,"path":"2022/02/23/策略模式/","link":"","permalink":"https://pdyun.cc/2022/02/23/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一、定义策略模式(Strategy Pattern) 又叫政策模式(Policy Pattern), 他是将定义的算法家族、分别封装起来, 让他们之间可以相互替换, 从而让算法的变化不会影响到使用算法的用户. 可以避免多重的 if…else…和switch语句 属于行为型设计模式 二、意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 三、主要解决：在有多种算法相似的情况下，使用 if…else、switch 等所带来的复杂和难以维护。 四、适用场景 假如系统中有很多类, 而他们的区别仅仅在于他们的行为不同. 一个系统需要动态的在几种算法中选择一种. 需要屏蔽算法规则. 五、Java代码简单案例案例采用于生活中的支付场景. 生活中有 支付宝, 微信, 银联, 京东支付等.. 1. 定义支付抽象类和实现类12345678910111213141516171819/** * 1. 支付抽象类 */public abstract class Payment &#123; public abstract String getName(); //通用逻辑放到抽象类里面实现 public MsgResult pay(String uid, double amount)&#123; //余额是否足够 if(queryBalance(uid) &lt; amount)&#123; return new MsgResult(500,&quot;支付失败&quot;,&quot;余额不足&quot;); &#125; return new MsgResult(200,&quot;支付成功&quot;,&quot;支付金额&quot; + amount); &#125; // 由各自实现类自行实现 protected abstract double queryBalance(String uid);&#125; 12345678910111213/** * 支付宝支付实现类 */public class AliPay extends Payment &#123; public String getName() &#123; return &quot;支付宝&quot;; &#125; // 支付宝查询余额方法 protected double queryBalance(String uid) &#123; return 900; &#125;&#125; 12345678910111213/** * 京东支付实现类 */public class JDPay extends Payment &#123; public String getName() &#123; return &quot;京东白条&quot;; &#125; // 京东支付查询余额方法 protected double queryBalance(String uid) &#123; return 500; &#125;&#125; 12345678910111213/** * 银联支付实现类 */public class UnionPay extends Payment &#123; public String getName() &#123; return &quot;银联支付&quot;; &#125; // 银联支付查询余额方法 protected double queryBalance(String uid) &#123; return 120; &#125;&#125; 12345678910111213/** * 微信支付实现类 */public class WechatPay extends Payment &#123; public String getName() &#123; return &quot;微信支付&quot;; &#125; // 微信支付查询余额方法 protected double queryBalance(String uid) &#123; return 263; &#125;&#125; 2. 定义支付策略类1234567891011121314151617181920212223242526/** * 2. 定义支付策略类 */public class PayStrategy &#123; public static final String ALI_PAY = &quot;AliPay&quot;; public static final String JD_PAY = &quot;JdPay&quot;; public static final String WECHAT_PAY = &quot;WechatPay&quot;; public static final String UNION_PAY = &quot;UnionPay&quot;; public static final String DEFAULT_PAY = ALI_PAY; private static Map&lt;String,Payment&gt; strategy = new HashMap&lt;String,Payment&gt;(); static &#123; strategy.put(ALI_PAY,new AliPay()); strategy.put(JD_PAY,new JDPay()); strategy.put(WECHAT_PAY,new WechatPay()); strategy.put(UNION_PAY,new UnionPay()); &#125; public static Payment get(String payKey)&#123; if(!strategy.containsKey(payKey))&#123; return strategy.get(DEFAULT_PAY); &#125; return strategy.get(payKey); &#125;&#125; 3. 定义支付结果类1234567891011121314151617181920212223/** * 3. 支付结果类 */public class MsgResult &#123; private int code; private Object data; private String msg; public MsgResult(int code, String msg, Object data) &#123; this.code = code; this.data = data; this.msg = msg; &#125; @Override public String toString() &#123; return &quot;MsgResult&#123;&quot; + &quot;code=&quot; + code + &quot;, data=&quot; + data + &quot;, msg=&#x27;&quot; + msg + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 4. 定义订单交易类12345678910111213141516171819202122232425/** * 4. 订单交易类 */public class Order &#123; private String uid; private String orderId; private double amount; public Order(String uid, String orderId, double amount) &#123; this.uid = uid; this.orderId = orderId; this.amount = amount; &#125; public MsgResult pay()&#123; return pay(PayStrategy.DEFAULT_PAY); &#125; public MsgResult pay(String payKey)&#123; Payment payment = PayStrategy.get(payKey); System.out.println(&quot;欢迎使用&quot; + payment.getName()); System.out.println(&quot;本次交易金额为&quot; + amount + &quot;，开始扣款&quot;); return payment.pay(uid,amount); &#125;&#125; 5. 测试类123456789101112131415/** * 测试类 */public class Test &#123; public static void main(String[] args) &#123; Order order = new Order(&quot;1&quot;,&quot;2020031401000323&quot;,500); System.out.println(order.pay()); order = new Order(&quot;2&quot;,&quot;2020031401000324&quot;,121.5); System.out.println(order.pay(PayStrategy.UNION_PAY)); order = new Order(&quot;2&quot;,&quot;2020031401000324&quot;,200); System.out.println(order.pay(PayStrategy.WECHAT_PAY)); &#125;&#125; 测试结果 12345678910111213-------------------------------------------------------欢迎使用支付宝本次交易金额为500.0，开始扣款MsgResult&#123;code=200, data=支付金额500.0, msg=&#x27;支付成功&#x27;&#125;欢迎使用银联支付本次交易金额为121.5，开始扣款MsgResult&#123;code=500, data=余额不足, msg=&#x27;支付失败&#x27;&#125;欢迎使用微信支付本次交易金额为200.0，开始扣款MsgResult&#123;code=200, data=支付金额200.0, msg=&#x27;支付成功&#x27;&#125;------------------------------------------------------- 六、策略模式优点 策略模式符合开闭原则. 避免使用多重条件转移语句, 如 if…else..等 使用策略模式可以提高算法的保密性和安全性. 七、策略模式缺点 客户端必须知道所有的策略, 并且自行决定使用哪一个策略. 代码中会产生非常多的策略类, 增加维护难度.","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"行为型设计模式","slug":"行为型设计模式","permalink":"https://pdyun.cc/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"模板方法模式","slug":"模板方法模式","date":"2022-02-23T07:16:00.000Z","updated":"2022-02-23T07:29:39.879Z","comments":true,"path":"2022/02/23/模板方法模式/","link":"","permalink":"https://pdyun.cc/2022/02/23/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一、定义(只能通过继承来实现, 使用覆盖实现微调)模板方法模式(Template Method Pattern) 通常又叫模板模式, 是指定义一个算法的骨架, 并允许子类成为其中的一个或者多个步骤提供实现. 模板方法使得子类可以在不改变算法结构的情况下, 重新定义算法的某些步骤. 属于行为型设计模式. 二、使用场景 一次性实现一个算法不变的部分, 并将可变的行为留给子类来实现. 各子类中公共的行为被提取出来并集中到一个公共的父类中, 从而避免代码重复. 三、Java代码简单写法使用三个类简单表述 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 1. 程抽象类, 用于统一课程的特性, 设置了一个钩子方法用于是否&#x27;检查作业&#x27;步骤 */public abstract class AbastractCourse &#123; public final void createCourse()&#123; //1、发布预习资料 postPreResoucse(); //2、制作课件 createPPT(); //3、直播授课 liveVideo(); //4、上传课后资料 postResource(); //5、布置作业 postHomework(); //6、检查作业, 我们可以交给子类实现, 可能每个课程检查作业方式不一样 //(也可能不需要检查作业), 我们可以交给用户自己来决定是否检查作业 if(needCheckHomework())&#123; checkHomework(); &#125; &#125; protected abstract void checkHomework(); //钩子方法 protected boolean needCheckHomework()&#123;return false;&#125; protected void postHomework()&#123; System.out.println(&quot;布置作业&quot;); &#125; protected void postResource()&#123; System.out.println(&quot;上传课后资料&quot;); &#125; protected void liveVideo()&#123; System.out.println(&quot;直播授课&quot;); &#125; protected void createPPT()&#123; System.out.println(&quot;制作课件&quot;); &#125; protected void postPreResoucse()&#123; System.out.println(&quot;发布预习资料&quot;); &#125; 12345678910111213141516171819/** * 2. Java课程实现类, 该类我们可以自定义决定是否可以&#x27;检查作业&#x27;的步骤 */public class JavaCourse extends AbastractCourse &#123; private boolean needCheckHomework = false; public void setNeedCheckHomework(boolean needCheckHomework) &#123; this.needCheckHomework = needCheckHomework; &#125; @Override protected boolean needCheckHomework() &#123; return this.needCheckHomework; &#125; protected void checkHomework() &#123; System.out.println(&quot;检查Java作业&quot;); &#125;&#125; 12345678/** * 3. ython课程实现类 */public class PythonCourse extends AbastractCourse &#123; protected void checkHomework() &#123; System.out.println(&quot;检查Python作业&quot;); &#125;&#125; 测试代码 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; System.out.println(&quot;=========Java课程=========&quot;); JavaCourse java = new JavaCourse(); // 设置java需要检查作业 java.setNeedCheckHomework(true); java.createCourse(); System.out.println(&quot;=========Python课程=========&quot;); PythonCourse python = new PythonCourse(); python.createCourse(); &#125;&#125; 测试结果 1234567891011121314151617---------------------------------------------=========Java课程=========发布预习资料制作课件直播授课上传课后资料布置作业检查Java作业=========Python课程=========发布预习资料制作课件直播授课上传课后资料布置作业--------------------------------------------- 四、优点 利用模板方法将相同处理逻辑的代码放到抽象父类中, 可以提高代码的复用性, 也符合开闭原则. 将不同代码放到不同子类中, 通过对子类的扩展增加新的行为, 提高代码的扩展性. 五、缺点 类数目的增加, 每一个抽象类都需要一个子类来实现, 这样导致类的个数增加. 类数量的增加, 间接的增加了系统实现的复杂度. 继承关系自身缺点, 如果父类添加新的抽象方法, 所有子类都需要改一遍.","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"行为型设计模式","slug":"行为型设计模式","permalink":"https://pdyun.cc/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"委派模式","slug":"委派模式","date":"2022-02-23T06:45:00.000Z","updated":"2022-02-23T06:55:44.340Z","comments":true,"path":"2022/02/23/委派模式/","link":"","permalink":"https://pdyun.cc/2022/02/23/%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一、委派模式的定义委派模式(Delegate Pattern) 又叫委托模式. 它的基本作用就是负责任务的调度和任务的分配, 将任务的分配和执行分离开来. 可以看做是一种特殊情况下的静态代理的全权代理. 不属于GOF 23种设计模式之一. 属于行为型模式. 二、委派模式和代理模式的区别 委派模式是行为型模式, 代理模式是结构型模式. 委派模式注重的是任务派遣, 注重结果;代理模式注重的是代码增强, 注重过程. 委派模式是一种特殊的静态代理, 相当于全权代理. 三、SpringMVC中的委派模式 从图中可以看出dispatcherServlet更像是一个分发任务的分发者, 但其实springmvc本身就是一个大的委派. web浏览器发送请求给dispatchServlet dispatchServlet委派HandlerMapping去找到url所对应的方法。 通过HandlerMapping找到的方法dispatcherServlet委派处理器适配器去调用方法返回ModelAndView 紧接着委派视图解析器去渲染modelAndView 最终返回给web浏览器。 从上述流程可以看出，dispatcherServlet委派的对象不是同一类对象，而是三个大的类，HandlerMap，处理器，视图解析器。 四、总结委派模式是一种设计思想，它想表达的是，尽量将工作分发给专门的对象去做 优点通过任务委派能将一个大型的任务细化, 然后通过统一管理这些子任务的完成情况实现任务跟进, 能够加快任务的执行效率. 缺点任务委派方式需要根据任务的复杂情况进行不同的改变, 在任务比较复杂的情况下可能需要进行多重委派, 容易造成紊乱.","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"行为型设计模式","slug":"行为型设计模式","permalink":"https://pdyun.cc/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"代理模式","slug":"代理模式","date":"2022-02-11T08:11:00.000Z","updated":"2022-02-11T08:43:52.376Z","comments":true,"path":"2022/02/11/代理模式/","link":"","permalink":"https://pdyun.cc/2022/02/11/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一、类型结构型设计模式 二、代理模式的定义代理模式 是指为其他对象提供一种代理, 以控制对这个对象的访问. 代理对象在客户端和目标对象之间起到中介作用. 三、静态代理和动态代理区别静态代理: 硬编码、手动注入, 手动拿到目标对象的引用, 手动调用代理目标的方法. 动态代理: 具有更强的扩展性, 自动注入, 自动生成一个新的类(同一个继承体系) 特征: 1.拿到代理目标对象的引用 2.实现功能增强 3.保护目标对象 四、动态代理对象的创建过程 动态拼接出代理对象的java类的代码(包括java类的import xxx、类名、构造方法、继承接口、方法等动态拼接出来形成一个正常的java类) 用文件流将代理对象的java类输出到磁盘, 保存为$Proxy0.java文件 将$Proxy0.java文件进行编译成.class文件, 新文件为$Proxy0.class 将生成的$Proxy0.class加载到JVM内存中 返回新的代理对象 五、CgLib Proxy 与 JDK Proxy 区别 不同点: CgLib Proxy 使用继承的方式, 覆盖父类的方法. JDK Proxy 采用实现接口的方式, 必须要求代理的目标实现一个接口. CgLib Proxy 对目标类没有任何要求. JDK Proxy 对于用户而言, 依赖更强, 调用更复杂. CgLib Proxy 采用另外一套API, 没有使用反射, 性能更高. JDK Proxy 生成逻辑较为简单, 执行效率相对较低, 每次都使用到反射. 相同点: 都是通过生成字节码, 重组成一个新的类. CgLib 有个坑: 由于使用的继承, 目标代理类不能有final修饰的方法, 他会忽略final修饰的方法. 六、代理模式优点 代理模式能将代理对象与真实被调用的目标对象分离. 一定程度上降低了系统的耦合度, 易于扩展. 代理可以起到保护目标对象的作用. 增强目标对象. 七、代理模式缺点 代理模式会造成系统设计中类数量增加. 在客户端和目标对象之前增加了一个代理对象, 会降低请求速度. 增加系统复杂度 八、Spring 中的代理选择原则 当 Bean 有实现接口时, Spring 就会使用 JDK 的动态代理. 当 Bean 没有实现接口时, Spring 会选择 CGLib. Spring 可以通过配置强制使用 CGLib, 只需在 Spring 配置文件中加入以下代码: 1&lt;aop:aspectj-autoproxy proxy-target-class=&#x27;true&#x27;/&gt; 九、JDK 动态代理的使用123456789101112131415161718192021222324252627public class MyProxy implements InvocationHandler &#123; // 目标对象接口 private IPerson target; public IPerson getInstance(IPerson target)&#123; this.target = target; Class&lt;? extends IPerson&gt; clazz = target.getClass(); return (IPerson) Proxy.newProxyInstance(clazz.getClassLoader(), clazz.getInterfaces(),this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object invoke = method.invoke(this.target, args); after(); return invoke; &#125; private void before()&#123; System.out.println(&quot;before()...&quot;); &#125; private void after()&#123; System.out.println(&quot;after()...&quot;); &#125;&#125; 1234567public static void main(String[] args)&#123; MyProxy proxy = new MyProxy(); IPerson instance = proxy.getInstance(new Zhangsan()); instance.doSomething(); &#125; 123456执行结果----------------------------------------------------------------------------------before()...张三正在执行某件事...after()...----------------------------------------------------------------------------------","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"结构型设计模式","slug":"结构型设计模式","permalink":"https://pdyun.cc/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"建造者模式","slug":"建造者模式","date":"2022-02-10T11:56:00.000Z","updated":"2022-02-10T11:57:35.836Z","comments":true,"path":"2022/02/10/建造者模式/","link":"","permalink":"https://pdyun.cc/2022/02/10/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一. 类型创建型模式 二. 定义建造者模式 是将一个复杂对象的构建与他的表示分离, 使得同样的构建过程可以创建不同的表示. 特征: 用户只需要指定需要创建的类型就可以获得对象, 建造过程及细节不需要了解. 三. 优缺点优点封装性好, 创建和使用分离. 扩展性好, 建造类之间独立、一定程度上解耦. 缺点产生多余的 Builder 对象 产品内部发生改变, 建造者都要修改, 成本较高 四. 简单写法123456789101112131415161718192021222324/** * 实体类 */@Datapublic class Course &#123; private String name; private String ppt; private String video; private String note; private String homework; @Override public String toString() &#123; return &quot;CourseBuilder&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, ppt=&#x27;&quot; + ppt + &#x27;\\&#x27;&#x27; + &quot;, video=&#x27;&quot; + video + &#x27;\\&#x27;&#x27; + &quot;, note=&#x27;&quot; + note + &#x27;\\&#x27;&#x27; + &quot;, homework=&#x27;&quot; + homework + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536/** * 建造者类 */public class CourseBuilder&#123; private Course course = new Course(); public CourseBuilder addName(String name) &#123; course.setName(name); return this; &#125; public CourseBuilder addPPT(String ppt) &#123; course.setPpt(ppt); return this; &#125; public CourseBuilder addVideo(String video) &#123; course.setVideo(video); return this; &#125; public CourseBuilder addNote(String note) &#123; course.setNote(note); return this; &#125; public CourseBuilder addHomework(String homework) &#123; course.setHomework(homework); return this; &#125; public Course build() &#123; return course; &#125;&#125; 测试类 12345678910111213public class Test &#123; public static void main(String[] args) &#123; CourseBuilder builder = new CourseBuilder(); builder.addName(&quot;设计模式&quot;) .addPPT(&quot;【PPT课件】&quot;) .addVideo(&quot;【回放视频】&quot;) .addNote(&quot;【课堂笔记】&quot;) .addHomework(&quot;【课后作业】&quot;); System.out.println(builder.build()); &#125;&#125; 12345执行结果-------------------------------------------------------------------------------------------------------------------------------CourseBuilder&#123;name=&#x27;设计模式&#x27;, ppt=&#x27;【PPT课件】&#x27;, video=&#x27;【回放视频】&#x27;, note=&#x27;【课堂笔记】&#x27;, homework=&#x27;【课后作业】&#x27;&#125;-------------------------------------------------------------------------------------------------------------------------------","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"创建型设计模式","slug":"创建型设计模式","permalink":"https://pdyun.cc/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"原型模式","slug":"原型模式","date":"2022-02-10T10:03:00.000Z","updated":"2022-02-10T10:04:52.076Z","comments":true,"path":"2022/02/10/原型模式/","link":"","permalink":"https://pdyun.cc/2022/02/10/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一. 类型创建型模式 二. 定义原型模式是指原型实例创建对象的种类, 并且通过拷贝这些原型创建新的对象. 调用者不需要知道任何创建细节, 不调用构造函数. 三. 适用场景 类初始化消耗资源较多 new 产生的一个对象需要非常繁琐的过程(数据准备、访问权限等) 构造函数比较复杂 循环体中产生大量对象时 四. 优点 性能优良, java 自带的原型模式是基于内存二进制流的拷贝, 比直接 new 一个对象性能上提升了许多 可以使用深克隆方式保存对象的状态, 使用原型模式将对象复制一份将其状态保存起来, 简化了创建过程. 五. 缺点 必须配备克隆(或者可拷贝)的方法 当对已有的类进行改造的时候, 需要修改代码, 违反了开闭原则 深拷贝、浅拷贝需要运用得当 六. 原型模式写法浅拷贝123456789101112131415161718192021222324252627282930/** * 类实现了Cloneable接口来指示Object.clone()方法，该方法可以合法地对类的实例进行字段对字段的复制。 * 在一个没有实现Cloneable接口的实例上调用Object的clone方法会导致抛出CloneNotSupportedException异常。 */@Datapublic class ConcretePrototype implements Cloneable &#123; private int age; private String name; private List&lt;String&gt; hobbies; @Override public ConcretePrototype clone() &#123; try &#123; return (ConcretePrototype)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); return null; &#125; &#125; @Override public String toString() &#123; return &quot;ConcretePrototype&#123;&quot; + &quot;age=&quot; + age + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, hobbies=&quot; + hobbies + &#x27;&#125;&#x27;; &#125;&#125; 使用案例 12345678910111213141516171819202122232425public static void main(String[] args) &#123; //创建原型对象 ConcretePrototype prototype = new ConcretePrototype(); prototype.setAge(18); prototype.setName(&quot;Tom&quot;); List&lt;String&gt; hobbies = new ArrayList&lt;String&gt;(); hobbies.add(&quot;书法&quot;); hobbies.add(&quot;美术&quot;); prototype.setHobbies(hobbies); //拷贝原型对象 ConcretePrototype cloneType = prototype.clone(); cloneType.getHobbies().add(&quot;技术控&quot;); System.out.println(&quot;原型对象：&quot; + prototype); System.out.println(&quot;克隆对象：&quot; + cloneType); System.out.println(prototype == cloneType); System.out.println(&quot;原型对象的爱好：&quot; + prototype.getHobbies()); System.out.println(&quot;克隆对象的爱好：&quot; + cloneType.getHobbies()); System.out.println(prototype.getHobbies() == cloneType.getHobbies()); &#125; 123456789执行结果--------------------------------------------------------------------------------------------原型对象：ConcretePrototype&#123;age=18, name=&#x27;Tom&#x27;, hobbies=[书法, 美术, 技术控]&#125;克隆对象：ConcretePrototype&#123;age=18, name=&#x27;Tom&#x27;, hobbies=[书法, 美术, 技术控]&#125;false原型对象的爱好：[书法, 美术, 技术控]克隆对象的爱好：[书法, 美术, 技术控]true-------------------------------------------------------------------------------------------- *结论 浅拷贝时引用对象是通过 JDK 中的字节流去完成复制, JDK 底层有一个机制, 如果是一个类已经存在的时候不会去重新加载, 就会进行一个值与值的一个简单复制, 相当于拷贝的是引用, 就会造成以上修改克隆对象中的值时, 原对象也已经被修改 深拷贝1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 深拷贝 */@Datapublic class ConcretePrototype implements Cloneable,Serializable &#123; private int age; private String name; private List&lt;String&gt; hobbies; @Override public ConcretePrototype clone() &#123; try &#123; return (ConcretePrototype)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 可以强转成ArrayList, ArrayList 的clone方法就是使用的深拷贝 */ public ConcretePrototype deepCloneHobbies()&#123; try &#123; ConcretePrototype result = (ConcretePrototype)super.clone(); result.hobbies = (List)((ArrayList)result.hobbies).clone(); return result; &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 序列化和反序列化 可以破坏单例, 可以利用这一点来返回一个新对象 */ public ConcretePrototype deepClone()&#123; try &#123; ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return (ConcretePrototype)ois.readObject(); &#125;catch (Exception e)&#123; e.printStackTrace(); return null; &#125; &#125; @Override public String toString() &#123; return &quot;ConcretePrototype&#123;&quot; + &quot;age=&quot; + age + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, hobbies=&quot; + hobbies + &#x27;&#125;&#x27;; &#125;&#125; 使用案例 123456789101112131415161718192021222324public static void main(String[] args) &#123; //创建原型对象 ConcretePrototype prototype = new ConcretePrototype(); prototype.setAge(18); prototype.setName(&quot;Tom&quot;); List&lt;String&gt; hobbies = new ArrayList&lt;String&gt;(); hobbies.add(&quot;书法&quot;); hobbies.add(&quot;美术&quot;); prototype.setHobbies(hobbies); //拷贝原型对象 ConcretePrototype cloneType = prototype.deepCloneHobbies(); // ConcretePrototype cloneType = prototype.deepClone(); cloneType.getHobbies().add(&quot;技术控&quot;); System.out.println(&quot;原型对象：&quot; + prototype); System.out.println(&quot;克隆对象：&quot; + cloneType); System.out.println(prototype == cloneType); System.out.println(&quot;原型对象的爱好：&quot; + prototype.getHobbies()); System.out.println(&quot;克隆对象的爱好：&quot; + cloneType.getHobbies()); System.out.println(prototype.getHobbies() == cloneType.getHobbies());&#125; 123456789执行结果--------------------------------------------------------------------------------------------原型对象：ConcretePrototype&#123;age=18, name=&#x27;Tom&#x27;, hobbies=[书法, 美术]&#125;克隆对象：ConcretePrototype&#123;age=18, name=&#x27;Tom&#x27;, hobbies=[书法, 美术, 技术控]&#125;false原型对象的爱好：[书法, 美术]克隆对象的爱好：[书法, 美术, 技术控]false-------------------------------------------------------------------------------------------- *结论 以上深拷贝两种方式 参见 public ConcretePrototype deepCloneHobbies() 方法 可以强转成ArrayList, ArrayList 的clone方法就是使用的深拷贝 参见 public ConcretePrototype deepClone() 方法 序列化和反序列化 可以破坏单例, 可以利用这一点来返回一个新对象","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"创建型设计模式","slug":"创建型设计模式","permalink":"https://pdyun.cc/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"单例模式","slug":"单例模式","date":"2022-02-10T09:44:00.000Z","updated":"2022-02-10T10:05:57.711Z","comments":true,"path":"2022/02/10/单例模式/","link":"","permalink":"https://pdyun.cc/2022/02/10/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一. 类型创建型模式 二. 优点 保证一个类仅有一个实例，减少了内存开销. 可以避免对资源的多重占用. 设置全局访问点, 严格控制访问. 三. 缺点 没有接口, 扩展困难. 如果要扩展单例对象, 只有修改代码, 无其他途径. 四. 单例的相关注意点 私有化构造器 保证线程安全 延迟加载 防止序列化和反序列化破坏单例 防御反射破攻击单例 五. 多种单例写法饿汉式单例1234567891011121314/** * 优点：执行效率高，性能高，没有任何的锁 * 缺点：由于提前创建对象, 没有使用的情况下，可能会造成内存浪费 */public class HungrySingleton &#123; private static final HungrySingleton hungrySingleton = new HungrySingleton(); private HungrySingleton()&#123;&#125; public static HungrySingleton getInstance()&#123; return hungrySingleton; &#125;&#125; 懒汉式单例(延迟加载)简单写法123456789101112131415/** * 优点：节省了内存,线程安全 * 缺点：性能低 */public class LazySimpleSingletion &#123; private static LazySimpleSingletion instance; private LazySimpleSingletion()&#123;&#125; public synchronized static LazySimpleSingletion getInstance()&#123; if(instance == null)&#123; instance = new LazySimpleSingletion(); &#125; return instance; &#125;&#125; DCL 双重检查锁写法12345678910111213141516171819202122/** * 优点:性能高了，线程安全了 * 缺点：可读性难度加大，不够优雅 */public class LazyDoubleCheckSingleton &#123; private volatile static LazyDoubleCheckSingleton instance; private LazyDoubleCheckSingleton()&#123;&#125; public static LazyDoubleCheckSingleton getInstance()&#123; //检查是否要阻塞 if (instance == null) &#123; synchronized (LazyDoubleCheckSingleton.class) &#123; //检查是否要重新创建实例 if (instance == null) &#123; instance = new LazyDoubleCheckSingleton(); //指令重排序的问题 &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类写法12345678910111213141516171819202122232425/** 静态内部类写法 ClassPath : LazyStaticInnerClassSingleton.class LazyStaticInnerClassSingleton$LazyHolder.class 优点：利用了Java本身语法特点，性能高，避免了内存浪费,不能被反射破坏 缺点：不优雅 */public class LazyStaticInnerClassSingleton &#123; private LazyStaticInnerClassSingleton()&#123; // 此处防止反射攻击破坏单例所做的检查, 此处让代码变得不优雅, 且不易懂 if(LazyHolder.INSTANCE != null)&#123; throw new RuntimeException(&quot;不允许非法访问&quot;); &#125; &#125; private static LazyStaticInnerClassSingleton getInstance()&#123; return LazyHolder.INSTANCE; &#125; private static class LazyHolder&#123; private static final LazyStaticInnerClassSingleton INSTANCE = new LazyStaticInnerClassSingleton(); &#125;&#125; 注册式单例枚举式单例12345678910111213141516171819202122/** * 枚举式单例 * 优点: 优雅的写法 * 缺点: 不能大批量创建对象 */public enum EnumSingleton &#123; INSTANCE; private Object data; public Object getData() &#123; return data; &#125; public void setData(Object data) &#123; this.data = data; &#125; public static EnumSingleton getInstance()&#123; return INSTANCE; &#125;&#125; 容器式单例123456789101112131415161718192021222324252627/** * 容器式单例 * 基于枚举式单例的改进, 可以大批量创建对象, * 以下代码需要增加线程安全的逻辑 */public class ContainerSingleton &#123; private ContainerSingleton()&#123;&#125; private static Map&lt;String,Object&gt; ioc = new ConcurrentHashMap&lt;String, Object&gt;(); public static Object getInstance(String className)&#123; Object instance = null; if(!ioc.containsKey(className))&#123; try &#123; instance = Class.forName(className).newInstance(); ioc.put(className, instance); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return instance; &#125;else&#123; return ioc.get(className); &#125; &#125;&#125; 解决序列化的单例12345678910111213141516171819202122232425public class SeriableSingleton implements Serializable &#123; //序列化 //把内存中对象的状态转换为字节码的形式 //把字节码通过IO输出流，写到磁盘上 //永久保存下来，持久化 //反序列化 //将持久化的字节码内容，通过IO输入流读到内存中来 //转化成一个Java对象 public final static SeriableSingleton INSTANCE = new SeriableSingleton(); private SeriableSingleton()&#123;&#125; public static SeriableSingleton getInstance()&#123; return INSTANCE; &#125; // 反序列化时, 输入流对象底层实际上是new的一个新对象返回 // 如果有该方法的话, 输入流会通过反射找到该名称的方法, 获取到返回结果来避免new一个对象 private Object readResolve()&#123; return INSTANCE; &#125;&#125; ThreadLoocal 式单例123456789101112131415public class ThreadLocalSingleton &#123; private static final ThreadLocal&lt;ThreadLocalSingleton&gt; threadLocaLInstance = new ThreadLocal&lt;ThreadLocalSingleton&gt;()&#123; @Override protected ThreadLocalSingleton initialValue() &#123; return new ThreadLocalSingleton(); &#125; &#125;; private ThreadLocalSingleton()&#123;&#125; public static ThreadLocalSingleton getInstance()&#123; return threadLocaLInstance.get(); &#125;&#125;","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"创建型设计模式","slug":"创建型设计模式","permalink":"https://pdyun.cc/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"工厂模式","slug":"工厂模式","date":"2022-02-10T09:42:00.000Z","updated":"2022-02-10T10:05:34.546Z","comments":true,"path":"2022/02/10/工厂模式/","link":"","permalink":"https://pdyun.cc/2022/02/10/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"一. 类型创建型模式 二. 意图定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。 三. 主要解决主要解决接口选择的问题。 四. 工厂模式多种写法 简单工厂(静态工厂) 工厂方法 抽象工厂","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"创建型设计模式","slug":"创建型设计模式","permalink":"https://pdyun.cc/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"Peilin Deng"},{"title":"最大公约数","slug":"最大公约数","date":"2022-02-08T07:52:00.000Z","updated":"2022-02-08T08:04:31.596Z","comments":true,"path":"2022/02/08/最大公约数/","link":"","permalink":"https://pdyun.cc/2022/02/08/%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0/","excerpt":"","text":"更相减损术更相减损术 出自中国古代 ‘九章算术’, 是一种最大公约数的算法. 他的原理简单: 两个正整数a和b(a&gt;b), 他们的最大公约数等于a-b的差值c和较小数b之间的最大公约数. 12345678910111213/** * 更相减损术 * * @return 最大公约数 */public static int getGreatestCommonDivisorV1(int a, int b) &#123; if (a == b) &#123; return a; &#125; int big = Math.max(a, b); int small = Math.min(a, b); return getGreatestCommonDivisorV2(big - small, small); &#125; 辗转相除法辗转相除法, 又名欧几里得算法, 该算法目的是求出两个正整数的最大公约数. 该算法基于一个定理: 两个正整数a和b(a&gt;b), 他们的最大公约数等于a除以b的余数c和b之间的最大公约数. 12345678910111213/** * 辗转相除法 (欧几里得算法) * * @return 最大公约数 */public static int getGreatestCommonDivisorV2(int a, int b) &#123; int big = Math.max(a, b); int small = Math.min(a, b); if (big % small == 0) &#123; return small; &#125; return getGreatestCommonDivisorV2(big % small, small);&#125;","categories":[],"tags":[],"author":"Peilin Deng"},{"title":"加一","slug":"加一","date":"2022-01-15T11:15:00.000Z","updated":"2022-01-15T11:19:01.588Z","comments":true,"path":"2022/01/15/加一/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E5%8A%A0%E4%B8%80/","excerpt":"","text":"1234567891011121314151617181920212223给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。你可以假设除了整数 0 之外，这个整数不会以零开头。示例 1：输入：digits = [1,2,3]输出：[1,2,4]解释：输入数组表示数字 123。示例 2：输入：digits = [4,3,2,1]输出：[4,3,2,2]解释：输入数组表示数字 4321。示例 3：输入：digits = [0]输出：[1]示例 4：输入：digits = [9,9,9]输出：[1,0,0,0] 1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) &#123; int[] arr = new int[]&#123;9, 9, 9, 9&#125;; System.out.println(&quot;数组加一前: &quot; + Arrays.toString(arr)); arr = plusOne(arr); System.out.println(&quot;数组加一后: &quot; + Arrays.toString(arr));&#125;---------------------------------------------------------------执行结果数组加一前: [9, 9, 9, 9]数组加一后: [1, 0, 0, 0, 0]---------------------------------------------------------------private static int[] plusOne(int[] digits) &#123; boolean isAddLength = false; for (int i = digits.length-1; i &gt;=0 ; i--) &#123; int temp = digits[i] + 1; if (temp % 10 == 0) &#123; if (i == 0)&#123; isAddLength = true; &#125; digits[i] = 0; continue; &#125; digits[i] = temp; break; &#125; if (isAddLength)&#123; digits = new int[digits.length+1]; digits[0] = 1; &#125; return digits;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[],"author":"Peilin Deng"},{"title":"数组 - 旋转数组","slug":"数组-旋转数组","date":"2022-01-15T10:47:00.000Z","updated":"2022-01-15T10:51:35.033Z","comments":true,"path":"2022/01/15/数组-旋转数组/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E6%95%B0%E7%BB%84-%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84/","excerpt":"","text":"旋转数组给你一个数组，将数组中的元素向右轮转 k 个位置，其中 k 是非负数。 12345678910111213141516171819示例 1:输入: nums = [1,2,3,4,5,6,7], k = 3输出: [5,6,7,1,2,3,4]解释:向右轮转 1 步: [7,1,2,3,4,5,6]向右轮转 2 步: [6,7,1,2,3,4,5]向右轮转 3 步: [5,6,7,1,2,3,4]示例 2:输入：nums = [-1,-100,3,99], k = 2输出：[3,99,-1,-100]解释: 向右轮转 1 步: [99,-1,-100,3]向右轮转 2 步: [3,99,-1,-100]进阶：尽可能想出更多的解决方案，至少有 三种 不同的方法可以解决这个问题。你可以使用空间复杂度为 O(1) 的 原地 算法解决这个问题吗？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static void main(String[] args) &#123; int k = 3; int[] arr = new int[]&#123;6, 4, 3, 2, 1, 9, 5, 7, 8, 10&#125;; System.out.println(&quot;数组旋转前: &quot; + Arrays.toString(arr)); rotate(arr, k); System.out.println(&quot;数组旋&quot; + k + &quot;个位置后: &quot; + Arrays.toString(arr));&#125;---------------------------------------------------------------- 执行结果数组旋转前: [6, 4, 3, 2, 1, 9, 5, 7, 8, 10]数组旋3个位置后: [7, 8, 10, 6, 4, 3, 2, 1, 9, 5] ----------------------------------------------------------------/** * 方法一 */private static void rotate(int[] nums, int k) &#123; k = k % nums.length; int[] new1 = Arrays.copyOfRange(nums, nums.length-k, nums.length); System.arraycopy(nums, 0, nums, k, nums.length - k); System.arraycopy(new1, 0, nums, 0, k);&#125;/** * 方法二 */private static void rotate2(int[] nums, int k) &#123; k = k % nums.length; int temp = nums[0]; boolean flag = true; for (int i = k - 1; i &gt;= 0; i--) &#123; for (int j = nums.length - 1; j &gt; 0; j--) &#123; if (flag) &#123; temp = nums[j]; flag = false; &#125; nums[j] = nums[j - 1]; &#125; nums[0] = temp; flag = true; &#125;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"计数排序","slug":"计数排序","date":"2022-01-15T07:55:00.000Z","updated":"2022-01-15T08:22:02.350Z","comments":true,"path":"2022/01/15/计数排序/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F/","excerpt":"","text":"当数列最大和最小差距过大时, 并不适用计数排序 12例如给出20个随机整数, 范围在0-1亿之间, 这时如果使用计数排序, 需要创建长度为1亿的数组. 不但严重浪费空间, 而且时间复杂度也会随之升高. 当数列元素不是整数时, 不适用计数排序 12如果数列中的元素都是小树, 如25.213, 或是0.0000000001这样的数字, 则无法创建对应的统计数组. 这样显然无法进行计数排序. 示例代码 1234567891011121314151617181920212223242526272829303132333435363738394041public static void main(String[] args) &#123; int[] arr = new int[]&#123;6, 4, 3, 2, 1, 9, 5, 7, 8, 10&#125;; int[] resultArr = countSort(arr); System.out.println(&quot;数组一排序: &quot; + Arrays.toString(resultArr)); arr = new int[]&#123;80, 89, 87, 82, 81, 88, 85, 84, 83, 86&#125;; int[] resultArr2 = countSort(arr); System.out.println(&quot;数组二排序: &quot; + Arrays.toString(resultArr2));&#125;-----------------------------------------------------------------数组一排序: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]数组二排序: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89]-----------------------------------------------------------------public static int[] countSort(int[] nums) &#123; // 得到数列最大/最小值 int max = nums[0]; int min = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; max = Math.max(nums[i], max); min = Math.min(nums[i], min); &#125; // 根据数列最大值和最小值确定计数数组长度 int[] countArr = new int[max - min + 1]; // 遍历数列, 填充统计长度 for (int num : nums) &#123; countArr[num - min]++; &#125; // 遍历统计数组, 输出结果 int index = 0; int[] sortArr = new int[nums.length]; for (int i = 0; i &lt; countArr.length; i++) &#123; for (int j = 0; j &lt; countArr[i]; j++) &#123; sortArr[index++] = i + min; &#125; &#125; return sortArr;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://pdyun.cc/tags/%E6%8E%92%E5%BA%8F/"},{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"二叉树遍历","slug":"二叉树遍历","date":"2022-01-15T06:31:00.000Z","updated":"2022-01-15T06:39:43.935Z","comments":true,"path":"2022/01/15/二叉树遍历/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/","excerpt":"","text":"递归遍历 (前序、中序、后序遍历)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 前序遍历 */public static void preOrder(TreeNode node) &#123; if (Objects.isNull(node)) &#123; return; &#125; System.out.print(node.data + &quot; &quot;); preOrder(node.leftChild); preOrder(node.rightChild);&#125;/** * 中序遍历 */public static void inOrder(TreeNode node) &#123; if (Objects.isNull(node)) &#123; return; &#125; inOrder(node.leftChild); System.out.print(node.data + &quot; &quot;); inOrder(node.rightChild);&#125;/** * 后序遍历 */public static void postOrder(TreeNode node) &#123; if (Objects.isNull(node)) &#123; return; &#125; postOrder(node.leftChild); postOrder(node.rightChild); System.out.print(node.data + &quot; &quot;);&#125;/** * 测试案例 */public static void main(String[] args) &#123; LinkedList&lt;Integer&gt; datas = new LinkedList&lt;&gt;(Arrays.asList(3,2,9,null,null,10,null,null,8,null,4)); TreeNode treeNode = TreeNode.createTreeNode(datas); System.out.println(&quot;前序遍历&quot;); preOrder(treeNode); System.out.println(); System.out.println(&quot;中序遍历&quot;); inOrder(treeNode); System.out.println(); System.out.println(&quot;后序遍历&quot;); postOrder(treeNode);&#125; 打印结果 12345678前序遍历3 2 9 10 8 4 中序遍历9 2 10 3 8 4 后序遍历9 10 2 4 8 3 非递归遍历 (层序遍历)123456789101112131415161718192021222324252627/** * 层序遍历 */public static void stackOrder(TreeNode treeNode) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(treeNode); while (!queue.isEmpty()) &#123; TreeNode poll = queue.poll(); System.out.print(poll.data + &quot; &quot;); if (poll.leftChild != null) &#123; queue.add(poll.leftChild); &#125; if (poll.rightChild != null) &#123; queue.add(poll.rightChild); &#125; &#125;&#125;public static void main(String[] args)&#123; LinkedList&lt;Integer&gt; datas = new LinkedList&lt;&gt;(Arrays.asList(1,2,4,null,null,5,null,null,3,null,6)); TreeNode treeNode = TreeNode.createTreeNode(datas); System.out.println(&quot;层序遍历: &quot;); stackOrder(treeNode);&#125; 打印结果 12层序遍历: 1 2 3 4 5 6","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"},{"name":"数据结构","slug":"算法小抄/数据结构","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://pdyun.cc/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"https://pdyun.cc/tags/%E9%93%BE%E8%A1%A8/"}],"author":"Peilin Deng"},{"title":"冒泡排序","slug":"冒泡排序","date":"2022-01-15T06:18:00.000Z","updated":"2022-01-15T06:27:22.071Z","comments":true,"path":"2022/01/15/冒泡排序/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","excerpt":"","text":"冒泡排序优化版 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 public static void main(String[] args) &#123; int[] arr = new int[]&#123;0, 6, 4, 3, 2, 1, 9, 5, 7, 8&#125;; sort(arr); System.out.println(&quot;第一次: &quot; + Arrays.toString(arr)); arr = new int[]&#123;6, 4, 3, 2, 1, 5, 0, 7, 8, 9&#125;; sort2(arr); System.out.println(&quot;第二次: &quot; + Arrays.toString(arr)); &#125; ------------------------------------------------------------ 打印结果 第一次: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 第二次: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ------------------------------------------------------------Process finished with exit code 0 public static void sort(int[] nums) &#123; boolean isSort = true; for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = 0; j &lt; nums.length - i - 1; j++) &#123; if (nums[j] &gt; nums[j + 1]) &#123; int a = nums[j + 1]; nums[j + 1] = nums[j]; nums[j] = a; isSort = false; &#125; &#125; if (isSort) &#123; break; &#125; &#125; &#125; public static void sort2(int[] nums) &#123; int lastChangeIndex = 0; int sortBorder = nums.length - 1; boolean isSort = true; for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = 0; j &lt; sortBorder; j++) &#123; if (nums[j] &gt; nums[j + 1]) &#123; int a = nums[j + 1]; nums[j + 1] = nums[j]; nums[j] = a; isSort = false; lastChangeIndex = j; &#125; &#125; sortBorder = lastChangeIndex; if (isSort) &#123; break; &#125; &#125; &#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://pdyun.cc/tags/%E6%8E%92%E5%BA%8F/"}],"author":"Peilin Deng"},{"title":"优先队列","slug":"优先队列","date":"2022-01-15T03:38:00.000Z","updated":"2022-01-15T04:09:26.986Z","comments":true,"path":"2022/01/15/优先队列/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/","excerpt":"","text":"以下代码基于最小堆实现的最小优先队列 二叉堆实现参见 –&gt; 二叉堆、堆排序 自定义实现优先队列1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * @ClassName 最小优先队列 * @Description 基于最小堆堆实现的优先队列 * @Author Deng PeiLin * @Date 2022/1/13 15:47 **/public class 优先队列 &#123; private int[] arr; private int size; public 优先队列 () &#123; this.arr = new int[1]; &#125; /** * 入队 */ public 优先队列 add(int data)&#123; if (size &gt;= arr.length) &#123; resize(); &#125; arr[size ++] = data; upAdjust(); return this; &#125; /** * 出队 */ public int out()&#123; if (size &lt;= 0)&#123; throw new RuntimeException(&quot;队列中无数据&quot;); &#125; int firstData = arr[0]; arr[0] = arr[--size]; downAdjust(); return firstData; &#125; /** * 上浮调整 */ private void upAdjust() &#123; int childIndex = size - 1; int parentIndex = (childIndex - 1) / 2; // temp 用于保存插入的叶子节点值, 用于最后的赋值 int temp = arr[childIndex]; while (childIndex &gt; 0 &amp;&amp; temp &lt; arr[parentIndex]) &#123; // 无需真正交换, 单项赋值即可 arr[childIndex] = arr[parentIndex]; childIndex = parentIndex; parentIndex = (parentIndex - 1) / 2; &#125; arr[childIndex] = temp; &#125; /** * 下沉调整 */ private void downAdjust() &#123; int parentIndex = 0; // temp 用于保存插入的叶子节点值, 用于最后的赋值 int temp = arr[parentIndex]; int childIndex = parentIndex * 2 + 1; while (childIndex &lt; size) &#123; // 如果有右节点, 且右节点小于左节点的值, 则定位到右节点 if (childIndex + 1 &lt; size &amp;&amp; arr[childIndex + 1] &lt; arr[childIndex]) &#123; childIndex++; &#125; // 如果父节点小于子节点的值则跳出, 不需要调整 if (temp &lt; arr[childIndex]) &#123; break; &#125; arr[parentIndex] = arr[childIndex]; parentIndex = childIndex; childIndex = childIndex * 2 + 1; &#125; arr[parentIndex] = temp; &#125; private void resize() &#123; arr = Arrays.copyOf(arr, size * 2); &#125; public int getSize() &#123; return size; &#125; @Override public String toString() &#123; return Arrays.toString(Arrays.copyOfRange(arr, 0, size)); &#125;&#125; 测试代码12345678910111213141516public static void main(String[] args)&#123; 优先队列 queue = new 优先队列(); queue.add(5).add(8).add(9).add(11).add(999).add(1); System.out.println(&quot;队列数据: &quot; + queue); int out = queue.out(); System.out.println(&quot;出队元素: &quot; + out); System.out.println(&quot;队列数据: &quot; + queue); int out2 = queue.out(); System.out.println(&quot;出队元素: &quot; + out2); System.out.println(&quot;队列数据: &quot; + queue); &#125; 测试结果 &gt;&gt;&gt; 以最小堆实现的最小优先队列, 队列头部皆为最小数据 1234567队列数据: [1, 8, 5, 11, 999, 9]出队元素: 1队列数据: [5, 8, 9, 11, 999]出队元素: 5队列数据: [8, 11, 9, 999]Process finished with exit code 0","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"队列","slug":"队列","permalink":"https://pdyun.cc/tags/%E9%98%9F%E5%88%97/"},{"name":"二叉堆","slug":"二叉堆","permalink":"https://pdyun.cc/tags/%E4%BA%8C%E5%8F%89%E5%A0%86/"}],"author":"Peilin Deng"},{"title":"二叉堆、堆排序","slug":"排序-堆排序","date":"2022-01-15T03:14:00.000Z","updated":"2022-01-15T04:13:04.791Z","comments":true,"path":"2022/01/15/排序-堆排序/","link":"","permalink":"https://pdyun.cc/2022/01/15/%E6%8E%92%E5%BA%8F-%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"二叉堆实现以下为最小堆代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * 用例适用于 &#x27;最小堆&#x27; */public class 二叉堆 &#123; public static void main(String[] args) &#123; int[] arr = new int[]&#123;1, 3, 2, 6, 5, 7, 8, 9, 10, 0&#125;; upAdjust(arr); System.out.println(Arrays.toString(arr)); arr = new int[]&#123;9, 6, 7, 11, 66, 5, 2, 3, 1, 0&#125;; build(arr); System.out.println(Arrays.toString(arr)); &#125; ------------------------------------------------------------ 打印结果 [0, 1, 2, 6, 3, 7, 8, 9, 10, 5] [0, 1, 2, 3, 6, 5, 7, 9, 11, 66] ------------------------------------------------------------ /** * 上浮调整 */ public static void upAdjust(int[] arr) &#123; int childIndex = arr.length - 1; int parentIndex = (childIndex - 1) / 2; // temp 用于保存插入的叶子节点值, 用于最后的赋值 int temp = arr[childIndex]; while (childIndex &gt; 0 &amp;&amp; temp &lt; arr[parentIndex]) &#123; // 无需真正交换, 单项赋值即可 arr[childIndex] = arr[parentIndex]; childIndex = parentIndex; parentIndex = (parentIndex - 1) / 2; &#125; arr[childIndex] = temp; &#125; /** * 下沉调整 * * @param arr 要调整的堆 * @param parentIndex 要 &#x27;下沉&#x27; 的父节点 * @param length 堆的有效大小 */ public static void downAdjust(int[] arr, int parentIndex, int length) &#123; // temp 用于保存插入的叶子节点值, 用于最后的赋值 int temp = arr[parentIndex]; int childIndex = parentIndex * 2 + 1; while (childIndex &lt; length) &#123; // 如果有右节点, 且右节点小于左节点的值, 则定位到右节点 if (childIndex + 1 &lt; length &amp;&amp; arr[childIndex + 1] &lt; arr[childIndex]) &#123; childIndex++; &#125; // 如果父节点小于子节点的值则跳出, 不需要调整 if (temp &lt; arr[childIndex]) &#123; break; &#125; arr[parentIndex] = arr[childIndex]; parentIndex = childIndex; childIndex = childIndex * 2 + 1; &#125; arr[parentIndex] = temp; &#125; /** * 构建二叉堆 * &lt;p&gt; * 二叉堆本质上是完全二叉树, 但是存储方式不是链式存储, 而是顺序存储, 所用数据结构为数组 */ public static void build(int[] arr) &#123; // 从最后一个非叶子节点开始, 依次做&#x27;下沉&#x27;调整 for (int i = (arr.length - 2) / 2; i &gt;= 0; i--) &#123; downAdjust(arr, i, arr.length); &#125; &#125;&#125; 堆排序1234567891011121314151617181920212223public class 堆排序 &#123; public static void main(String[] args) &#123; int[] arr = new int[]&#123;1, 3, 2, 6, 5, 7, 8, 9, 10, 0&#125;; sort(arr); &#125; public static void sort(int[] arr) &#123; 二叉堆.build(arr); System.out.println(Arrays.toString(arr)); for (int i = arr.length - 1; i &gt;= 0; i--) &#123; // 最后一个元素和第一个元素交换 int temp = arr[0]; arr[0] = arr[i]; arr[i] = temp; 二叉堆.downAdjust(arr,0,i); System.out.println(Arrays.toString(arr)); &#125; &#125;&#125; 排序结果 1234567891011[0, 1, 2, 6, 3, 7, 8, 9, 10, 5][1, 3, 2, 6, 5, 7, 8, 9, 10, 0][2, 3, 7, 6, 5, 10, 8, 9, 1, 0][3, 5, 7, 6, 9, 10, 8, 2, 1, 0][5, 6, 7, 8, 9, 10, 3, 2, 1, 0][6, 8, 7, 10, 9, 5, 3, 2, 1, 0][7, 8, 9, 10, 6, 5, 3, 2, 1, 0][8, 10, 9, 7, 6, 5, 3, 2, 1, 0][9, 10, 8, 7, 6, 5, 3, 2, 1, 0][10, 9, 8, 7, 6, 5, 3, 2, 1, 0][10, 9, 8, 7, 6, 5, 3, 2, 1, 0]","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"},{"name":"数据结构","slug":"算法小抄/数据结构","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"二叉堆","slug":"二叉堆","permalink":"https://pdyun.cc/tags/%E4%BA%8C%E5%8F%89%E5%A0%86/"},{"name":"排序","slug":"排序","permalink":"https://pdyun.cc/tags/%E6%8E%92%E5%BA%8F/"},{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"数组 - 移动零","slug":"数组-移动零","date":"2022-01-14T03:01:00.000Z","updated":"2022-01-14T03:05:28.566Z","comments":true,"path":"2022/01/14/数组-移动零/","link":"","permalink":"https://pdyun.cc/2022/01/14/%E6%95%B0%E7%BB%84-%E7%A7%BB%E5%8A%A8%E9%9B%B6/","excerpt":"","text":"移动零给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。 示例: 输入: [0,1,0,3,12]输出: [1,3,12,0,0] 说明: 必须在原数组上操作，不能拷贝额外的数组。尽量减少操作次数。 1234567891011121314151617class Solution &#123; public void moveZeroes(int[] nums) &#123; if (nums == null || nums.length &lt;= 0) &#123; return; &#125; int index = 0; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] != 0) &#123; nums[index++] = nums[i]; &#125; &#125; while (index &lt; nums.length)&#123; nums[index++] = 0; &#125; &#125;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"数组 - 两个数组的交集 II","slug":"数组-两个数组的交集-II","date":"2022-01-14T02:58:00.000Z","updated":"2022-01-14T03:00:52.150Z","comments":true,"path":"2022/01/14/数组-两个数组的交集-II/","link":"","permalink":"https://pdyun.cc/2022/01/14/%E6%95%B0%E7%BB%84-%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86-II/","excerpt":"","text":"两个数组的交集 II给你两个整数数组 nums1 和 nums2 ，请你以数组形式返回两数组的交集。返回结果中每个元素出现的次数，应与元素在两个数组中都出现的次数一致（如果出现次数不一致，则考虑取较小值）。可以不考虑输出结果的顺序。 示例 1： 输入：nums1 = [1,2,2,1], nums2 = [2,2]输出：[2,2]示例 2: 输入：nums1 = [4,9,5], nums2 = [9,4,9,8,4]输出：[4,9] 提示： 1 &lt;= nums1.length, nums2.length &lt;= 10000 &lt;= nums1[i], nums2[i] &lt;= 1000 进阶： 如果给定的数组已经排好序呢？你将如何优化你的算法？如果 nums1 的大小比 nums2 小，哪种方法更优？如果 nums2 的元素存储在磁盘上，内存是有限的，并且你不能一次加载所有的元素到内存中，你该怎么办？ 1234567891011121314151617181920212223class Solution &#123; public int[] intersect(int[] arr1, int[] arr2) &#123; Arrays.sort(arr1); Arrays.sort(arr2); int arr1Len = arr1.length, arr2Len = arr2.length; int len = Math.min(arr1Len, arr2Len); int[] newInt = new int[len]; int i = 0, j = 0, k = 0; while (i &lt; arr1Len &amp;&amp; j &lt; arr2Len) &#123; if (arr1[i] == arr2[j]) &#123; newInt[k++] = arr1[i]; i++; j++; &#125; else if (arr1[i] &lt; arr2[j]) &#123; i++; &#125; else &#123; j++; &#125; &#125; return Arrays.copyOfRange(newInt, 0, k); &#125;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"数组 - 只出现一次的数字","slug":"数组-只出现一次的数字","date":"2022-01-14T02:49:00.000Z","updated":"2022-01-14T02:51:16.586Z","comments":true,"path":"2022/01/14/数组-只出现一次的数字/","link":"","permalink":"https://pdyun.cc/2022/01/14/%E6%95%B0%E7%BB%84-%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97/","excerpt":"","text":"只出现一次的数字给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 说明： 你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？ 示例 1: 输入: [2,2,1]输出: 1示例 2: 输入: [4,1,2,1,2]输出: 4 123456789class Solution &#123; public int singleNumber(int[] nums) &#123; int a = 0; for (int num: nums)&#123; a = num ^ a; &#125; return a; &#125;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"},{"name":"位运算","slug":"位运算","permalink":"https://pdyun.cc/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"}],"author":"Peilin Deng"},{"title":"数组 - 是否存在重复元素","slug":"数组-是否存在重复元素","date":"2022-01-14T02:46:00.000Z","updated":"2022-01-14T02:54:17.350Z","comments":true,"path":"2022/01/14/数组-是否存在重复元素/","link":"","permalink":"https://pdyun.cc/2022/01/14/%E6%95%B0%E7%BB%84-%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0/","excerpt":"","text":"存在重复元素给定一个整数数组，判断是否存在重复元素。 如果存在一值在数组中出现至少两次，函数返回 true 。如果数组中每个元素都不相同，则返回 false 。 示例 1: 输入: [1,2,3,1]输出: true示例 2: 输入: [1,2,3,4]输出: false示例 3: 输入: [1,1,1,3,3,4,3,2,4,2]输出: true 123456789101112class Solution &#123; public boolean containsDuplicate(int[] nums) &#123; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int num : nums) &#123; //因为集合set中不能有重复的元素，如果有重复的 //元素添加，就会添加失败 if (!set.add(num)) return true; &#125; return false; &#125;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"数组 - 删除排序数组中的重复项","slug":"数组-删除排序数组中的重复项","date":"2022-01-14T02:36:00.000Z","updated":"2022-01-14T02:54:53.766Z","comments":true,"path":"2022/01/14/数组-删除排序数组中的重复项/","link":"","permalink":"https://pdyun.cc/2022/01/14/%E6%95%B0%E7%BB%84-%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/","excerpt":"","text":"删除排序数组中的重复项给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。 不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。 12345678910111213class Solution &#123; public int removeDuplicates(int[] nums) &#123; if (nums.length == 0) return 0; int index = 0; for (int i = 1; i &lt; nums.length; i++) &#123; if (nums[index6] != nums[i]) &#123; index ++; nums[index] = nums[i]; &#125; &#125; return index +1; &#125;&#125;","categories":[{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"}],"tags":[{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"}],"author":"Peilin Deng"},{"title":"Spring Boot自动装配","slug":"Spring-Boot自动装配","date":"2021-09-30T02:07:00.000Z","updated":"2021-09-30T06:31:30.673Z","comments":true,"path":"2021/09/30/Spring-Boot自动装配/","link":"","permalink":"https://pdyun.cc/2021/09/30/Spring-Boot%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D/","excerpt":"转载自: https://mrbird.cc/deepin-springboot-autoconfig.html 模式注解Stereotype Annotation俗称为模式注解，Spring中常见的模式注解有@Service，@Repository，@Controller等，它们都“派生”自@Component注解。我们都知道，凡是被@Component标注的类都会被Spring扫描并纳入到IOC容器中，那么由@Component派生的注解所标注的类也会被扫描到IOC容器中。下面我们主要通过自定义模式注解来了解@Component的“派生性”和“层次性”。","text":"转载自: https://mrbird.cc/deepin-springboot-autoconfig.html 模式注解Stereotype Annotation俗称为模式注解，Spring中常见的模式注解有@Service，@Repository，@Controller等，它们都“派生”自@Component注解。我们都知道，凡是被@Component标注的类都会被Spring扫描并纳入到IOC容器中，那么由@Component派生的注解所标注的类也会被扫描到IOC容器中。下面我们主要通过自定义模式注解来了解@Component的“派生性”和“层次性”。 @Component “派生性”新建一个Spring Boot工程，Spring Boot版本为2.1.0.RELEASE，artifactId为autoconfig，并引入spring-boot-starter-web依赖。项目结构如下所示: 在com.example.demo下新建annotation包，然后创建一个FirstLevelService注解： 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Servicepublic @interface FirstLevelService &#123; String value() default &quot;&quot;;&#125; 这个注解定义由@Service标注，查看@Service的源码会发现其被@Component注解标注，所以它们的层次关系为: 123└─@Component └─@Service └─@FirstLevelService 即@FirstLevelService为@Component派生出来的模式注解，我们来测试一下被它标注的类是否能够被扫描到IOC容器中： 在com.example.demo下新建service包，然后创建一个TestService类： 123@FirstLevelServicepublic class TestService &#123;&#125; 在com.example.demo下新建bootstrap包，然后创建一个ServiceBootStrap类，用于测试注册TestService并从IOC容器中获取它： 123456789101112@ComponentScan(&quot;com.example.demo.service&quot;)public class ServiceBootstrap &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new SpringApplicationBuilder(ServiceBootstrap.class) .web(WebApplicationType.NONE) .run(args); TestService testService = context.getBean(&quot;testService&quot;, TestService.class); System.out.println(&quot;TestService Bean: &quot; + testService); context.close(); &#125;&#125; 运行该类的main方法，控制台输出如下： @Component “层次性”我们在com.example.demo.annotation路径下再创建一个SecondLevelService注解定义，该注解由上面的@FirstLevelService标注： 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@FirstLevelServicepublic @interface SecondLevelService &#123; String value() default &quot;&quot;;&#125; 这时候层次关系为： 1234└─@Component └─@Service └─@FirstLevelService └─@SecondLevelService 我们将TestService上的注解换成@SecondLevelService，然后再次运行ServiceBootStrap的main方法，输出如下： 可见结果也是成功的 这里有一点需要注意的是：**@Component注解只包含一个value属性定义，所以其“派生”的注解也只能包含一个value属性定义。 ** @Enable模块驱动@Enable模块驱动在Spring Framework 3.1后开始支持。这里的模块通俗的来说就是一些为了实现某个功能的组件的集合。通过@Enable模块驱动，我们可以开启相应的模块功能。 @Enable模块驱动可以分为“注解驱动”和“接口编程”两种实现方式，下面逐一进行演示： 注解驱动Spring中，基于注解驱动的示例可以查看@EnableWebMvc源码： 123456@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Documented@Import(&#123;DelegatingWebMvcConfiguration.class&#125;)public @interface EnableWebMvc &#123;&#125; 该注解通过@Import导入一个配置类DelegatingWebMvcConfiguration： 该配置类又继承自WebMvcConfigurationSupport，里面定义了一些Bean的声明。 所以，基于注解驱动的@Enable模块驱动其实就是通过@Import来导入一个配置类，以此实现相应模块的组件注册，当这些组件注册到IOC容器中，这个模块对应的功能也就可以使用了。 ** 我们来定义一个基于注解驱动的@Enable模块驱动。 在com.example.demo下新建configuration包，然后创建一个HelloWorldConfiguration配置类： 12345678@Configurationpublic class HelloWorldConfiguration &#123; @Bean public String hello() &#123; return &quot;hello world&quot;; &#125;&#125; 这个配置类里定义了一个名为hello的Bean，内容为hello world。 在com.example.demo.annotation下创建一个EnableHelloWorld注解定义： 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(HelloWorldConfiguration.class)public @interface EnableHelloWorld &#123;&#125; 运行该类的main方法，控制台输出如下： 说明我们自定义的基于注解驱动的@EnableHelloWorld是可行的。 接口编程除了使用上面这个方式外，我们还可以通过接口编程的方式来实现@Enable模块驱动。Spring中，基于接口编程方式的有@EnableCaching注解，查看其源码： 1234567891011@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;CachingConfigurationSelector.class&#125;)public @interface EnableCaching &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default 2147483647;&#125; EnableCaching注解通过@Import导入了CachingConfigurationSelector类，该类间接实现了ImportSelector接口，在 深入学习Spring组件注册 中，我们曾介绍了可以通过ImportSelector来实现组件注册。 所以通过接口编程实现@Enable模块驱动的本质是：通过@Import来导入接口ImportSelector实现类，该实现类里可以定义需要注册到IOC容器中的组件，以此实现相应模块对应组件的注册。 接下来我们根据这个思路来自个实现一遍： 在com.example.demo下新建selector包，然后在该路径下新建一个HelloWorldImportSelector实现ImportSelector接口 123456public class HelloWorldImportSelector implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[]&#123;HelloWorldConfiguration.class.getName()&#125;; &#125;&#125; 如果看不懂上面这段代码含义的朋友可以阅读深入学习Spring组件注册一文。 接着我们修改 EnableHelloWorld： 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(HelloWorldImportSelector.class)public @interface EnableHelloWorld &#123;&#125; 上面导入的是HelloWorldImportSelector，而非HelloWorldConfiguration。 再次运行TestEnableBootstap的main方法，你会发现输出是一样的。 自动装配Spring Boot中的自动装配技术底层主要用到了下面这些技术: Spring 模式注解装配 Spring @Enable 模块装配 Spring 条件装配装（深入学习Spring组件注册中有介绍） Spring 工厂加载机制 Spring 工厂加载机制的实现类为SpringFactoriesLoader，查看其源码： 该类的方法会读取META-INF目录下的spring.factories配置文件，我们查看spring-boot-autoconfigure-2.1.0.RELEASE.jar下的该文件： 当启动类被@EnableAutoConfiguration标注后，上面截图中的所有类Spring都会去扫描，看是否可以纳入到IOC容器中进行管理。 比如我们查看org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration的源码： 可看到该类上标注了一些注解，其中@Configuration为模式注解，@EnableConfigurationProperties为模块装配技术，ConditionalOnClass为条件装配技术。这和我们上面列出的Spring Boot自动装配底层主要技术一致，所以我们可以根据这个思路来自定义一个自动装配实现。 新建一个配置类HelloWorldAutoConfiguration： 12345@Configuration@EnableHelloWorld@ConditionalOnProperty(name = &quot;helloworld&quot;, havingValue = &quot;true&quot;)public class HelloWorldAutoConfiguration &#123; &#125; 然后在resources目录下新建META-INF目录，并创建spring.factories文件： 123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.example.demo.configuration.HelloWorldAutoConfiguration 接着在配置文件application.properties中添加helloworld=true配置 1helloworld=true 最后创建EnableAutoConfigurationBootstrap，测试下HelloWorldAutoConfiguration是否生效： 123456789101112@EnableAutoConfigurationpublic class EnableAutoConfigurationBootstrap &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new SpringApplicationBuilder(EnableAutoConfigurationBootstrap.class) .web(WebApplicationType.NONE) .run(args); String hello = context.getBean(&quot;hello&quot;, String.class); System.out.println(&quot;hello Bean: &quot; + hello); context.close(); &#125;&#125; 运行该main方法，控制台输出如下： 说明我们自定义的自动装配已经成功了。 下面简要分析下代码的运行逻辑： Spring 的工厂加载机制会自动读取META-INF目录下spring.factories文件内容； 我们在spring.factories定义了： 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.example.demo.configuration.HelloWorldAutoConfiguration 我们在测试类上使用了@EnableAutoConfiguration注解标注，那么HelloWorldAutoConfiguration就会被Spring扫描，看是否符合要求，如果符合则纳入到IOC容器中； HelloWorldAutoConfiguration上的@ConditionalOnProperty的注解作用为：当配置文件中配置了helloworld=true（我们确实添加了这个配置，所以符合要求）则这个类符合扫描规则；@EnableHelloWorld注解是我们前面例子中自定义的模块驱动注解，其引入了hello这个Bean，所以IOC容器中便会存在hello这个Bean了； 通过上面的步骤，我们就可以通过上下文获取到hello这个Bean了。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://pdyun.cc/tags/SpringBoot/"}],"author":"Peilin Deng"},{"title":"Mysql 数据库事务隔离级别","slug":"Mysql-数据库事务隔离级别","date":"2021-08-27T03:03:00.000Z","updated":"2021-08-30T02:46:09.547Z","comments":true,"path":"2021/08/27/Mysql-数据库事务隔离级别/","link":"","permalink":"https://pdyun.cc/2021/08/27/Mysql-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","excerpt":"[Mysql] —— 通过例子理解事务的4种隔离级别 第1级别：Read Uncommitted(读取未提交内容) 第2级别：Read Committed(读取提交内容) 第3级别：Repeatable Read(可重读) 第4级别：Serializable(可串行化) SQL标准定义了4种隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。 低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。 首先，我们使用 test 数据库，新建 tx 表，并且如图所示打开两个窗口来操作同一个数据库： 第1级别：Read Uncommitted(读取未提交内容)(1)所有事务都可以看到其他未提交事务的执行结果","text":"[Mysql] —— 通过例子理解事务的4种隔离级别 第1级别：Read Uncommitted(读取未提交内容) 第2级别：Read Committed(读取提交内容) 第3级别：Repeatable Read(可重读) 第4级别：Serializable(可串行化) SQL标准定义了4种隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。 低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。 首先，我们使用 test 数据库，新建 tx 表，并且如图所示打开两个窗口来操作同一个数据库： 第1级别：Read Uncommitted(读取未提交内容)(1)所有事务都可以看到其他未提交事务的执行结果 (2)本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少 (3)该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#首先，修改隔离级别set tx_isolation=&#x27;READ-UNCOMMITTED&#x27;; select @@tx_isolation;# mysql 8.0 使用:# set transaction_isolation=&#x27;READ-UNCOMMITTED&#x27;;# select @@transaction_isolation;+------------------+| @@tx_isolation |+------------------+| READ-UNCOMMITTED |+------------------+#事务A：启动一个事务start transaction;select * from tx;+------+------+| id | num |+------+------+| 1 | 1 || 2 | 2 || 3 | 3 |+------+------+#事务B：也启动一个事务(那么两个事务交叉了) 在事务B中执行更新语句，且不提交start transaction;update tx set num=10 where id=1;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+#事务A：那么这时候事务A能看到这个更新了的数据吗?select * from tx;+------+------+| id | num |+------+------+| 1 | 10 | ---&gt;可以看到！说明我们读到了事务B还没有提交的数据| 2 | 2 || 3 | 3 |+------+------+#事务B：事务B回滚,仍然未提交rollback;select * from tx;+------+------+| id | num |+------+------+| 1 | 1 || 2 | 2 || 3 | 3 |+------+------+#事务A：在事务A里面看到的也是B没有提交的数据select * from tx;+------+------+| id | num |+------+------+| 1 | 1 | ---&gt;脏读意味着我在这个事务中(A中)，事务B虽然没有提交，但它任何一条数据变化，我都可以看到！| 2 | 2 || 3 | 3 |+------+------+ 第2级别：Read Committed(读取提交内容)(1)这是大多数数据库系统的默认隔离级别（但不是MySQL默认的） (2)它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变 (3)这种隔离级别出现的问题是——不可重复读(Nonrepeatable Read)：不可重复读意味着我们在同一个事务中执行完全相同的select语句时可能看到不一样的结果。 |——&gt;导致这种情况的原因可能有：(1)有一个交叉的事务有新的commit，导致了数据的改变;(2)一个数据库被多个实例操作时,同一事务的其他实例在该实例处理其间可能会有新的commit 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#首先修改隔离级别set tx_isolation=&#x27;read-committed&#x27;;select @@tx_isolation;# mysql 8.0 使用:# set transaction_isolation=&#x27;read-committed&#x27;;# select @@transaction_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+#事务A：启动一个事务start transaction;select * from tx;+------+------+| id | num |+------+------+| 1 | 1 || 2 | 2 || 3 | 3 |+------+------+#事务B：也启动一个事务(那么两个事务交叉了) 在这事务中更新数据，且未提交start transaction;update tx set num=10 where id=1;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+#事务A：这个时候我们在事务A中能看到数据的变化吗?select * from tx; ---------------&gt;+------+------+ || id | num | |+------+------+ || 1 | 1 |---&gt;并不能看到！ || 2 | 2 | || 3 | 3 | |+------+------+ |——&gt;相同的select语句，结果却不一样 |#事务B：如果提交了事务B呢? |commit; | |#事务A: |select * from tx; ---------------&gt;+------+------+| id | num |+------+------+| 1 | 10 |---&gt;因为事务B已经提交了，所以在A中我们看到了数据变化| 2 | 2 || 3 | 3 |+------+------+ 第3级别：Repeatable Read(可重读)(1)这是MySQL的默认事务隔离级别 (2)它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行 (3)此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行 (4)InnoDB和Falcon存储引擎通过多版本并发控制(MVCC，Multiversion Concurrency Control)机制解决了该问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#首先，更改隔离级别set tx_isolation=&#x27;repeatable-read&#x27;;select @@tx_isolation;# mysql 8.0 使用:# set transaction_isolation=&#x27;repeatable-read&#x27;;# select @@transaction_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+#事务A：启动一个事务start transaction;select * from tx;+------+------+| id | num |+------+------+| 1 | 1 || 2 | 2 || 3 | 3 |+------+------+#事务B：开启一个新事务(那么这两个事务交叉了) 在事务B中更新数据，并提交start transaction;update tx set num=10 where id=1;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+commit;#事务A：这时候即使事务B已经提交了,但A能不能看到数据变化？select * from tx;+------+------+| id | num |+------+------+| 1 | 1 | ---&gt;还是看不到的！(这个级别2不一样，也说明级别3解决了不可重复读问题)| 2 | 2 || 3 | 3 |+------+------+#事务A：只有当事务A也提交了，它才能够看到数据变化commit;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+ 第4级别：Serializable(可串行化)(1)这是最高的隔离级别 (2)它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。 (3)在这个级别，可能导致大量的超时现象和锁竞争 123456789101112131415161718192021#首先修改隔离界别set tx_isolation=&#x27;serializable&#x27;;select @@tx_isolation;# mysql 8.0 使用:# set transaction_isolation=&#x27;serializable&#x27;;# select @@transaction_isolation;+----------------+| @@tx_isolation |+----------------+| SERIALIZABLE |+----------------+#事务A：开启一个新事务start transaction;#事务B：在A没有commit之前，这个交叉事务是不能更改数据的start transaction;insert tx values(&#x27;4&#x27;,&#x27;4&#x27;);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionupdate tx set num=10 where id=1;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"},{"name":"事务","slug":"事务","permalink":"https://pdyun.cc/tags/%E4%BA%8B%E5%8A%A1/"}],"author":"Peilin Deng"},{"title":"MySql 执行计划","slug":"MySql-执行计划","date":"2021-08-25T14:00:18.000Z","updated":"2021-08-26T05:53:46.254Z","comments":true,"path":"2021/08/25/MySql-执行计划/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/","excerpt":"执行计划类型const直接通过聚簇索引或者二级索引+聚簇索引回源，查询到想要的数据。这种根据索引可以直接快速查询到数据的过程，在执行计划里称之为const。二级索引必须是unique，才是const。否则就是ref ref一般走索引都是ref，如果是组合索引，则要求查询条件必须是从索引最左侧开始连续多列都是等值比较。 range对索引列使用范围查询。 index只需要遍历二级索引就可以拿到想要的数据，而不需要回源到聚簇索引的访问方式。 索引： 1idx(S21,S22,S23,S24) SQL：1SELECT S21,S22,S23 FROM TABLE WHERE S22 = &#x27;X&#x27; AND S23 = &#x27;Z&#x27;; 第一反应：这个SQL无法直接从联合索引树的根节点进行二分查找。 基于上面的索引以及SQL，可以直接遍历联合索引树的叶子节点，找到所需要的数据，不需要再回源到聚簇索引进行二次查询，这种方式就是使用的index访问。 虽然遍历了叶子节点，但是叶子节点内容少。也比回表查询快。","text":"执行计划类型const直接通过聚簇索引或者二级索引+聚簇索引回源，查询到想要的数据。这种根据索引可以直接快速查询到数据的过程，在执行计划里称之为const。二级索引必须是unique，才是const。否则就是ref ref一般走索引都是ref，如果是组合索引，则要求查询条件必须是从索引最左侧开始连续多列都是等值比较。 range对索引列使用范围查询。 index只需要遍历二级索引就可以拿到想要的数据，而不需要回源到聚簇索引的访问方式。 索引： 1idx(S21,S22,S23,S24) SQL：1SELECT S21,S22,S23 FROM TABLE WHERE S22 = &#x27;X&#x27; AND S23 = &#x27;Z&#x27;; 第一反应：这个SQL无法直接从联合索引树的根节点进行二分查找。 基于上面的索引以及SQL，可以直接遍历联合索引树的叶子节点，找到所需要的数据，不需要再回源到聚簇索引进行二次查询，这种方式就是使用的index访问。 虽然遍历了叶子节点，但是叶子节点内容少。也比回表查询快。 什么情况下一次查询用到多个索引 现有索引：1idx(x1)，idx(x2); 现有SQL：1SELECT * FROM TABLE WHERE X1 = XX AND X2 = ZZ; 在一般情况下，查询优化器生成执行计划只会按照其中一个字段的索引树去查找，然后再回表到聚簇索引查完整数据，然后根据另一个字段的值过滤。 当按照某个索引值查询之后得到了上万条的数据，此时就要考虑再通过另一个索引查询，将两个索引得到的结果的主键进行求交集，然后再去回表查询。 多表关联的SQL语句的执行计划驱动表与被驱动表在多表关联查询时，一般是通过部分条件先从一张表中取出符合条件的数据，然后再在这些数据中进行后续的条件匹配。先查询的表叫做驱动表，后查询的表就叫被驱动表。 内连接与外连接 内连接：INNER JOIN，连接条件写在WHERE中，并且按照表与表之间的字段关系严格判断，为空的不会显示 外连接：[LEFT | RIGHT] OUTER JOIN，连接条件写在ON中；如果是LEFT则表示左侧表中的数据不管右侧表里是否有关联都会返回出来，右侧大不了显示为NULL。 嵌套循环关联多表关联查询，往往都是利用驱动表的结果，去被驱动表中通过where条件，on条件进行遍历匹配。因此如果关联表很多，就会因为遍历的效率影响整个SQL的执行效率，所以要合理的在驱动表和被驱动表上建立合适的索引。 执行成本的计算成本的组成 IO成本 CPU成本 计算方式12345671. MYSQL规定读取一页花费的成本默认是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。2. 不管读取到的记录需不需要检测是否符合搜索条件，其成本都是0.23. 通过show table status like &#x27;表名&#x27;，可以查看指定表的一些信息4. rows是表中的记录数（对于innodb来说这个是个估计值），data_length是聚簇索引的字节数大小。通过data_length/(1024*16)可以算出有多少页，就能算出全表扫描的成本。5. IO成本=数据页数量*1+1.16. CPU成本=行记录数*0.2+1.07. 总成本=IO成本+CPU成本 计算示例 123数据页数=(98304/1024)/16=6 行记录数=603 总成本=6*1+0.2*603=126.6 二级索引要注意的点 二级索引在计算时要先计算二级索引根据条件查一波数据的IO成本，比如score between 25,200 or score between 250,300，这是2个范围，否则score=XX就是一个区间。 一般一个区间可以简单的认为是一个数据页，也可能是n个数据页，反正是个位数级别的。 二级索引得到的结果再回表，一条数据回表一次。 a104","categories":[],"tags":[],"author":"Peilin Deng"},{"title":"MySql 关于索引的一些特殊情况","slug":"MySql-关于索引的一些特殊情况","date":"2021-08-25T13:59:00.000Z","updated":"2021-08-25T13:59:36.508Z","comments":true,"path":"2021/08/25/MySql-关于索引的一些特殊情况/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5/","excerpt":"","text":"范围查询数据量过大导致索引失效存在索引idx_fk_customer_id(customer_id)，表中数据16000条。 12EXPLAIN SELECT * FROM rental WHERE customer_id&lt;102; # 使用索引EXPLAIN SELECT * FROM rental WHERE customer_id&lt;103; # 全表扫描 当范围查询时，如果符合条件的数据过多时，因为建立索引的字段虽然在索引树上有序，但是这一部分数据还要回源到聚簇索引中再次查询，并且得到的数据在磁盘上并不是连续的，这样会产生大量的随机IO，而随机IO是非常慢的，与其这样还不如全表扫描。全表扫描最起码是顺序IO。 Semi join半连接 explain列中filtered为什么有时候不准 Extra列中Using index condition都是索引下推吗？","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 索引机制","slug":"MySql-索引机制","date":"2021-08-25T13:55:00.000Z","updated":"2021-08-25T13:55:41.870Z","comments":true,"path":"2021/08/25/MySql-索引机制/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E7%B4%A2%E5%BC%95%E6%9C%BA%E5%88%B6/","excerpt":"主键索引的设计每个数据页中都有一个页目录，可以方便在当前数据页中进行数据的查询。但是如果有多个数据页的情况下，对于一个主键的查询，得知数据在哪个数据页显得尤为重要。因此针对主键设计了一个主键目录，就是把每个数据页的页号以及数据页中最小的主键放在一起，组成一个索引的目录，如下图：基于主键目录，先通过主键目录可以对比得到查询的数据可能在哪个数据页，然后到对应的数据页中基于二分法查找。 索引页","text":"主键索引的设计每个数据页中都有一个页目录，可以方便在当前数据页中进行数据的查询。但是如果有多个数据页的情况下，对于一个主键的查询，得知数据在哪个数据页显得尤为重要。因此针对主键设计了一个主键目录，就是把每个数据页的页号以及数据页中最小的主键放在一起，组成一个索引的目录，如下图：基于主键目录，先通过主键目录可以对比得到查询的数据可能在哪个数据页，然后到对应的数据页中基于二分法查找。 索引页 概念当数据量超级大的时候，数据页的数量也非常的多。主键目录就得存放大量的数据页和最小主键值。性能没有得到突破。此时，通过索引页来存放索引数据。需要注意的是，索引页中，出现了类型为1的行数据。表示的是B+树非叶子节点。虽然索引页多了，但是又应该到哪个索引页中去查主键数据，此时又可以把索引页进行一次“索引”，在更高层的索引层级中，保存了每个索引页里的最小主键值和索引页号。（如果跟高层的索引层级中数据也嫌多，那就继续套娃，这就形成了一个树结构） 基于索引页的查找如果要查询一个数据的主键为19，就应该先从顶层的索引页60里去找，通过二分法的方式得到下层要去索引页17中查找。然后一直找到了数据可能在数据页2中，然后去数据页2中，通过页目录，找到对应的槽位，读取数据。 索引分类聚簇索引如果在一个B+树索引数据结构中，叶子节点就是数据页本身，那么可以称这个B+数为聚簇索引。（innodb默认创建的一套基于主键的索引结构，表中的数据直接放在聚簇索引里，作为叶子节点的数据页） 二级索引如果要对非主键的字段创建索引，那么会重新生成一颗B+树，叶子节点也是数据页，但是数据页中只会存放主键字段和对应的索引字段。排序规则也是按照创建索引字段的顺序来严格排序的，也会有页分裂来保证顺序。 回表在二级索引上进行查询时，比如对name字段建立的二级索引，当select name from xxx where id = xxx时，通过叶子节点中的数据页内容就能直接返回。但是如果select * from xxx where name = xxx时，叶子节点的数据不足以返回，还得通过主键去聚簇索引中定位到主键对应的完整数据行，此时才能把select * 要查询的字段值全部拿出来。 联合索引多个字段建立二级索引，也是一颗独立的B+树，叶子节点的数据页中包含了id，colA，colB。然后按照colA排序，如果colA相同就按照colB排序。 插入数据时如何维护不同索引的B+树 创建表时，就一个数据页。目前为空 开始插入数据，这个初始的数据页就是根页。数据页内部有一个基于主键的页目录，此时通过页目录查询就行。 数据越来越多数据页满了，创建一个新的数据页，然后把根页中的数据拷贝过去，同时再搞一个新的数据页，根据主键值的大小进行挪动，让两个数据页根据主键值排序，使得第二个数据页的主键值都大于第一个数据页的主键值。此时根页就变成了索引页。根页中存放了两个数据页的页号和他们里面的最小的主键值。 随着不停的增加数据，数据页不断的页分裂。索引页中的数据页索引条目越来越多，索引页开始分裂成两个索引页，然后根页继续往上走一个层级，引用两个索引页。 然后开始套娃。 与聚簇索引不同的是，二级索引的B+树的索引页中，除了存放页号和最小的索引字段值外，还会额外存放最小索引字段对应的主键值。 使用索引的几个原则 索引idx_abc(a,b,c) 等值匹配原则where条件中字段采用等于连接，并且完全包含了索引中的所有字段。比如where a=1 and b=2 and c=3 最左侧列匹配采用索引中左侧的部分字段来查询，不能跳跃。比如where a=1 and b=2 可以使用索引。但是where a=1 and c=3 不行。 最左前缀匹配原则如果使用like查询，则最左侧不能出现通配符。比如where a like ‘1%’。 范围查找规则where语句里如果有范围查询，那只有对联合索引里最左侧的列进行范围查询才能用到索引！后续的字段无法使用到索引。比如where a &gt; 1 and a&lt;5 and b&lt;1只会使用a列的索引 等值匹配+范围匹配按照前面的列等值匹配，后面的列范围匹配，需要注意的是，如果多列范围匹配只会生效最靠左的那一列。比如where a=1 and b &gt;1 and b&lt;4 and c&lt;5只会使用a,b列的索引 利用索引优化查询SQL排序如何利用索引对语句SELECT * FROM TABLE ORDER BY TOTAL_SCORE DESC, NAME DESC LIMIT 20,10语句主要是把表根据总分降序，名字降序排序后从第20页取出10条数据，可以建立（TOTAL_SCORE,NAME）的一个索引，这样的话，直接从索引树中最大的数据开始进行偏移，然后读取10条数据就行。因为索引树本身自带排序。这样的索引建立有一个前提，就是ORDER BY后面要么都是升序，要么都是降序，不能出现部分升序，部分降序。 SQL分组如何利用索引通常而言，对于group by后的字段，最好也是按照联合索引里的最左侧的字段开始，按顺序排列开来，这样的话，其实就可以完美的运用上索引来直接提取一组一组的数据，然后针对每一组的数据执行聚合函数就可以了。 覆盖索引如果我们建立了一个索引idx_name_age，那么我们在执行select * from student where name = ‘张三’ and age &gt;5 时，会先扫描一次idx_name_age索引，拿到主键后再去聚簇索引中查询一次，这叫做回表。但是如果查询的字段恰好是索引中的一部分，比如select name，这样的话，直接通过索引树就能够直接返回，这叫做覆盖索引。 如何尽可能的减少回表在利用联合索引查询的实际情况下，往往可能因为回表到聚簇索引的次数太多，直接进行全表扫描。因此要尽可能的减少回表次数。 尽可能在SQL中指定要查询的字段名，尽量走覆盖索引 即便是要回表，尽可能使用limit，where等语句限定回表到聚簇索引的次数。 设计索引的考虑因素 实际查询中在where，group by,order by后面高频出现的字段 基数比较大的字段（基数：不同的数据对于同一个列的不同值，比如性别这一列的基数最大只能是2，而出生年月日因人而异就会很多） 字段类型比较小的字段 如果非得在varchar(255)这样的字段上建立索引，也可以考虑只建立前20个字符的一个索引。 对索引列使用函数会导致无法使用到索引 不要建立太多的索引，因为新增数据可能会导致多个索引树的页分裂，很费时间 一款交友软件，陌生人搜索相关的索引建立过程字段的确定 省份provice 城市city 性别sex 年龄age 如果where和order by中的字段不同，建立谁的索引？对于SQL：SELECT * FROM USER WHERE provice = ‘四川’ order by age = 24WHERE条件和ORDER BY使用了不同的字段；建立PROVINCE的索引，ORDER BY利用不到索引；建立age的索引，WHERE条件利用不到索引；如果建立联合索引Idx(province,age)也解决不了问题，只能二选一建立索引。以where条件中的字段建立索引，因为基于where筛选可以最快速度筛选出所需要的少量数据。如果数据量不是特别大的情况下，order by的成本也不会太大 如何跳过基数很小的字段在索引中的位置对于建立了索引idx(provice,city,sex,age)的SQL：SELECT * FROM USER WHERE provice = xx and city = xx and age = 15 上面的SQL，说明了对于sex的条件没有勾选；因为sex的基数最大是2。上面的SQL在已有的索引下，是无法通过age在索引中进行筛选的。但是可以通过添加上sex in (‘male’,’female’) 这个等值条件，使得索引生效。 根据七天内是否在线作为过滤条件原始字段：latest_login_time如果添加了这个字段，势必会利用latest_login_time的一个大于或者小于操作来筛选数据，但是在idx(provice,city,sex,age)的情况下，修改索引为(provice,city,sex,latest_login_time,age)也会导致age使用不到索引。新增字段：does_login_in_latest_7_days（基数为2，原理同sex，利用等值查询） 通过对基数很小的字段进行索引的创建对于SQL：SELECT * FROM USER WHERE SEX = ‘female’ ORDER BY VIP_SCORE DESC LIMIT 0,10如果只是建立索引idx(sex)，上面的SQL经过索引后依然有海量的数据，再进行磁盘文件排序，性能很低。再这样的情况下，可以针对于基数很低的字段再加上一个排序字段单独设计一个辅助索引，idx(sex,score)。此时依然可以使用到索引来排序。因为sex=’female’的数据在磁盘上是排在一起的。找到这一部分数据后，他们肯定都是按照score排序的，此时根据score字段值的顺序去读取limit语句指定的数据就行。 区间查询的字段一定要放在索引的最右边","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 索引引入的前提","slug":"MySql-索引引入的前提","date":"2021-08-25T13:53:00.000Z","updated":"2021-08-25T13:54:55.013Z","comments":true,"path":"2021/08/25/MySql-索引引入的前提/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E7%B4%A2%E5%BC%95%E5%BC%95%E5%85%A5%E7%9A%84%E5%89%8D%E6%8F%90/","excerpt":"","text":"磁盘数据页的存储结构特性 数据页是按顺序一页一页的存放的，两两相邻的数据页之间会采用双向链表的格式相互引用。 数据页内部多个数据行通过主键顺序形成单向链表 每个数据页都有一个页目录，根据数据行的主键存放了一个目录，同时数据行是被分散存储到不同的槽位里去的。所以每个数据页的目录里，就是这个页里没个主键跟所在槽位的映射关系。 主键查询通过传入的主键到页目录中根据主键进行二分查找，通过二分查找在目录中定位到数据的槽位，到对应的槽位遍历每一行数据进行对比 非主键查询进入数据页里，根据单向链表依次遍历查找数据，性能很差 全表扫描在没有任何索引数据结构的时候，无论如何查询数据，都是一个全表扫描的过程。根据双向链表依次把磁盘上的数据页加载到缓存页里去，然后在缓存页内部来查找那条数据。 页分裂数据页中包含了一个起始行，行类型是2；包含了一个行类型为3的结束行（具体可以看03.数据在磁盘上的存储，里面有提到行格式）。其他行都是普通行，类型为0；当不停的插入数据时，最开始在第一个数据页。当第一个数据页满了，就创建了第二个数据页。但是有时候主键不一定是自增长的，所以会出现第二页中的数据的主键大于第一页中的数据的主键；为了避免这种情况，在新增一个数据页的时候，会把前一个数据页中主键值较大的，挪动到新的数据页中来。然后把新插入的主键较小的数据挪到上一个数据页中，保证新数据页中的主键值一定比上一个数据页里的主键值大（索引的一个核心基础），这就是页分裂","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 锁机制","slug":"MySql-锁","date":"2021-08-25T13:32:00.000Z","updated":"2021-08-25T13:42:26.704Z","comments":true,"path":"2021/08/25/MySql-锁/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E9%94%81/","excerpt":"前情提要当多个事务同时更新一条数据的时候，如何防止脏写的问题 锁机制的引入依靠锁机制让多个事务更新同一行数据的时候串行化，避免同时更新。 锁机制下的更新步骤 事务A要更新一条数据，先判断当前数据是否有锁。没锁则当前事务创建一个锁，其中包含了自己的trx_id和等待状态，然后把锁和数据关联起来。 此时数据和锁都是在内存中。 事务B也要更新这条数据，检查数据是否有锁时发现存在着事务A创建的锁。则创建了属于自己的一个锁，其中等待状态为true。表示正在等待 事务A更新完后，释放锁，然后寻找到事务B对这条数据加锁了。此时就会把事务B的锁中的等待状态修改为false，然后唤醒事务B。 行锁独占锁","text":"前情提要当多个事务同时更新一条数据的时候，如何防止脏写的问题 锁机制的引入依靠锁机制让多个事务更新同一行数据的时候串行化，避免同时更新。 锁机制下的更新步骤 事务A要更新一条数据，先判断当前数据是否有锁。没锁则当前事务创建一个锁，其中包含了自己的trx_id和等待状态，然后把锁和数据关联起来。 此时数据和锁都是在内存中。 事务B也要更新这条数据，检查数据是否有锁时发现存在着事务A创建的锁。则创建了属于自己的一个锁，其中等待状态为true。表示正在等待 事务A更新完后，释放锁，然后寻找到事务B对这条数据加锁了。此时就会把事务B的锁中的等待状态修改为false，然后唤醒事务B。 行锁独占锁 简介又叫X锁，Exclude锁。当有一个事务加了独占锁后，其他事务再来更新当前数据，都是要加独占锁的，但是只能在独占锁后面等待。 备注说明当多事务更新同一行数据时，其他事物是能够直接读取这行数据的，并不需要加锁。因为默认开启mvcc机制可以基于ReadView去undo log版本链中找到一个能够读取的版本。 共享锁简介又叫S锁。语法是：SELECT * FROM TABLE LOCK IN SHARE MODE；意思是在查询的时候对一行数据加共享锁。 备注说明当一行数据加了X锁后，S锁是无法添加的，因为两者互斥。当一行数据加了S锁后，其他事物也能添加S锁，因为S锁不互斥。 其他情况查询操作通过LOCK IN SHARE 添加共享锁；查询操作通过FOR UPDATE 添加互斥锁； 表锁语法LOCK TABLES xxx READ；加表级共享锁（很少用）LOCK TABLES xxx WRITE；加表级独占锁（很少用） 其他加锁的操作 如果有事务在表里执行增删改操作，就会在行级加独占锁。还会在表级加一个意向独占锁。 如果事务在表里执行查询操作，那么会在表级添加一个意向共享锁。 备注说明 意向独占锁和意向共享锁不互斥 互斥关系 锁类型 独占锁 意向独占锁 共享锁 意向共享锁 独占锁 互斥 互斥 互斥 互斥 意向独占锁 互斥 不互斥 互斥 不互斥 共享锁 互斥 互斥 不互斥 不互斥 意向共享锁 互斥 不互斥 不互斥 不互斥 独占锁与其他锁都互斥 意向XX锁与意向XX锁之间不互斥 共享锁，意向共享锁之间不互斥 意向共享锁只与独占锁互斥 不确定性的性能抖动脏页刷盘原因分析当一个查询语句，加载了大量的数据到缓存页中，导致内存中大量的缓存页被淘汰然后刷回磁盘。 解决方案减少缓存页刷盘的频率：增加buffer pool分配的内存空间 Redolog刷盘原因分析redolog不断的写入，当日志文件写满了，就会对第一个日志文件进行覆盖写入，此时如果第一个日志文件中的一些redolog对应的内存里的缓存页的数据如果还没有被刷回磁盘的话。也会触发脏页回盘的过程。 解决方案提升缓存页刷盘的速度 因为刷盘是典型的随机IO，所以要提升随机IO的性能，使用SSD固态硬盘。 配置参数innodb_io_capacity：采用多大的IO速率刷盘（每秒随机IO的次数） 配置参数innodb_flush_neighbors：刷盘时把缓存页临近的其他缓存页也刷盘，但是这样刷回的缓存页就会变多，如果是SSD，把这个设置为0就行。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql MVCC机制","slug":"MySql-MVCC机制","date":"2021-08-25T13:21:00.000Z","updated":"2021-08-25T13:31:39.331Z","comments":true,"path":"2021/08/25/MySql-MVCC机制/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-MVCC%E6%9C%BA%E5%88%B6/","excerpt":"MVCC：Multi-Version Concurrent Control，多版本并发控制。 前情提要 当多个线程执行事务的时候，对同一个缓存页里的一行数据进行更新。这个冲突如何处理 当一个事务更新一条数据时，另一个事务在查询这条数据。 常见问题脏写&amp;脏读因为一个事务去更新或者查询了另一个没有提交的事务更新过去的数据。因为另一个事务还没提交，所以随时可能回滚。导致自己更新的数据或者查询的数据没了。 不可重复读在一个事务开始之后，多次读取同一条数据的结果因为其他事务修改的提交，显示为多次读取到不同的值。 幻读","text":"MVCC：Multi-Version Concurrent Control，多版本并发控制。 前情提要 当多个线程执行事务的时候，对同一个缓存页里的一行数据进行更新。这个冲突如何处理 当一个事务更新一条数据时，另一个事务在查询这条数据。 常见问题脏写&amp;脏读因为一个事务去更新或者查询了另一个没有提交的事务更新过去的数据。因为另一个事务还没提交，所以随时可能回滚。导致自己更新的数据或者查询的数据没了。 不可重复读在一个事务开始之后，多次读取同一条数据的结果因为其他事务修改的提交，显示为多次读取到不同的值。 幻读 在一个是事务开始后，多次读取一组数据的结果因为其他事务的新增或者删除的提交，显示为新增了数据或者减少了数据。 四种隔离级别读未提交read uncommitted能够解决脏写，因为一个事务对同一条数据进行操作时（更新，删除），其他对该条数据的操作的事务将会卡住。当第一个事务提交后第二个事务才会执行。否则第二个事务等待一段时间后报错。一般没人用这个。 读已提交read committed能够解决脏读和脏写，只会读取到其他事物已经提交的数据。ORACLE的默认隔离级别 可重复读repeatable read能够解决脏读，脏写和不可重复读。但是会出现幻读。事务一旦开始，多次查询一个值，会一直读取到同一个值。MYSQL的默认隔离级别，MYSQL中RR级别不存在幻读。 串行化serializable基本解决以上所有问题，因为事务是串行进行，不存在并发的情况。 隔离级别的修改set [global | session] transaction_isolation level xxxxxx：REPEATABLE READ，READ COMMITTED，READ UNCOMMITTED，SERIALIZABLE 基于undo多版本链表实现的ReadView机制在MYSQL中，事务的ID是自增的，这是一个重点！！！在执行一个事务的时候，会生成一个ReadView，其中包括了以下4个（不仅仅是4个）关键内容： m_ids：在生成readview时，当前系统中==活跃的读写事务==的事务id列表【当前事务（新建事务）与正在内存中commit的事务不在活跃事务列表中】 min_trx_id：表示在生成readview时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值 max_trx_id：生成readview时系统中==应该分配给下一个事务的id值== creator_trx_id：生成readview的事务的事务id通过这些信息，在Readview生成后，当前事务更新的数据可以被自身读到，或者是在Readview生成前提交的事务修改的值，也是可以读到的。但是在生成ReadView的时候就已经活跃的事务，或者是ReadView生成后再开启的事务，修改的数据也是读不到的。 举个栗子（RR） 数据库中存在一条数据，事务id是32，是初始值。 事务A（trx=36）和事务B（trx=39）同时开启，事务A查询，事务B更新。 事务A根据min_trx=36&gt;trx_id=32，知道这个数据在事务开启前就已经提交过了。所以可以查询到该条数据。事务B同理也能查询到，然后事务B把值改成了值B。 事务A再次查询的时候，此时数据中的trx_id=39处于[min_trx_id,max_trx_id]，说明更新数据的事务是和自己差不多同时开启的，并且trx_id=39∈[36,39]。所以就不能查询这条数据了 虽然事务A不能查询trx_id=39这条数据，但是可以顺着roll_ptr找下去，能找到最近的一条trx_id=32&lt;36的数据。说明这一个undo log版本是在事务A开启之前就提交过的。所以查询得到的是原始值。 如果此时事务A更新该数据为值A，trx_id修改为36，同时保存之前事务B修改的值的快照，如下图 当事务A来查询数据时，发现trx_id=45刚好和自己Read_View中的creator_trx_id一致，说明数据是自己修改的，自己可以直接读取到。 当事务C来进行一次更新操作后。事务A再去读取，发现trx_id=41&gt;max_trx_id，说明在自己开启事务后有一个事务去更新了这笔数据，自己也不能去查询。然后顺着roll_ptr刚好找到一个trx_id=36的undo日志，说明是自己修改过的，直接拿到了值A READ COMMITTED是如何基于READ VIEW实现的核心点在于：每次发起的查询，都生成一个新的Read View上面的例子中，第2步事务B提交后，事务A查询时，创建新的Read View，此时活跃的事务就只有事务A（trx_id=36）了，查询到的数据trx_id=39，在min_trx_id和max_trx_id这个区间内，并且不在m_ids列表中，说明已经提交了，所以可以读取到这个值。 REPEATABLE READ是如何基于READ VIEW实现的核心点在于：每次发起的查询，使用的Read View仍然是第一次SELECT生成的。所以即便其他的事务提交了，m_ids中的内容也不会发生变化。 RR如何基于READ VIEW解决幻读在事务A开启后，进行了一次范围查询；之后事务C插入了符合范围查询的数据，但是这些数据的DB_TRX_ID是事务C的ID，因为Read View只会创建一次，事务C大于事务A的ReadView中的max_trx_id，所以事务A的再次查询是获取不到新增的数据的。 A57","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql Undolog（回滚日志）","slug":"MySql-Undolog（回滚日志）","date":"2021-08-25T13:18:00.000Z","updated":"2021-08-25T13:20:09.454Z","comments":true,"path":"2021/08/25/MySql-Undolog（回滚日志）/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-Undolog%EF%BC%88%E5%9B%9E%E6%BB%9A%E6%97%A5%E5%BF%97%EF%BC%89/","excerpt":"前情提要为了在事务提交前，随时能够回滚缓存页中已经修改的数据，就需要用undolog来记录之前的改动情况。新增操作就对应着一个删除操作来回滚，删除操作也有对应的一个新增操作。更新操作也有对应的更新操作。 回滚类型undolog根据操作类型分为3种类型。 新增类型：TRX_UNDO_INSERT_REC内容： 日志开始位置 主键的各列长度和值（可能是联合主键） 表id undolog日志编号 undolog日志类型 日志结束位置操作：在回滚时，通过获取主键的值以及表id可以直接定位到对应的缓存页，从里面删除之前插入的数据","text":"前情提要为了在事务提交前，随时能够回滚缓存页中已经修改的数据，就需要用undolog来记录之前的改动情况。新增操作就对应着一个删除操作来回滚，删除操作也有对应的一个新增操作。更新操作也有对应的更新操作。 回滚类型undolog根据操作类型分为3种类型。 新增类型：TRX_UNDO_INSERT_REC内容： 日志开始位置 主键的各列长度和值（可能是联合主键） 表id undolog日志编号 undolog日志类型 日志结束位置操作：在回滚时，通过获取主键的值以及表id可以直接定位到对应的缓存页，从里面删除之前插入的数据 删除更新如果更新的条件是主键列，则删除行然后添加一条记录。如果更新的条件不是主键列，则进行反向更新。 undolog版本链在03.数据在磁盘上的存储中，说到了数据在磁盘上的存储格式，其中就包含了隐藏字段：DB_TRX_ID和DB_ROLL_PTR。 DB_TRX_ID：最近一次更新这条数据事务的ID DB_ROLL_PTR：更新这个事务之前生成的undolog通过这2个隐藏字段，就可以在多事务并发访问下，保证数据的串行修改。 示例","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql Redolog（重做日志）","slug":"MySql-Redolog（重做日志）","date":"2021-08-25T13:11:00.000Z","updated":"2021-08-25T13:14:30.300Z","comments":true,"path":"2021/08/25/MySql-Redolog（重做日志）/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-Redolog%EF%BC%88%E9%87%8D%E5%81%9A%E6%97%A5%E5%BF%97%EF%BC%89/","excerpt":"前情提要在执行增删改操作的时候，是基于Buffer Pool中的缓存页中的数据的。更新了缓存页中的数据后，会写入一条数据到Redo Log中。在提交事务的时候，会立马把Redo Log刷入磁盘（推荐方式），然后在RedoLog中写入binlog信息和一个commit标记，事务至此提交完毕。 FAQRedoLog保障了什么当更新了缓存中的数据页后，缓存页还没有刷到磁盘上。MYSQL宕机，那么MYSQL重启后，会直接读取RedoLog中的内容，重做到Buffer Pool中，然后在刷到磁盘。因为RedoLog是顺序读写，所以效率很高。并且为了保证数据的不丢失，RedoLog也要设置成不经过OS Cache。 为什么要写入RedoLog，直接刷到磁盘的缺点在哪里？ 一个缓存页是16KB，刷盘比较耗时。而且你可能只修改了几个字节的数据。 缓存页刷入磁盘是随机读写。效率很低。而RedoLog是顺序读写，效率高","text":"前情提要在执行增删改操作的时候，是基于Buffer Pool中的缓存页中的数据的。更新了缓存页中的数据后，会写入一条数据到Redo Log中。在提交事务的时候，会立马把Redo Log刷入磁盘（推荐方式），然后在RedoLog中写入binlog信息和一个commit标记，事务至此提交完毕。 FAQRedoLog保障了什么当更新了缓存中的数据页后，缓存页还没有刷到磁盘上。MYSQL宕机，那么MYSQL重启后，会直接读取RedoLog中的内容，重做到Buffer Pool中，然后在刷到磁盘。因为RedoLog是顺序读写，所以效率很高。并且为了保证数据的不丢失，RedoLog也要设置成不经过OS Cache。 为什么要写入RedoLog，直接刷到磁盘的缺点在哪里？ 一个缓存页是16KB，刷盘比较耗时。而且你可能只修改了几个字节的数据。 缓存页刷入磁盘是随机读写。效率很低。而RedoLog是顺序读写，效率高 详细介绍RedoLog的类型根据数据页修改的字节数划分了不同的类型 MLOG_1BYTE：修改了1个字节 MLOG_2BYTE：修改了2个字节 MLOG_4BYTE：修改了4个字节 MLOG_WRITE_STRING：修改了一大串的值 RedoLog的大致内容MLOG_NBYTE，表空间ID，数据页号，数据页中的偏移量，具体修改的值MLOG_WRITE_STRING，表空间ID，数据页号，数据页中的偏移量，修改的长度，具体修改的值 RedoLog BlockRedoLog中，包含着多个RedoLog Block。每个RedoLog大小是512KB；在写入Redolog之前先写入内存中的RedoLog Block，然后再把RedoLog Block写入磁盘文件。具体的结构见图。 RedoLog buffer好比Buffer Pool，基于内存中的一块连续空间。里面分配了多个空的RedoLog block。用来存放redolog。 在一个事务中，多个操作对应多个redo Log，对应着一组redolog，现在别的地方暂存，执行完了再把一组的redolog写入到内存中的redolog buffer中的block中 如果一个事务对应的redoLog太多，就会放到两个甚至多个redolog block中。 如果一个redolog group比较小，也可能会把多个redolog group合并在一个redolog block中。 刷盘时机 写入redolog buffer的日志占用了总容量（innodb_log_buffer_size）的50%。 事务提交的时候 后台线程定时刷新 MYSQL关闭的时候 RedoLog的一些默认处理磁盘上默认redolog数量：2个(innodb_log_files_in_group)磁盘上默认redolog大小：48MB(innodb_log_file_size)磁盘上的默认名：ib_logfile0，ib_logfile1一般情况是向一个redolog中写，写满了就换下一个。所以redolog最多保存96MB的redolog，如果第二个写满了，就覆盖第一个日志文件里面原来的redolog","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 数据在磁盘上的存储","slug":"MySql-数据在磁盘上的存储","date":"2021-08-25T13:09:00.000Z","updated":"2021-08-25T13:16:03.393Z","comments":true,"path":"2021/08/25/MySql-数据在磁盘上的存储/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E6%95%B0%E6%8D%AE%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E7%9A%84%E5%AD%98%E5%82%A8/","excerpt":"物理数据存储格式行格式 COMPACT格式 大致格式：变长字段的长度列表，null值列表（长度为8n），数据头[隐藏字段]，col1的值，col2的值。。。 xxx格式 变长字段的存储因为变长字段的内容不固定，所以无法判断数据要从何处截断，因此在数据的头部保存了变长字段的长度列表。多个变长字段按照字段顺序逆序放入变长字段的长度列表中。不考虑为null的列。","text":"物理数据存储格式行格式 COMPACT格式 大致格式：变长字段的长度列表，null值列表（长度为8n），数据头[隐藏字段]，col1的值，col2的值。。。 xxx格式 变长字段的存储因为变长字段的内容不固定，所以无法判断数据要从何处截断，因此在数据的头部保存了变长字段的长度列表。多个变长字段按照字段顺序逆序放入变长字段的长度列表中。不考虑为null的列。 NULL值的存储对于所有的NULL值，是通过二进制的bit位来存储，一行数据如果有多个字段的值为NULL，那么这些字段的NULL会以bit位的形式存放在NULL值列表中。0表示不是NULL，1表示是NULL，同样也是逆序存放.==需要注意的是，不允许为NULL的列是不考虑的==。 数据头 bit位 名称 作用 1 预留位 无 1 预留位 无 1 delete_mask 删除标志位 1 min_rec_mask B+树的每一层非叶子节点的最小值会有这个标志 4 n_owned 拥有的记录数 13 heap_no 当前记录在记录堆的位置信息 3 record_type 当前记录的类型，0：普通；1：B+树非叶子节点；2：最小值数据；3：最大值数据 16 next_record 下一条数据的指针 隐藏字段 DB_ROW_ID：行唯一标识，在没有指定主键和Unique key唯一索引的时候，会以他作为主键 DB_TRX_ID：事务相关 DB_ROLL_PTR：回滚指针，用于事务回滚 示例 红色的列表示不允许为空 varchar(10) varchar(20) varchar(5) char(2) char(3) 可能格式 hello nice a zx cc [0x01,0x04,0x05][00000000][头字段]hello nice a zx cc ppt word flash d z [0x05,0x04,0x03][00000000][头字段]ppt wprd flash d z jack NULL cc ps NULL [0x02,0x04][00001001][头字段]jack cc ps tom 3 mg NULL KG [0x02,0x01,0x03][00000100][头字段]tom 3 mg KG 紧凑的意义节省空间？ 读取的过程 示例样本(选自上方)[0x02,0x01,0x03][00000100][010000001000011111]tom 3 mg KG 先读取出变长字段长度列表和NULL值列表，分析得到几个变长字段以及哪几个字段是NULL。因为MYSQL自己定义的列以及类型自己最清楚哪些列是变长哪些列允许NULL 第一个字段不允许为空所以不会出现在NULL值列表中，是变长类型所以从变长列表中取出0x03，就去字段列表中读取3个字符的长度，得到tom 第二个字段为变长允许为空，所以读取NULL值列表知道不为空，在读取变长列表得到长度为0x01,所以读取1个字符的长度得到3 第三个字段为变长允许为空，所以读取NULL值列表知道不为空，在读取变长列表得到长度为0x02,所以读取2个字符的长度得到mg 第四个字段为定长允许为空，所以直接读取NULL值列表知道为空，所以直接为null 第五个字段为定长允许为空，直接读取NULL值列表知道不为空，所以直接读取固定的3个长度得到KG 。（这里KG后面还有一个空格补充长度） 行溢出因为每行数据都是存放在一个数据页中的，一个数据页是16KB，如果一行数据的大小超过了数据页的大小。比如一个字段是VARCHAR(65532),最多可以放65532个字符，65532个字符至少也是65532b≈64kb&gt;&gt;16kb。这个时候就会在那一页存放你的数据，然后特别长的字段中，只会包含部分数据，同时还==包含一个20个字节的指针，指向其他的数据页==，用于把这些数据页用链表串联起来，存放超大数据。 数据页的拆分数据页16kb的大小实际上被拆分成了多个部分，包括 文件头（38b） 数据页头（56b） 最小记录和最大记录（26b） 多个数据行 空闲空间 数据页目录 文件尾部（8b） 数据区与数据组在磁盘上，一个表空间的数据文件中可能包含多个数据页，为了便于管理，引入了数据区的概念。一个数据区对应着64个连续的数据页，每页16kb，所以一个数据区是1MB。256个数据区划分为1组(extent)。所以1组是256MB。 第一个数据区特殊的3页一个表空间的第一个数据区的前3个数据页是固定的，存放描述性信息。 FSP_HDR IBUF_BITMAP INODE 其他数据区特殊的2页同理也是存放描述性信息 XDES 未知 一个口述的数据插入流程 根据表名找到对应的表空间，定位到对应的磁盘文件 从磁盘文件中拿到一个extent组，从里面找出一页数据页 加载数据页到Buffer Pool","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql Buffer Pool 与数据页","slug":"ySql-Buffer-Pool-与数据页","date":"2021-08-25T13:03:00.000Z","updated":"2021-08-25T13:17:03.892Z","comments":true,"path":"2021/08/25/ySql-Buffer-Pool-与数据页/","link":"","permalink":"https://pdyun.cc/2021/08/25/ySql-Buffer-Pool-%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%A1%B5/","excerpt":"Buffer Pool在对数据库执行增删改查操作的时候，因为对磁盘的随机读写操作速度非常慢。所以通过Buffer Pool缓存磁盘的真实数据。 数据页MYSQL中抽象出来的数据单位，MYSQL把很多行数据放在一个数据页里。实际上我们更新一行数据的时候，是通过数据库找到这行数据所在的数据页，然后加载到Buffer Pool中。默认情况下，一个数据页是16KB 缓存页因为在Buffer Pool中存放的也是一个一个的数据页，也叫作缓存页。在默认情况下，是和磁盘上的数据页一一对应的，所以也是16KB。","text":"Buffer Pool在对数据库执行增删改查操作的时候，因为对磁盘的随机读写操作速度非常慢。所以通过Buffer Pool缓存磁盘的真实数据。 数据页MYSQL中抽象出来的数据单位，MYSQL把很多行数据放在一个数据页里。实际上我们更新一行数据的时候，是通过数据库找到这行数据所在的数据页，然后加载到Buffer Pool中。默认情况下，一个数据页是16KB 缓存页因为在Buffer Pool中存放的也是一个一个的数据页，也叫作缓存页。在默认情况下，是和磁盘上的数据页一一对应的，所以也是16KB。 缓存页的描述信息用于描述缓存页的一些基本信息，比如数据页所属表空间、数据页的编号、在Buffer Pool中的地址等。每个缓存页都有对应的一个描述信息，在Buffer Pool中，每个缓存页的描述信息在最前面，然后各个缓存页放在后面描述数据大概相当于缓存页是5%。 free链表概念引入当读取数据页放入Buffer Pool的时候，怎么知道哪些缓存页是空闲的？free链表是一个双向链表，每个节点是一个空闲的缓存页的描述块地址。 空间占用 free链表只是一个逻辑上的概念，因为每个缓存页的描述数据块中维护了两个指针，free_prev和free_next，分别指向free链表的上一个节点和下一个节点，这样就串成了一个free链表。 free链表还有一个基础节点（但是不在链表中，链表头结点的prev=null，尾结点的next=null），40个字节，存放了free链表的头结点的地址、尾结点的地址以及free链表里当前还有多少个节点。 数据页读取到Buffer Pool的过程 从free链表里获取一个描述数据块，获取到对应的空闲缓存页 把数据页读取到对应的缓存页，写入相关的描述信息到描述数据块中 从free链表中移除 flush链表在执行增删改的时候，都是基于内存中的缓存页进行操作的，一旦更新了缓存页中的数据，使得和磁盘上的数据页里的数据不一致。那么这就是脏数据页。类似于free链表，通过缓存页描述数据块中的两个指针来将脏数据页串起来。组成一个双向链表，也有一个基础节点存放头结点尾结点的地址等。 MYSQL预读机制当从磁盘上加载一个数据页的时候，可能会连带把这个数据页相邻的其他数据页也加载到缓存中去。分为以下两种预读方式，暂时不做说明 线性预读 顺序访问了一个区里的多个数据页（默认56页），就会把下一个相邻区中的所有数据页加载到缓存中 随机预读 如果Buffer Pool中缓存了一个区的13个随机数据页，而且这些数据页是比较频繁被访问的，就会把这个区的其他数据页都加载到缓存中 LRU链表简化版 当free链表已经没有空闲页的时候，所有的缓存页都塞了数据库，此时就要淘汰掉一些缓存页。 此时可以将一个脏数据页刷到磁盘，然后清空这个缓存页，就有了一个空闲的缓存页。但是选择哪一个脏数据页去清空，此时就要用到LRU链表。 当把一个数据页加载到缓存页的时候，把对应的描述数据块放到LRU链表头部。后续查询了或者修改了某个缓存页，也会把这个缓存页挪动到LRU链表头部。 但是MYSQL的预读机制可能会加载没人访问的数据页，如下图。 基于冷热分离的LRU链表 将链表按照5:3的比例分割，63%的热数据，37%的冷数据。 数据页第一次加载到缓存的时候，放入冷数据头部。在1s后（参数配置）访问这个缓存页，就会被加入热数据头部。 在热数据区域的前1/4部分缓存页被访问后不会移动到链表头部，避免浪费性能 有一个后台线程会定时把冷数据区域的尾部缓存页刷回磁盘，清空加入回free链表。 热数据区域也会在MYSQL闲暇的时候刷回磁盘 无空闲缓存页时从冷数据区域尾部找到一个缓存页刷回磁盘并清空成为空闲页。 Buffer Pool并发访问Buffer Pool的性能问题 多线程同时访问Buffer Pool，就会同时操作同一个free链表、flush链表和lru链表。那必然要进行加锁 因为是基于内存的操作，所以很快。其次这些链表的操作，也是基于指针的操作，也不存在性能低下的可能。多个Buffer Pool优化并发能力给Buffer Pool分配比较大的内存，则可以设置多个Buffer Pool.如果给分配的内存小于1G，最多就只有1个Buffer Pool。 innodb_buffer_pool_instances=8 基于chunk机制动态调整Buffer Pool的大小 Buffer Pool是由多个chunk组成的，默认一个chunk的大小是128M。 分配Buffer Pool的内存8G，4个Buffer Pool实例，那么每个Buffer Pool是2G，拥有16个chunk。 需要动态扩容的话只需要申请一系列128MB大小的chunk就行，然后分配给buffer pool就行。 内存的分配 Buffer Pool总共占用机器内存的50%-60% buffer Pool总大小 = (chunk size * buffer pool instance) * chunk count总结 根据机器的内存设置合理的buffer pool的大小，然后设置buffer pool的数量，使得chunk数量*chunk size 接近单个buffer pool的内存。充分利用内存减少内存碎片 每个buffer pool里的多个chunk共用一套链表数据结构。 后台线程定时根据lru链表和flush链表，去把一批缓存页刷入磁盘并释放，同时更新free链表 如果缓存页满了，无法加载自己的缓存页，就把lru链表冷数据区域的缓存页刷盘","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 基础","slug":"MySql-基础","date":"2021-08-25T12:58:00.000Z","updated":"2021-08-25T13:17:44.357Z","comments":true,"path":"2021/08/25/MySql-基础/","link":"","permalink":"https://pdyun.cc/2021/08/25/MySql-%E5%9F%BA%E7%A1%80/","excerpt":"名词说明MYSQL驱动在底层跟数据库建立网络连接 系统连接池建立数据库连接是一个非常耗时的操作，而实际业务中往往会有很多请求去访问数据库，所以要使用一个数据库连接池来维护多个数据库连接。线程使用完连接后不用销毁，直接放回连接池以便后续使用。 MYSQL连接池维护了与系统之间的多个数据库连接。除此之外，系统每次与MYSQL建立连接的时候，还会进行账户信息验证，库表权限验证。 SQL接口MYSQL内部提供的一个组件，负责执行线程传递过来的SQL语句","text":"名词说明MYSQL驱动在底层跟数据库建立网络连接 系统连接池建立数据库连接是一个非常耗时的操作，而实际业务中往往会有很多请求去访问数据库，所以要使用一个数据库连接池来维护多个数据库连接。线程使用完连接后不用销毁，直接放回连接池以便后续使用。 MYSQL连接池维护了与系统之间的多个数据库连接。除此之外，系统每次与MYSQL建立连接的时候，还会进行账户信息验证，库表权限验证。 SQL接口MYSQL内部提供的一个组件，负责执行线程传递过来的SQL语句 查询解析器负责对SQL语句进行解析，知道做什么操作，对哪张表操作，操作哪些数据，怎么操作等 查询优化器得到一个效率最高的执行计划 执行器根据查询优化器选择的一套执行计划，不停的调用存储引擎的各种接口去完成SQL语句的执行计划。 比如执行器可能先会调用存储引擎的一个接口去获取user表的第一行数据，判断id是否为我们期望的一个值，如果不是就继续调用接口获取下一行数据继续判断 存储引擎接口执行SQL语句，按照一定的步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等。 流程图 InnoDB内存结构缓冲池缓冲池（Buffer Pool），方便查询的时候，直接可以从内存缓冲池中获取，减少对磁盘的查询 undo日志用于回滚数据 更新缓存数据流程 记录加载到缓冲池 加锁 旧值写入undo日志文件 更新缓冲池中的记录，此时这个数据就是脏数据了（和磁盘数据不一致） redo日志记录内存中的数据修改，避免内存修改后没有同步到磁盘上。InnoDB存储引擎特有的一个东西。在mysql重启时会加载redo日志中的修改到内存里去，然后等适当时机通过IO线程把修改后的数据同步到磁盘上。 RedoLog Buffer内存中的一个缓冲区。暂时存放redo日志。 binlog归档日志，偏向物理性质的重做日志，类似于，对XX表中某一行数据进行了修改，修改后的值是XXX；在提交事务的时候，还会把binlog的文件名，位置以及commit标记写入对应的redo日志中。 事务提交流程1.根据策略(innodb_flush_log_at_trx_commit)，把redo日志从redo log buffer刷到磁盘文件。 0：不管事务，每一秒都会把日志写入，并且刷到磁盘。事务提交时不会主动触发写磁盘的操作。1：只要事务提交成功，redo log就必然在磁盘里（建议）2：提交事务的时候，把redo日志写入磁盘对应的os cache缓存，而不是直接进入磁盘文件，可能要过一段时间再写入磁盘 根据策略(sync_binlog)，把binlog日志写入磁盘 0：写入os cache，一段时间后写入磁盘（默认）1：强制在提交事务的时候，直接写入到磁盘文件 把写入磁盘的binlog日志的文件名，位置以及一个commit标记写入到redo日志 至此，事务才算提交完成。只要redo日志中不存在commit标记则认为提交失败。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 8.0新特性","slug":"MySQL8-0新特性","date":"2021-08-23T03:56:00.000Z","updated":"2021-08-27T03:10:59.117Z","comments":true,"path":"2021/08/23/MySQL8-0新特性/","link":"","permalink":"https://pdyun.cc/2021/08/23/MySQL8-0%E6%96%B0%E7%89%B9%E6%80%A7/","excerpt":"MySql 8.0新特性MySQL从5.7一跃直接到8.0，这其中的缘由，咱就不关心那么多了，有兴趣的朋友自行百度，本次的版本更新，在功能上主要有以下6点： 账户与安全 优化器索引 通用表表达式 窗口函数 InnoDB 增强 JSON 增强","text":"MySql 8.0新特性MySQL从5.7一跃直接到8.0，这其中的缘由，咱就不关心那么多了，有兴趣的朋友自行百度，本次的版本更新，在功能上主要有以下6点： 账户与安全 优化器索引 通用表表达式 窗口函数 InnoDB 增强 JSON 增强 一、账户与安全123456789101112131.用户的创建与授权 在MySQL5.7的版本： &gt; grant all privileges on *.* to &#x27;用户名&#x27;@&#x27;主机&#x27; identified by &#x27;密码&#x27;； 在MySQL8.0需要分开执行： &gt;create user &#x27;用户名&#x27;@&#x27;主机&#x27; identified by &#x27;密码&#x27;； &gt;grant all privileges on *.* to &#x27;用户名&#x27;@&#x27;主机&#x27;； 用以前的一条命令在8.0里面创建用户，会出现sql语法错误 12345678910111213142.认证插件更新 MySQL5.7默认身份插件是mysql_native_password MySQL8.0默认的身份插件是caching_sha2_password 查看身份认证插件命令：show variables like &#x27;default_authentication_plugin%&#x27;; 身份认证插件可以通过以下2中方式改变： 1）系统变量default_authentication_plugin去改变，在my.ini文件的[mysqld]下面设置default_authentication_plugin=mysql_native_password即可 2）如果希望只是某一个用户通过mysql_native_password的方式认证，可以修改数据库mysql下面的user表的字段，执行以下命令： &gt;alter user &#x27;用户名&#x27;@&#x27;主机&#x27; identified width mysql_native_password by &#x27;密码&#x27;; 1234567891011121314151617181920212223242526272829303.密码管理 MySQL8.0的密码管理策略有3个变量 password_history 修改密码不允许与最近几次使用或的密码重复，默认是0，即不限制 password_reuse_interval 修改密码不允许与最近多少天的使用过的密码重复，默认是0,即不限制 password_require_current 修改密码是否需要提供当前的登录密码，默认是OFF,即不需要；如果需要，则设置成ON 查询当前MySQL密码管理策略相关变量，使用以下命令： &gt;show variables like &#x27;password%&#x27;; 1)设置全局的密码管理策略，在my.ini配置文件中，设置以上3个变量的值这种设置方式，需要重启mysql服务器；某些生产环境不允许重启，MySQL8.0提供了关键字persist,持久化，执行以下命令： &gt;set persist password_history=6; 这条命令会在数据目录下生成新的配置文件（/var/lib/mysql/mysqld-auto.cnf），下次服务器重启的时候除了读取全局配置文件，还会读取这个配置文件,这条配置就会被读入从而达到持久化的目的 2)针对某一个用户单独设置密码管理策略 &gt;alter user &#x27;用户名&#x27;@&#x27;主机&#x27; password history 5; 这样，这个用户的password_history 就被设置成了5,查看一下： &gt;show user,host,Password_reuse_history from user; 查看某一张的字段的所有字段，使用以下命令: &gt;desc 表名; 12345678910111213141516171819202122232425262728293031323334353637383940414.角色管理 角色：一组权限的集合 一组权限赋予某个角色，再把某个角色赋予某个用户，那用户就拥有角色对应的权限 1)创建一个角色 &gt;create role &#x27;角色1&#x27;; 2)为这个角色赋予相应权限 &gt;grant insert,update on *.* to &#x27;角色1&#x27;; 3)创建一个用户 &gt;create user &#x27;用户1&#x27; identified by &#x27;用户1的密码&#x27;; 4)为这个用户赋予角色的权限 &gt;grant &#x27;角色1&#x27; on *.* to &#x27;用户1&#x27;； 执行完上面4步，用户1就拥有了插入与更新的权限 5)再创建1个用户 &gt;create user &#x27;用户2&#x27; identified by &#x27;用户2的密码&#x27;; 6)为这个用户赋予同样的角色 &gt;grant &#x27;角色1&#x27; on *.* to &#x27;用户2&#x27;; 执行完上面2步，用户2也用了角色1的权限，即插入与更新 查看用户权限，执行以下命令： &gt;show grants for &#x27;用户名&#x27;; 7)启用角色,设置了角色，如果不启用，用户登录的时候，依旧没有该角色的权限 &gt;set default role &#x27;角色名&#x27; to &#x27;用户名&#x27;; 8)如果一个用户有多个角色，使用以下命令 &gt;set default role all to &#x27;用户名&#x27;; MySQL中与用户角色相关的表：mysql.default_roles、mysql.role_edges,有兴趣的朋友可以进去查看下。 9)撤销权限 &gt;revoke insert,update on *.* from &#x27;角色名&#x27;; 二、优化器索引12345678910111213141516171819202122232425262728293031323334351.隐藏索引（invisible index） 隐藏索引不会被优化器使用，但仍需要维护 应用场景： 1）软删除 删除索引，在线上，如果删除错了索引，只能通过创建索引的方式将其添加回来，对于一些大的数据库而言，是比较耗性能的；为了避免删错，可以先将其设置为不可见，优化器这时候就不会使用它，但是后台仍然在维护，确定后，再删除。 2）灰度发布 与软删除差不多，如果想要测试一些索引的功能或者随后可能会使用到这个索引，可以先将其设置为隐藏索引，对于现有的查询不会产生影响，测试后，确定需要该索引，可以将其设置成可见索引。 创建隐藏索引，执行如下命令（如果是不隐藏，则不需要后面的invisible关键字）： &gt;create index 索引名称 on 表名(字段名) invisible; 查询某一张表的索引，执行如下命令： &gt;show index from 表名； 使用explain语句查看查询优化器对索引的使用情况 &gt;explain select * from 表名 where 条件; 查询优化器有很多开关，有一个是use_invisible_indexes(是否使用隐藏索引),默认是off(不适用)，将其设置成on,即可使用隐藏索引。查看当前查询优化器的所有开关变脸，执行如下命令： &gt;select @@optimizer_switch; 设置已经存在的索引为可见或者隐藏，执行如下命令： &gt;alter table 表名 alter index 索引名 visible; &gt;alter table 表名 alter index 索引名 invisible; 主键不可以设置为隐藏索引。 1232.降序索引（descending index） MySQL8.0开始真正支持降序索引，只有InnoDB引擎支持降序所以，且必须是BTREE降序索引，MySQL8.0不在对group by操作进行隐式排序。 1234567891011121314151617183.函数索引 索引中使用函数表达式 支持JSON数据节点的索引 函数索引是基于虚拟列的功能实现的假设用户表（tb_user）的的用户登录账号(username)不需要区分大小写，则可以创建一个函数索引&gt;create index username_upper_index on tb_user((upper(username)));这样在查询的时候 SELECT * FROM tb_user WHERE upper(username) = &#x27;ABD123DSJ&#x27;; 就会使用索引。上面的函数索引，也可以通过MySQL5.7已有的虚拟计算列来模拟，为用户表（tb_user）创建新的一列（new_column）,这一列是计算列，不需要赋值，它的值就是username的大写。&gt;alter tbale tb_user add column new_column varchar(10) generated always as (upper(username));然后给new_column创建一个索引，可以达到模拟MySQL8.0中的函数索引的效果。 三、通用表表达式12345671.非递归 CTE 派生表：select * from (select 1) as dt; 通用表表达式：with cte as (select 1) select * from cte; with cte1(id) as (select 1),cte2 as (select id+1 from cte1) select * from cte1 join cte2; 12.递归 CTE 四、窗口函数五、InnoDB增强11.集成数据字段 12345672.原子ddl操作 MySQL5.7执行drop命令 drop table t1,t2; 如果t1存在，t2不存在，会提示t2表不存在，但是t1表仍然会被删除。 MySQL8.0执行同样的drop命令，会提示t2表不存在，而且t1表不会被删除，保证了原子性。 ddl操作（针对表）的原子性前提是该表使用的存储引擎是InnoDB 12345673.自增列持久化 解决了之前的版本，主键重复的问题。 MySQL5.7及其以前的版本，MySQL服务器重启，会重新扫描表的主键最大值，如果之前已经删除过id=100的数据，但是表中当前记录的最大值如果是99，那么经过扫描，下一条记录的id是100，而不是101。 MySQL8.0则是每次在变化的时候，都会将自增计数器的最大值写入redo log,同时在每次检查点将其写入引擎私有的系统表。则不会出现自增主键重复的问题。 14.死锁检查控制 15.锁定语句选项 六、JSON增强1234567891.内联路径操作符 column-&gt;&gt;path等价于之前的：JSON_UNQUOTE(column -&gt; path)JSON_UNQUOTE(JSON_EXTRACT(column,path)) 1232.JSON聚合函数MySQL8.0和MySQL5.7.22增加了2个聚合函数 121)JSON_ARRAYAGG(),将多行数据组合成json数组 示例：select o_id,json_arrayagg(attribute) as attributes from t group by o_id; 122)JSON_OBJECTAGG()，用于生成json对象 示例：select o_id json_objectagg(attribute,value) as attributes from t group by o_id; 注意：json的聚合函数针对重复key,会使用最后的覆盖前面已有的值，如果下面的o_id=3，它的color有2个值，一个green,一个yellow,使用生成json的聚合函数的时候，前面的green会被覆盖掉。 123453.JSON实用函数 1)JSON_PRETTY() 输出json数据的时候，格式化。 select json_object(&#x27;id&#x27;,3,&#x27;name&#x27;,&#x27;Barney&#x27;); 1 select json_pretty(json_object(&#x27;id&#x27;,3,&#x27;name&#x27;,&#x27;Barney&#x27;)); 123 2)JSON_STORAGE_SIZE() json数据所占用的存储空间（单位：字节） 3)JSON_STORAGE_FREE() json数据更新后所释放的空间（单位：字节） 1234567894.JSON合并函数MySQL8.0废弃了JSON_MERGE()函数，推荐使用以下两个函数合并JSON数据 1)JSON_MERGE_PATCH() 2)JSON_MERGE_PRESERV()上面两个函数都是JSON数据合并，最大的区别就是前者遇到相同key的时候会用后面的覆盖前面的，后者会都保留，看下面的截图： 1235.JSON表函数 MySQL8.0新增了JSON_TABLE()函数，将JSON数据转换成关系表，可以将该函数的返回结果当做一个普通的临时表进行sql查询。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MyBatis 插件的使用及原理","slug":"MyBatis插件关键对象","date":"2021-08-20T10:59:00.000Z","updated":"2022-03-02T13:41:49.332Z","comments":true,"path":"2021/08/20/MyBatis插件关键对象/","link":"","permalink":"https://pdyun.cc/2021/08/20/MyBatis%E6%8F%92%E4%BB%B6%E5%85%B3%E9%94%AE%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"MyBatis插件关键对象 Interceptor 接口：自定义拦截器（实现类） InterceptorChain：存放插件的容器 Plugin：h对象；提供创建代理类的方法 Invocation：对被代理对象的封装 1. 自定义插件mybatis插件（准确的说应该是around拦截器，因为接口名是interceptor，而且invocation.proceed要自己调用，配置中叫插件）功能非常强大，可以让我们无侵入式的对SQL的执行进行干涉，从SQL语句重写、参数注入、结果集返回等每个主要环节，典型的包括权限控制检查与注入、只读库映射、K/V翻译、动态改写SQL。 MyBatis 默认支持对4大对象（Executor，StatementHandler，ParameterHandler，ResultSetHandler）上的方法执行拦截，具体支持的方法为： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed)，主要用于sql重写。 ParameterHandler (getParameterObject, setParameters)，用于参数处理。 ResultSetHandler (handleResultSets, handleOutputParameters)，用于结果集二次处理。 StatementHandler (prepare, parameterize, batch, update, query)，用于jdbc层的控制。 大多数情况下仅在Executor做插件比如SQL重写、结果集脱敏，ResultSetHandler和StatementHandler仅在高级场景中使用，而且某些场景中非常有价值。 四大对象的在sql执行过程中的调用链如下： 具体的方法定义可以参见每个类方法的签名，这里就不详细展开了。这四个类被创建后不是直接返回，而是创执行了interceptorChain.pluginAll(parameterHandler)才返回。如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142//Configuration 中public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler;&#125;public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler;&#125;public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125;public Executor newExecutor(Transaction transaction) &#123; return newExecutor(transaction, defaultExecutorType);&#125;public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType ** null ? defaultExecutorType : executorType; executorType = executorType ** null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH ** executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE ** executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 1-1 编写Interceptor的实现类 Executor拦截器案例1:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Intercepts(&#123; // @Signature(type = Executor.class, method = /* org.apache.ibatis.executor.Executor中定义的方法,参数也要对应 */&quot;update&quot;, args = &#123; MappedStatement.class, Object.class&#125;), @Signature( type = Executor.class, method = &quot;query&quot;, args = &#123; MappedStatement.class, Object.class,RowBounds.class, ResultHandler.class &#125; ) &#125;)public class SelectPruningColumnPlugin implements Interceptor &#123; public static final ThreadLocal&lt;ColumnPruning&gt; enablePruning = new ThreadLocal&lt;ColumnPruning&gt;()&#123; @Override protected ColumnPruning initialValue() &#123; return null; &#125; &#125;; Logger logger = LoggerFactory.getLogger(SelectPruningColumnPlugin.class); static int MAPPED_STATEMENT_INDEX = 0;// 这是对应上面的args的序号 static int PARAMETER_INDEX = 1; static int ROWBOUNDS_INDEX = 2; static int RESULT_HANDLER_INDEX = 3; @Override public Object intercept(Invocation invocation) throws Throwable &#123; if (enablePruning.get() != null &amp;&amp; enablePruning.get().isEnablePruning()) &#123; Object[] queryArgs = invocation.getArgs(); MappedStatement mappedStatement = (MappedStatement) queryArgs[MAPPED_STATEMENT_INDEX]; Object parameter = queryArgs[PARAMETER_INDEX]; BoundSql boundSql = mappedStatement.getBoundSql(parameter); String sql = boundSql.getSql();// 获取到SQL ，进行调整 String name = mappedStatement.getId(); logger.debug(&quot;拦截的方法名是:&quot; + name + &quot;,sql是&quot; + sql + &quot;,参数是&quot; + JsonUtils.toJson(parameter)); String execSql = pruningColumn(enablePruning.get().getReserveColumns(), sql); logger.debug(&quot;修改后的sql是:&quot; + execSql); // 重新new一个查询语句对像 BoundSql newBoundSql = new BoundSql(mappedStatement.getConfiguration(), execSql, boundSql.getParameterMappings(), boundSql.getParameterObject()); // 把新的查询放到statement里 MappedStatement newMs = copyFromMappedStatement(mappedStatement, new BoundSqlSqlSource(newBoundSql)); for (ParameterMapping mapping : boundSql.getParameterMappings()) &#123; String prop = mapping.getProperty(); if (boundSql.hasAdditionalParameter(prop)) &#123; newBoundSql.setAdditionalParameter(prop, boundSql.getAdditionalParameter(prop)); &#125; &#125; queryArgs[MAPPED_STATEMENT_INDEX] = newMs; // 因为涉及分页查询PageHelper插件，所以不能设置为null，需要业务上下文执行完成后设置为null// enablePruning.set(null); &#125; Object result = invocation.proceed(); return result; &#125; @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125; 案例2: 带反射123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Intercepts(&#123; @Signature( type = Executor.class,method = &quot;query&quot;, args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125; )&#125;)public class MyPageInterceptor implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; System.out.println(&quot;将逻辑分页改为物理分页&quot;); Object[] args = invocation.getArgs(); MappedStatement ms = (MappedStatement) args[0]; // MappedStatement BoundSql boundSql = ms.getBoundSql(args[1]); // Object parameter RowBounds rb = (RowBounds) args[2]; // RowBounds // RowBounds为空，无需分页 if (rb ** RowBounds.DEFAULT) &#123; return invocation.proceed(); &#125; // 将原 RowBounds 参数设为 RowBounds.DEFAULT，关闭 MyBatis 内置的分页机制 //args[2] = RowBounds.DEFAULT; // 在SQL后加上limit语句 String sql = boundSql.getSql(); String limit = String.format(&quot;LIMIT %d,%d&quot;, rb.getOffset(), rb.getLimit()); sql = sql + &quot; &quot; + limit; // 自定义sqlSource SqlSource sqlSource = new StaticSqlSource(ms.getConfiguration(), sql, boundSql.getParameterMappings()); // 修改原来的sqlSource Field field = MappedStatement.class.getDeclaredField(&quot;sqlSource&quot;); field.setAccessible(true); field.set(ms, sqlSource); // 执行被拦截方法 return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123; &#125;&#125; ResultSetHandler拦截器123456789101112131415161718192021222324252627@Intercepts(&#123; @Signature( type = ResultSetHandler.class, method = &quot;handleResultSets&quot;, args = &#123; Statement.class&#125; ) &#125;)public class OptMapPlugin implements Interceptor &#123; @Override public Object intercept(Invocation invocation) throws Throwable &#123; Object target = invocation.getTarget(); Statement stmt = (Statement) invocation.getArgs()[0]; if (target instanceof DefaultResultSetHandler) &#123; DefaultResultSetHandler resultSetHandler = (DefaultResultSetHandler) target; Class clz = resultSetHandler.getMappedStatement().getResultMaps().get(0).getType(); if (clz ** OptMap.class) &#123; List&lt;Object&gt; resultList = new ArrayList&lt;Object&gt;(); OptMap optMap = new OptMap(); resultList.add(optMap); resultSet2OptMap(resultSetHandler.getConfiguration(),resultSetHandler,optMap,stmt.getResultSet()); return resultList; &#125; return invocation.proceed(); &#125; //如果没有进行拦截处理，则执行默认逻辑 return invocation.proceed(); &#125; 注册插件最后将插件配置到mybatis-config.xml 123456&lt;!-- mybatis-config.xml 注册插件--&gt;&lt;plugins&gt; &lt;plugin interceptor=&quot;com.dpl.mybatis.plugin.SelectPruningColumnPlugin&quot;&gt; &lt;property name=&quot;someProperty&quot; value=&quot;100&quot;/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 2. 插件实现原理2-1. 初始化操作首先我们来看下在全局配置文件加载解析的时候做了什么操作。 进入方法内部可以看到具体的解析操作 1234567891011121314151617private void pluginElement(XNode parent) throws Exception &#123; if (parent != null) &#123; for (XNode child : parent.getChildren()) &#123; // 获取&lt;plugin&gt; 节点的 interceptor 属性的值 String interceptor = child.getStringAttribute(&quot;interceptor&quot;); // 获取&lt;plugin&gt; 下的所有的properties子节点 Properties properties = child.getChildrenAsProperties(); // 获取 Interceptor 对象 Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).getDeclaredConstructor().newInstance(); // 设置 interceptor的 属性 interceptorInstance.setProperties(properties); // Configuration中记录 Interceptor configuration.addInterceptor(interceptorInstance); &#125; &#125; &#125; 该方法用来解析全局配置文件中的plugins标签，然后对应的创建Interceptor对象，并且封装对应的属性信息。最后调用了Configuration对象中的方法。 configuration.addInterceptor(interceptorInstance) 123public void addInterceptor(Interceptor interceptor) &#123; interceptorChain.addInterceptor(interceptor); &#125; 通过这个代码我们发现我们自定义的拦截器最终是保存在了 InterceptorChain 这个对象中。而 InterceptorChain 的定义为 1234567891011121314151617public class InterceptorChain &#123; // 保存所有的 Interceptor 也就我所有的插件是保存在 Interceptors 这个List集合中的 private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); // public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; // 获取拦截器链中的所有拦截器 target = interceptor.plugin(target); // 创建对应的拦截器的代理对象 &#125; return target; &#125; public void addInterceptor(Interceptor interceptor) &#123; interceptors.add(interceptor); &#125; public List&lt;Interceptor&gt; getInterceptors() &#123; return Collections.unmodifiableList(interceptors); &#125;&#125; 2.2 如何创建代理对象在解析的时候创建了对应的Interceptor对象，并保存在了InterceptorChain中，那么这个拦截器是如何和对应的目标对象进行关联的呢？ 首先拦截器可以拦截的对象是Executor,ParameterHandler,ResultSetHandler,StatementHandler. 那么我们来看下这四个对象在创建的时候又什么要注意的 2.2.1 Executor 我们可以看到Executor在装饰完二级缓存后会通过 pluginAll 来创建 Executor 的代理对象。 123456public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; // 获取拦截器链中的所有拦截器 target = interceptor.plugin(target); // 创建对应的拦截器的代理对象 &#125; return target;&#125; 进入plugin方法中，我们会进入到 1234// 决定是否触发 intercept()方法default Object plugin(Object target) &#123; return Plugin.wrap(target, this);&#125; 然后进入到MyBatis给我们提供的Plugin工具类的实现 wrap方法中。 123456789101112131415161718192021222324/*** 创建目标对象的代理对象* 目标对象 Executor ParameterHandler ResultSetHandler StatementHandler* @param target 目标对象* @param interceptor 拦截器* @return */public static Object wrap(Object target, Interceptor interceptor) &#123; // 获取用户自定义 Interceptor中@Signature注解的信息 // getSignatureMap 负责处理@Signature 注解 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); // 获取目标类型 Class&lt;?&gt; type = target.getClass(); // 获取目标类型 实现的所有的接口 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); // 如果目标类型有实现的接口 就创建代理对象 if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; // 否则原封不动的返回目标对象 return target;&#125; Plugin中的各个方法的作用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class Plugin implements InvocationHandler &#123; private final Object target; // 目标对象 private final Interceptor interceptor; // 拦截器 private final Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap; // 记录 @Signature 注解的 信息 private Plugin(Object target, Interceptor interceptor, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; &#125; /*** 创建目标对象的代理对象* 目标对象 Executor ParameterHandler ResultSetHandler StatementHandler* @param target 目标对象* @param interceptor 拦截器* @return */ public static Object wrap(Object target, Interceptor interceptor) &#123; // 获取用户自定义 Interceptor中@Signature注解的信息 // getSignatureMap 负责处理@Signature 注解 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); // 获取目标类型 Class&lt;?&gt; type = target.getClass(); // 获取目标类型 实现的所有的接口 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); // 如果目标类型有实现的接口 就创建代理对象 if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; // 否则原封不动的返回目标对象 return target; &#125; /*** 代理对象方法被调用时执行的代码* @param proxy* @param method* @param args* @return* @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // 获取当前方法所在类或接口中，可被当前Interceptor拦截的方法 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123; // 当前调用的方法需要被拦截 执行拦截操作 return interceptor.intercept(new Invocation(target, method, args)); &#125; // 不需要拦截 则调用 目标对象中的方法 return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; private static Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; getSignatureMap(Interceptor interceptor) &#123; Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class); // issue #251 if (interceptsAnnotation == null) &#123; throw new PluginException(&quot;No @Intercepts annotation was found in interceptor &quot; + interceptor.getClass().getName()); &#125; Signature[] sigs = interceptsAnnotation.value(); Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = new HashMap&lt;&gt;(); for (Signature sig : sigs) &#123; Set&lt;Method&gt; methods = signatureMap.computeIfAbsent(sig.type(), k -&gt; new HashSet&lt;&gt;()); try &#123; Method method = sig.type().getMethod(sig.method(), sig.args()); methods.add(method); &#125; catch (NoSuchMethodException e) &#123; throw new PluginException(&quot;Could not find method on &quot; + sig.type() + &quot;named &quot; + sig.method() + &quot;. Cause: &quot; + e, e); &#125; &#125; return signatureMap; &#125; private static Class&lt;?&gt;[] getAllInterfaces(Class&lt;?&gt; type, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; Set&lt;Class&lt;?&gt;&gt; interfaces = new HashSet&lt;&gt;(); while (type != null) &#123; for (Class&lt;?&gt; c : type.getInterfaces()) &#123; if (signatureMap.containsKey(c)) &#123; interfaces.add(c); &#125; &#125; type = type.getSuperclass(); &#125; return interfaces.toArray(new Class&lt;?&gt;[interfaces.size()]); &#125;&#125; 2.2.2 StatementHandler在获取StatementHandler的方法中 123456789101112131415161718@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, rowBounds, ResultHandler resultHandler, BoundSqlStatement stmt = null;Object parameter, RowBounds boundSql) throws SQLException &#123; try &#123; Configuration configuration = ms.getConfiguration(); // 注意，已经来到SQL处理的关键对象 StatementHandler &gt;&gt; StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 获取一个 Statement对象 stmt = prepareStatement(handler, ms.getStatementLog()); // 执行查询 return handler.query(stmt, resultHandler); &#125; finally &#123; // 用完就关闭 closeStatement(stmt); &#125;&#125; 在进入newStatementHandler方法 1234567public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); // 植入插件逻辑（返回代理对象） statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125; 可以看到statementHandler的代理对象 2.2.3 ParameterHandler在上面步骤的RoutingStatementHandler方法中，我们来看看 123456789101112131415161718public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; // StatementType 是怎么来的？ 增删改查标签中的 statementType=&quot;PREPARED&quot;，默认值 PREPARED switch (ms.getStatementType()) &#123; case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: // 创建 StatementHandler 的时候做了什么？ &gt;&gt; delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException(&quot;Unknown statement type: &quot; + ms.getStatementType()); &#125;&#125; 然后我们随便选择一个分支进入，比如PreparedStatementHandler 在newParameterHandler的步骤我们可以发现代理对象的创建 123456789public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); // 植入插件逻辑（返回代理对象） parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler;&#125; 2.2.4 ResultSetHandler在上面的newResultSetHandler()方法中，也可以看到ResultSetHander的代理对象 12345678public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler,ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); // 植入插件逻辑（返回代理对象） resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler;&#125; 2.3 执行流程以Executor的query方法为例，当查询请求到来的时候，Executor的代理对象是如何处理拦截请求的呢？我们来看下。当请求到了executor.query方法的时候 然后会执行Plugin的invoke方法 1234567891011121314151617181920212223/*** 代理对象方法被调用时执行的代码* @param proxy* @param method* @param args* @return* @throws Throwable */@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; // 获取当前方法所在类或接口中，可被当前Interceptor拦截的方法 Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123; // 当前调用的方法需要被拦截 执行拦截操作 return interceptor.intercept(new Invocation(target, method, args)); &#125; // 不需要拦截 则调用 目标对象中的方法 return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125;&#125; 然后进入interceptor.intercept 会进入我们自定义的 FirstInterceptor对象中 12345678910111213/*** 执行拦截逻辑的方法* @param invocation* @return* @throws Throwable */@Overridepublic Object intercept(Invocation invocation) throws Throwable &#123; System.out.println(&quot;FirtInterceptor 拦截之前 ....&quot;); Object obj = invocation.proceed(); // 执行目标方法 System.out.println(&quot;FirtInterceptor 拦截之后 ....&quot;); return obj;&#125; 这个就是自定义的拦截器执行的完整流程 2.4 多拦截器插件执行顺序见 MyBatis 插件的执行顺序 插件执行流程如果我们有多个自定义的拦截器，那么他的执行流程是怎么样的呢？比如我们创建了两个 Interceptor 都是用来拦截 Executor 的query方法，一个是用来执行逻辑A 一个是用来执行逻辑B的。 单个拦截器的执行流程 如果说对象被代理了多次，这里会继续调用下一个插件的逻辑，再走一次Plugin的invoke()方法。这里我们需要关注一下有多个插件的时候的运行顺序。 配置的顺序和执行的顺序是相反的。InterceptorChain的List是按照插件从上往下的顺序解析、添加的。 而创建代理的时候也是按照list的顺序代理。执行的时候当然是从最后代理的对象开始。 这个我们可以通过实际的案例来得到验证，最后来总结下Interceptor的相关对象的作用 对象 作用 Interceptor 自定义插件需要实现接口，实现4个方法 InterceptChain 配置的插件解析后会保存在Configuration的InterceptChain中 Plugin 触发管理类，还可以用来创建代理对象 Invocation 对被代理类进行包装，可以调用proceed()调用到被拦截的方法","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://pdyun.cc/tags/MyBatis/"},{"name":"插件","slug":"插件","permalink":"https://pdyun.cc/tags/%E6%8F%92%E4%BB%B6/"}],"author":"Peilin Deng"},{"title":"MyBatis 插件的执行顺序","slug":"MyBatis-插件的执行顺序","date":"2021-08-20T10:58:00.000Z","updated":"2022-03-02T13:05:52.874Z","comments":true,"path":"2021/08/20/MyBatis-插件的执行顺序/","link":"","permalink":"https://pdyun.cc/2021/08/20/MyBatis-%E6%8F%92%E4%BB%B6%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/","excerpt":"","text":"多个插件执行顺序 本文转载自 https://zhuanlan.zhihu.com/p/266735787在 mybatis 中允许针对 SQL 在执行前后进行扩展操作，而这些扩展操作也叫做插件。允许用插件来拦截的方法包括： MyBatis 默认支持对4大对象（Executor，StatementHandler，ParameterHandler，ResultSetHandler）上的方法执行拦截，具体支持的方法为： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed)，主要用于sql重写。 ParameterHandler (getParameterObject, setParameters)，用于参数处理。 ResultSetHandler (handleResultSets, handleOutputParameters)，用于结果集二次处理。 StatementHandler (prepare, parameterize, batch, update, query)，用于jdbc层的控制。 通过插件可以实现 SQL 打印，分页插件等功能。这时候就会延伸出一个问题：如果存在多个插件，这些插件的执行顺序是怎样的？ 一、插件的执行顺序插件执行顺序一共有两种1、不同拦截对象的执行顺序 Mybatis 针对以上这四种对象的拦截的执行顺序是固定的，因为 Mybatis代码的执行流程是固定的。以 SimpleExecutor#query 来说，这四种对象的执行代码如下： 通过源码知道，执行顺序为：Executor-&gt;StatementHandler-&gt;ParameterHandler-&gt;StatementHandler-&gt;ResultSetHandler 虽然中间 StatementHandler 执行了多次，但是总的来说，执行顺序优先级从高到低为：Executor-&gt;StatementHandler-&gt;ParameterHandler-&gt;ResultSetHandler 2、同种拦截对象的执行顺序针对同种对象如果存在多种拦截器对象，其拦截顺序如何？ 首先在前面，知道了插件功能的实现是通过代理的方式对原有的如：Executor、ParameterHandler 等进行了代理增强，而经过代理后的原有的 Executor 、ParameterHandler 等对象会以如下方式存在： 如图，存在多个拦截器都是先进后出，针对代理模式来说来说，可以对被代理的原始对象的处理前后进行代码增强操作。 而那个拦截器优先执行，取决于在生成代理对象时的顺序，也就是包裹在最外层的插件（拦截器）优先执行。 来回顾一下代理对象生成时的逻辑然后结合mybatis-config.xml 配置文件的关于 的配置信息，即可知道相关的执行顺序。 来看代理生成代码 InterceptorChain#pluginAll，如下： 如上述代码所示，通过遍历 interceptors List 列表对 target 对象进行包装（target 可以是 Executor or ParameterHandler等）。 也就是在 List 列表的最开始的 interceptor 插件最先被包裹在 target 对象外层，也就是如下图所示： 如上图所示，在配置文件中越靠前的插件配置，在 interceptors List 列表中的位置自然越靠前，其执行顺序自然越靠后。 总结：同个对象的多个拦截器执行顺序根据配置文件 mybatis-config.xml 插件配置顺序有关，配置越靠前，执行顺序越靠后","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://pdyun.cc/tags/MyBatis/"},{"name":"插件","slug":"插件","permalink":"https://pdyun.cc/tags/%E6%8F%92%E4%BB%B6/"}],"author":"Peilin Deng"},{"title":"MyBatis 运行时序图","slug":"MyBatis-运行时序图","date":"2021-08-20T10:55:00.000Z","updated":"2021-08-27T03:10:40.819Z","comments":true,"path":"2021/08/20/MyBatis-运行时序图/","link":"","permalink":"https://pdyun.cc/2021/08/20/MyBatis-%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BA%8F%E5%9B%BE/","excerpt":"架构分层","text":"架构分层 1. 创建会话工厂类 2. 创建会话 3. 获取代理对象 4. 调用代理对象方法, 执行SQL","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://pdyun.cc/tags/MyBatis/"}],"author":"Peilin Deng"},{"title":"Spring 事务传播原理及数据库事务操作原理","slug":"Spring-事务传播原理及数据库事务操作原理","date":"2021-08-20T10:43:00.000Z","updated":"2021-08-27T03:05:59.208Z","comments":true,"path":"2021/08/20/Spring-事务传播原理及数据库事务操作原理/","link":"","permalink":"https://pdyun.cc/2021/08/20/Spring-%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E5%8E%9F%E7%90%86%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E6%93%8D%E4%BD%9C%E5%8E%9F%E7%90%86/","excerpt":"","text":"1. 什么是事务?事务(Transaction) 是访问并可能更新数据库中各个数据的一个程序执行单元(unit).特点: 事务是恢复和并发控制的基本单位, 事务应该具备四个属性原子性、一致性、隔离性、持久性.这四个属性通常称为 ACID 特性. 2. Spring 事务传播属性 3. 数据库事务的隔离级别 http://pdyun.cc:4000/2021/08/27/Mysql-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/ 4. Spring 事务的隔离级别","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://pdyun.cc/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 循环依赖及三级缓存","slug":"Spring-循环依赖及三级缓存","date":"2021-08-20T10:42:00.000Z","updated":"2021-08-20T11:09:17.630Z","comments":true,"path":"2021/08/20/Spring-循环依赖及三级缓存/","link":"","permalink":"https://pdyun.cc/2021/08/20/Spring-%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%8F%8A%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98/","excerpt":"Spring 循环依赖及三级缓存 Spring 在启动过程中，使用到了三个map，称为三级缓存。 Spring启动过程大致如下： 1.加载配置文件2.解析配置文件转化beanDefination，获取到bean的所有属性、依赖及初始化用到的各类处理器等3.创建beanFactory并初始化所有单例bean4.注册所有的单例bean并返回可用的容器，一般为扩展的applicationContext","text":"Spring 循环依赖及三级缓存 Spring 在启动过程中，使用到了三个map，称为三级缓存。 Spring启动过程大致如下： 1.加载配置文件2.解析配置文件转化beanDefination，获取到bean的所有属性、依赖及初始化用到的各类处理器等3.创建beanFactory并初始化所有单例bean4.注册所有的单例bean并返回可用的容器，一般为扩展的applicationContext 一级缓存 在第三步中，所有单例的bean初始化完成后会存放在一个Map(singletonObjects)中，beanName为key，单例bean为value。第三步单例bean的初始化过程大致如下： 0.标记bean为创建中1.new出bean对象2.如果支持循环依赖则生成三级缓存，可以提前暴露bean3.填充bean属性，解决属性依赖4.初始化bean，处理Aware接口并执行各类bean后处理器，执行初始化方法，如果需要生成aop代理对象5.如果存在循环依赖，解决之 – 这里有点问题，这一步是如果之前解决了aop循环依赖，则缓存中放置了提前生成的代理对象，然后使用原始bean继续执行初始化，所以需要再返回最终bean前，把原始bean置换为代理对象返回。6.此时bean已经可以被使用，进行bean注册(标记)并注册销毁方法。7.将bean放入容器中(一级缓存)，移除创建中标记及二三级缓存(后面再具体分析) 循环依赖及三级缓存 根据以上步骤可以看出bean初始化是一个相当复杂的过程，假如初始化A bean时，发现A bean依赖B bean,即A初始化执行到了第2步，此时B还没有初始化，则需要暂停A，先去初始化B，那么此时new出来的A对象放哪里，直接放在容器Map里显然不合适，半残品怎么能用，所以需要提供一个可以标记创建中bean(A)的Map，可以提前暴露正在创建的bean供其他bean依赖，如果在初始化A所依赖的bean B时，发现B也需要注入一个A的依赖，则B可以从创建中的beanMap中直接获取A对象（创建中）注入A，然后完成B的初始化，返回给正在注入属性的A，最终A也完成初始化，皆大欢喜。 如果配置不允许循环依赖，则上述缓存就用不到了，A 依赖B，就是创建B，B依赖C就去创建C，创建完了逐级返回就行，所以，一级缓存之后的其他缓存(二三级缓存)就是为了解决循环依赖！而配置支持循环依赖后，就一定要解决循环依赖吗？肯定不是！循环依赖在实际应用中也有，但不会太多，简单的应用场景是： controller注入service，service注入mapper，只有复杂的业务，可能service互相引用，有可能出现循环依赖，所以为了出现循环依赖才去解决，不出现就不解决，虽然支持循环依赖，但是只有在出现循环依赖时才真正暴露早期对象，否则只暴露个获取bean的方法，并没有真正暴露bean，因为这个方法不会被执行到，这块的实现就是三级缓存（singletonFactories），只缓存了一个单例bean工厂。 这个bean工厂不仅可以暴露早期bean还可以暴露代理bean，如果存在aop代理，则依赖的应该是代理对象，而不是原始的bean。而暴露原始bean是在单例bean初始化的第2步，填充属性第3步，生成代理对象第4步，这就矛盾了，A依赖到B并去解决B依赖时，要去初始化B，然后B又回来依赖A，而此时A还没有执行代理的过程，所以，需要在填充属性前就生成A的代理并暴露出去，第2步时机就刚刚好。 三级缓存的bean工厂getObject方式，实际执行的是getEarlyBeanReference，如果对象需要被代理(存在beanPostProcessors -&gt; SmartInstantiationAwareBeanPostProcessor)，则提前生成代理对象。 二级缓存 根据以上步骤可以看出bean初始化是一个相当复杂的过程，但是貌似三级缓存已经解决所有问题了，二级缓存用来做什么呢？为什么三级缓存不直接叫做二级缓存?这个应该是在缓存使用时决定的： 三级缓存中提到出现循环依赖才去解决，也就是说出现循环依赖时，才会执行工厂的getObject生成(获取)早期依赖，这个时候就需要给它挪个窝了，因为真正暴露的不是工厂，而是对象，所以需要使用一个新的缓存保存暴露的早期对象(earlySingletonObjects)，同时移除提前暴露的工厂，也不需要在多重循环依赖时每次去执行getObject(虽然个人觉得不会出问题，因为代理对象不会重复生成，详细可以了解下代理里面的逻辑，如wrapIfNecessary)。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 启动流程简述","slug":"Spring-启动流程","date":"2021-08-20T05:47:00.000Z","updated":"2021-08-20T07:10:45.327Z","comments":true,"path":"2021/08/20/Spring-启动流程/","link":"","permalink":"https://pdyun.cc/2021/08/20/Spring-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","excerpt":"beanDefinitionMap -&gt; 用来存储 BeanDefinition(Bean 的配置信息)factoryBeanObjectCache -&gt; 用来存储原生 Bean 对象的Map, 指反射创建出的实际对象factoryBeanInstanceCache -&gt; 用来存储 BeanWrapper 的Map, 指原生 Bean 的包装类 Spring 启动流程简述一. 配置阶段 web.xml1234DispatcherServlet 路径设定 init-param ( contextConfigLocation = classPath:application.xml )设定 url-pattern ( /* )配置 Annotation 等","text":"beanDefinitionMap -&gt; 用来存储 BeanDefinition(Bean 的配置信息)factoryBeanObjectCache -&gt; 用来存储原生 Bean 对象的Map, 指反射创建出的实际对象factoryBeanInstanceCache -&gt; 用来存储 BeanWrapper 的Map, 指原生 Bean 的包装类 Spring 启动流程简述一. 配置阶段 web.xml1234DispatcherServlet 路径设定 init-param ( contextConfigLocation = classPath:application.xml )设定 url-pattern ( /* )配置 Annotation 等 appication.xml1配置 包扫描路径、Bean定义、视图解析配置等...... …… 二. 初始化阶段 Servlet.init() 12Spring 是 servlet 编程模型, 容器启动时会调用 servlet 的 init() 方法, 在该方法中会读取配置进行 IoC 容器及 MVC 组件的初始化. IoC 部分 (定位、加载、注册) 1234初始化 IoC 容器 1. 通过 web.xml 的配置定位 application .xml配置文件. 2. 使用 BeanDefinitionReader 读取配置文件, 扫描类并封装成 BeanDefinition 3. 创建 BeanFatory, 将 *beanDefinition 注册到 DefalutListableBeanFactory 的 beanDefinitionMap 中 DI 、 AOP 部分 123456784. 初始化非延迟加载的 bean0). 标记 bean 为创建中 1). 通过反射 new 出 bean 对象, 封装成 BeanWrapper 对象 2). 如果 bean 为单例且支持循环依赖则生成三级缓存 singletonFactories, 可提前暴露 bean 3). 填充bean属性，解决属性依赖 4). 初始化bean的各个Aware接口(各个Aware接口能让bean获取到部分属性: ApplicationContextAware-能获取到ApplicationContex; BeanFactoryAware 能获取到 BeanFactory) 并执行各类 bean 的后处理器, 执行初始化方法, 如果有 AOP 配置需要生成 AOP 代理对象 5). 如果存在循环依赖，解决之 – 这里有点问题，这一步是如果之前解决了aop循环依赖，则缓存中放置了提前生成的代理对象，然后使用原始bean继续执行初始化，所以需要再返回最终bean前，把原始bean置换为代理对象返回。 6). 此时 bean 已经可以使用, 将 bean 放入一级缓存 singletonObjects , 移除创建中标记以及二三级缓存 MVC 部分 12345678910111213141516171819205. 初始化 MVC 九大组件// 1). 初始化文件上传解析器initMultipartResolver(context);// 2). 初始化本地语言环境initLocaleResolver(context);// 3). 初始化模板处理器initThemeResolver(context);// 4). 初始化 HandlerMapping 组件initHandlerMappings(context);// 5). 初始化参数适配器initHandlerAdapters(context);// 6). 初始化异常拦截器initHandlerExceptionResolvers(context);// 7). 初始化视图预处理器initRequestToViewNameTranslator(context);// 8). 初始化视图解析器initViewResolvers(context);// 9). 初始化 FlashMap 管理器( 为了解决请求转发和重定向过程中参数的丢失问题: redirect-&gt;重定向, request 参数会丢失 ; forward-&gt;转发, 自动将 request 参数系诶带到下一个请求 )initFlashMapManager(context); 三. 运行阶段 从页面点击按钮或者 url 访问资源请求会先到 DispatcherServlet 的 doDispatch() 方法, 该方法会从 HandlerMapping 中通过 url 去匹配对应的控制器及方法 通过参数解析器解析参数并反射执行方法, 返回一个 ModelAndView 通过视图解析器解析 ModelAndView, 决定返回页面或者输出数据 前端根据对应结果来展示","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 基础认知与技术架构","slug":"Spring-基础认知与技术架构","date":"2021-08-19T15:10:00.000Z","updated":"2021-08-20T11:19:52.620Z","comments":true,"path":"2021/08/19/Spring-基础认知与技术架构/","link":"","permalink":"https://pdyun.cc/2021/08/19/Spring-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5%E4%B8%8E%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/","excerpt":"Spring Spring 是一个轻量级Java开发框架，最早有Rod Johnson创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的JavaSE/JavaEE full-stack（一站式）轻量级开源框架，为开发Java应用程序提供全面的基础架构支持。Spring负责基础架构，因此Java开发者可以专注于应用程序的开发。 Spring最根本的使命是解决企业级应用开发的复杂性，即简化Java开发。 1. Spring 简化开发的四个基本策略 基于POJO 的轻量级和最小侵入性编程. 通过依赖注入和面向接口松耦合. 基于切面和惯性进行声明式编程. 通过切面和模板减少样版式代码.","text":"Spring Spring 是一个轻量级Java开发框架，最早有Rod Johnson创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的JavaSE/JavaEE full-stack（一站式）轻量级开源框架，为开发Java应用程序提供全面的基础架构支持。Spring负责基础架构，因此Java开发者可以专注于应用程序的开发。 Spring最根本的使命是解决企业级应用开发的复杂性，即简化Java开发。 1. Spring 简化开发的四个基本策略 基于POJO 的轻量级和最小侵入性编程. 通过依赖注入和面向接口松耦合. 基于切面和惯性进行声明式编程. 通过切面和模板减少样版式代码. 2. Spring 中的编程思想 Spring思想 应用场景 (特点) 一句话归纳 OOP Object Oriented Programming (面向对象编程) 用程序归纳总结生活中一切事物 封装、继承、多态. BOP Bean Oriented Programming (面向Bean编程) 面向Bean (普通Java类) 设计程序, 解放程序员. 一切从Bean开始. AOP Aspect Oriented Programming (面向切面编程) 找出多个类中有一定规律的代码, 开发时拆开, 应运行时再合并. 面向切面编程, 及面向规则编程. 解耦, 专人做专事. IoC Inversion of Control (控制反转) 将new对象的动作交给Spring管理, 并由Spring保存已创建的对象 (IOC容器). 转交控制权(即控制权反转). DI/DL Dependency Injection (依赖注入) 或者Dependency Lookup (依赖查找) , Spring不仅保存自己创建的对象, 而且保存对象与对象之间的关系. 注入即赋值, 主要三种方式 — 构造方法、set方法、直接赋值. 自动赋值. 3. Spring 注解编程演化V1.X | V2.0 | V2.5 | V3.X | V4.X | V5.X— | — | — | — | — | — | —注解驱动启蒙时代 | 注解驱动过渡时代 | 引入新的骨架式Annotation | 注解驱动黄金时代 | 注解驱动完善时代 | 注解驱动成熟时代 4. Spring 模块结构 Spring 总共大约有 20 个模块， 由 1300 多个不同的文件构成。 而这些组件被分别整合在核心容器（Core Container） 、 AOP（Aspect Oriented Programming）和设备支持（Instrmentation） 、数据访问与集成（Data Access/Integeration） 、 Web、 消息（Messaging） 、 Test等 6 个模块中。 5. Spring 系统架构模块功能介绍Spring 核心模块 模块名称 主要功能 spring-core IoC控制反转与DI依赖注入的最基本实现 spring-beans Bean工厂与Bean的装配 spring-context 定义基础的Spring的Context上下文即IoC容器 spring-context-support 对Spring IoC的扩展支持, 以及IoC子容器 spring-context-indexer Spring的类管理组件和Classpath扫描 spring-expression Spring表达式语言 Spring 面向切面编程模块 模块名称 主要功能 spring-aop 面向切面编程的引用模块, 整合Asm, CGLib、JDKProxy spring-aspects 继承AspectJ, AOP应用框架 spring-instrument 动态Class Loading模块 Spring 数据访问与继承模块 模块名称 主要功能 spring-jdbc Spring 提供的JDBC抽象框架的组要实现模块, 用于简化 Spring JDBC 操作 spring-tx Spring JDBC 事务控制实现模块 spring-orm 主要继承 Hibernate, Java Persitence API (JPA) 和 Java Data Object (JDO) spring-oxm 将Java对象映射成XML数据, 或者将XML数据映射成Java对象 spring-jms Java Messaging Service 能够发送和接收信息 Spring Web 模块 模块名称 主要功能 spring-web 提供了最基础Web支持, 主要建立于核心容器之上, 通过 Servlet 或者 Listeners 来初始化 IoC 容器 spring-webmvc 实现了 Spring-MVC (model-view-controller) 的 Web 应用 spring-websokect 主要是与 Web 前端的全双工通讯的协议 spring-webflux 一个新的非阻塞函数式 Reactive Web 框架, 可以用来建立异步的. 非阻塞, 事件驱动的服务 Spring 通信报文 模块 模块名称 主要功能 spring-messaging 从 Spring4 开始新加入的一个模块, 主要职责是为 Spring 框架继承一些基础的报文传输应用 Spring 集成测试 模块 模块名称 主要功能 spring-test 主要为测试提供支持的 Spring 集成兼容 模块 模块名称 主要功能 spring-framwork-bom Bill of Materials. 解除 Spring 的不同模块依赖版本不同问题 6. Spring 模块之依赖关系图 7. 版本命名规则Spring 版本命名规则 其他常见软件版本命名规则 语义化版本命名通用规则 商业软件中常见的修饰词","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"外网访问家庭网络小记","slug":"外网访问家庭网络小记","date":"2021-08-13T16:16:00.000Z","updated":"2021-08-13T16:44:04.286Z","comments":true,"path":"2021/08/14/外网访问家庭网络小记/","link":"","permalink":"https://pdyun.cc/2021/08/14/%E5%A4%96%E7%BD%91%E8%AE%BF%E9%97%AE%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E5%B0%8F%E8%AE%B0/","excerpt":"记录一次家庭内网使用DDNS让外网访问, 同时动态更新域名123此篇文章献给&#x27;懒人&#x27;同学~ 相信很多同学在自己家里学习啥的搞些小网站小程序, 比如部署一些在线看视频丶个人网盘丶个人博客等的网站, 但是在公司时想访问记录或查询一些资料, 但是又因为访问不了家庭网络而烦躁... 在此分享能使用任意外网访问家庭内网, 同时动态更新域名的方法.当然在此之前我使用过花生壳、公云等一些软件, 他也可以让你从外网访问家庭内网, 但是别的不说, 他限速而且收费呀… 自己搭建可以全速使用家里的带宽步骤如下: 一. 外网访问","text":"记录一次家庭内网使用DDNS让外网访问, 同时动态更新域名123此篇文章献给&#x27;懒人&#x27;同学~ 相信很多同学在自己家里学习啥的搞些小网站小程序, 比如部署一些在线看视频丶个人网盘丶个人博客等的网站, 但是在公司时想访问记录或查询一些资料, 但是又因为访问不了家庭网络而烦躁... 在此分享能使用任意外网访问家庭内网, 同时动态更新域名的方法.当然在此之前我使用过花生壳、公云等一些软件, 他也可以让你从外网访问家庭内网, 但是别的不说, 他限速而且收费呀… 自己搭建可以全速使用家里的带宽步骤如下: 一. 外网访问 1. 申请公网IP 想访问家庭网络必定需要找家里开网络的运营商, 让他们给开公网IP, 我家里使用的是电信宽带, 电话直接打 10000 号人工服务让他们帮忙开通, 理由嘛很简单( 找个借口说家里安装监控就给你开了 ) , 电信现在默认都是给的私网IP. 2. 光猫改为桥接模式 申请完公网IP先别急着挂, 还需要让他们把宽带网络改成桥接模式, 后面我们路由器使用拨号上网 3. 查询宽带账号和密码 由于路由器现在是使用拨号上网, 所以还需要找他运营商拿到宽带的账户和密码, 这些都是必要条件 4. 设备网线连接 我们使用网线连接 光猫的网口 和 路由器WAN口, 主机的网线则联通路由器的LAN口, ( WAN口是连接外部网络, LAN口是连接内部网络, 家里的电脑网线都可以用LAN接口连接, 并且此时我们电脑是没有网络的 ) 12graph LR光猫网口 --&gt; 路由器WAN口 12graph LR路由器LAN口 --&gt; 电脑网口 5. 设置路由器 此时已经具备的条件:公网ip, 宽带改为桥接模式, 宽带账号和密码, 设备网线正确连接 开始设置路由器: 我的路由器设备使用的小米路由器, 暂以小米路由器为例, 路由器网关是 192.168.31.1 , 自己的路由器网关自己搜一下, 然后输入路由器用户名密码 上网设置如图, 上网方式选择PPPOE手动拨号, 然后输入宽带的账号和密码即可 拨号成功应该就可以上网了~~~ 6. 检查IP地址 百度查询自己本机的IP是否与路由器拨号成功获得的IP地址相同.++如果不同, 那一般都是私网ip 没有申请公网ip的.++ 7. 路由转发 一般路由器都拥有路由转发功能, 可以自己配置转发规则. 端口转发: 映射端口, 访问外网 ip:端口, 会直接映射到内网的ip:端口如: **访问外网地址 22.135.173.55:8848, 会被转发到内网 192.168.31.26:8000 ** 8. 测试 我本地电脑随便开启一个服务部署成功, 内网ip:port 192.168.31.26:8401 接着使用外网ip访问, 注意自己映射的端口哦访问成功~~ 二. 设置动态更新域名12由于电信给的公网IP是动态IP, 每次关闭重启光猫都会更换公网IP地址, 所以这也是个很头疼的事情... 个人方案解决了该情况 1. 准备域名 ( 本方案只支持腾讯云域名, 对接腾讯云API ) 我使用的方法, 使用Python写了一个脚本, 动态去更新域名, 需要准备一个腾讯云的域名。提供购买链接 https://buy.cloud.tencent.com/domain?from=console 2. 开通腾讯云 API 密钥 API 密钥代表你的账号身份和所拥有的权限，使用腾讯云 API 可以操作您名下的所有腾讯云资源。给上链接 https://console.cloud.tencent.com/cam/capi 开通完后新建密钥( 单机即可, 自动创建 ): 3. 安装Python3 由于使用的 Python 写的脚本, 需要环境拥有Python, 版本 3 及以上.安装方法参考 https://www.cnblogs.com/weven/p/7252917.html安装完成后查看Python版本: 4. 献上脚本 复制以下代码 保存为 xxx.py 格式就行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197VERSION = 1from hashlib import sha1import jsonimport timeimport base64import hmacclass DDnsHelper(): def __init__(self, mid=0, params=&#123;&#125;): pass def excute(self): import requests SecretId = &#x27;*需要填写*&#x27; SecretKey = &#x27;*需要填写*&#x27; runningPause = 20 domainName = &#x27;pelyhome.cc&#x27; # *需要填写你自己的域名* ddnsDomains = [ &#123; # *需要填写你自己的域名* &#x27;name&#x27;: &#x27;@.pelyhome.cc&#x27;, &#x27;value&#x27;: &#x27;&#x27;, # &#x27;always&#x27;: False, # DNS生存时间 &#x27;ttl&#x27;: 600, # 主机记录, 即域名前缀 &#x27;subDomain&#x27;: &#x27;@&#x27;, &#x27;recordId&#x27;: &#x27;&#x27;, # 记录类型 &#x27;recordType&#x27;: &#x27;A&#x27;, # 线路类型, 指定细分解析线路 &#x27;recordLine&#x27;: &#x27;默认&#x27;, &#x27;description&#x27;: &#x27;本地提供api服务的地址&#x27;, # 查看本地域名的接口, 这是自己写的接口, 仅仅返回一个纯粹的本地外网IP地址 &#x27;localDomain&#x27;: &#x27;https://www.hosix.cn/ip&#x27;, &#x27;localValue&#x27;: &#x27;&#x27; &#125; ] class tenXunDDNS_Helper(): def __init__(self): self.running = True self.action = &quot;&quot; self.secretId = SecretId self.nonce = 38651 self.region = &#x27;ap-guangzhou&#x27; self.secretKey = SecretKey self.version = &#x27;2017-03-12&#x27; self.domain = domainName self.url = &#x27;cns.api.qcloud.com/v2/index.php&#x27; self.httpType = &#x27;https://&#x27; self.endpoint = self.httpType + self.url self.ddnsDomain = ddnsDomains self.runningPause = runningPause self.remoteRecords = [] def getServerIp(self): timeStamp = int(time.time()) params = &#123;&#125; params[&#x27;Action&#x27;] = &#x27;RecordList&#x27; params[&#x27;domain&#x27;] = self.domain params[&#x27;Nonce&#x27;] = self.nonce params[&#x27;SecretId&#x27;] = self.secretId params[&#x27;Timestamp&#x27;] = timeStamp s = self.get_string_to_sign(&quot;GET&quot;, self.url, params) Signature = self.sign_str(self.secretKey, s, sha1) params[&#x27;Signature&#x27;] = Signature response = requests.get(self.endpoint, params=params) result = json.loads(response.text) if int(result[&#x27;code&#x27;]) != 0: raise Exception(&#x27;获取域名失败&#x27; + &#x27;:&#x27; + str(result[&#x27;code&#x27;]) + &#x27;:&#x27; + result[&#x27;message&#x27;]) data = result[&#x27;data&#x27;] self.remoteRecords = data[&#x27;records&#x27;] # print(self.remoteRecords) def postServerIp(self, domain): timeStamp = int(time.time()) params = &#123;&#125; params[&#x27;Action&#x27;] = &#x27;RecordCreate&#x27; params[&#x27;domain&#x27;] = self.domain params[&#x27;Nonce&#x27;] = self.nonce params[&#x27;SecretId&#x27;] = self.secretId params[&#x27;Timestamp&#x27;] = timeStamp params[&#x27;subDomain&#x27;] = domain[&#x27;subDomain&#x27;] params[&#x27;recordType&#x27;] = domain[&#x27;recordType&#x27;] params[&#x27;recordLine&#x27;] = domain[&#x27;recordLine&#x27;] params[&#x27;value&#x27;] = domain[&#x27;value&#x27;] params[&#x27;ttl&#x27;] = domain[&#x27;ttl&#x27;] s = self.get_string_to_sign(&quot;GET&quot;, self.url, params) Signature = self.sign_str(self.secretKey, s, sha1) params[&#x27;Signature&#x27;] = Signature response = requests.get(self.endpoint, params=params) result = json.loads(response.text) if int(result[&#x27;code&#x27;]) != 0: raise Exception(&#x27;添加域名失败&#x27; + &#x27;:&#x27; + str(result[&#x27;code&#x27;]) + &#x27;:&#x27; + result[&#x27;message&#x27;]) data = result[&#x27;data&#x27;] print(&#x27;添加域名成功ip:%s,本地ip:%s,域名:%s&#x27; % (domain[&#x27;value&#x27;], domain[&#x27;localValue&#x27;], domain[&#x27;name&#x27;])) def updateServerIp(self, domain): timeStamp = int(time.time()) params = &#123;&#125; params[&#x27;Action&#x27;] = &#x27;RecordModify&#x27; params[&#x27;domain&#x27;] = self.domain params[&#x27;Nonce&#x27;] = self.nonce params[&#x27;SecretId&#x27;] = self.secretId params[&#x27;Timestamp&#x27;] = timeStamp params[&#x27;subDomain&#x27;] = domain[&#x27;subDomain&#x27;] params[&#x27;recordId&#x27;] = domain[&#x27;recordId&#x27;] params[&#x27;recordType&#x27;] = domain[&#x27;recordType&#x27;] params[&#x27;recordLine&#x27;] = domain[&#x27;recordLine&#x27;] params[&#x27;value&#x27;] = domain[&#x27;localValue&#x27;] params[&#x27;ttl&#x27;] = domain[&#x27;ttl&#x27;] s = self.get_string_to_sign(&quot;GET&quot;, self.url, params) Signature = self.sign_str(self.secretKey, s, sha1) params[&#x27;Signature&#x27;] = Signature response = requests.get(self.endpoint, params=params) result = json.loads(response.text) if int(result[&#x27;code&#x27;]) != 0: raise Exception(&#x27;更新域名失败&#x27; + &#x27;:&#x27; + str(result[&#x27;code&#x27;]) + &#x27;:&#x27; + result[&#x27;message&#x27;]) data = result[&#x27;data&#x27;] print(&#x27;更新域名成功源ip:%s,本地ip:%s,域名:%s&#x27; % (domain[&#x27;value&#x27;], domain[&#x27;localValue&#x27;], domain[&#x27;name&#x27;])) def deleteServerIp(self): pass def getLocalDomain(self, domain): res = requests.get(domain[&#x27;localDomain&#x27;]) ip = res.content.decode(&quot;utf-8&quot;).strip() return ip def clearDnsRecord(self): for domain in self.ddnsDomain: if not domain[&#x27;always&#x27;]: domain[&#x27;value&#x27;] = &#x27;&#x27; domain[&#x27;localValue&#x27;] = &#x27;&#x27; def run(self): self.getServerIp() for domain in self.ddnsDomain: if (not domain[&#x27;always&#x27;]): # 获取本地ip try: domain[&#x27;localValue&#x27;] = self.getLocalDomain(domain) except Exception as e: print(&quot;获取本地ip失败 不更新:%s,本地ip:%s,域名:%s&quot; % ( domain[&#x27;value&#x27;], domain[&#x27;localValue&#x27;], domain[&#x27;name&#x27;])) else: continue flag = False for remoteDomain in self.remoteRecords: if (domain[&#x27;subDomain&#x27;] == remoteDomain[&#x27;name&#x27;]): domain[&#x27;recordId&#x27;] = remoteDomain[&#x27;id&#x27;] domain[&#x27;value&#x27;] = remoteDomain[&#x27;value&#x27;] flag = True break if flag: if (domain[&#x27;value&#x27;] == domain[&#x27;localValue&#x27;]): pass # print(&quot;无需更新ip:%s,本地ip:%s,域名:%s&quot; % (domain[&#x27;value&#x27;],domain[&#x27;localValue&#x27;],domain[&#x27;name&#x27;])) else: self.updateServerIp(domain) continue else: domain[&#x27;value&#x27;] = domain[&#x27;localValue&#x27;] self.postServerIp(domain) self.clearDnsRecord() def start(self): start_time = int(time.time()) while self.running: next_time = int(time.time()) + self.runningPause if (next_time - start_time) &gt; self.runningPause: try: self.run() except Exception as e: print(e.__str__()) start_time = start_time + self.runningPause else: time.sleep(self.runningPause / 10) def get_string_to_sign(self, method, endpoint, params): s = method + endpoint + &quot;?&quot; query_str = &quot;&amp;&quot;.join(&quot;%s=%s&quot; % (k, params[k]) for k in sorted(params)) # print(s + query_str) return s + query_str def sign_str(self, key, s, method): hmac_str = hmac.new(key.encode(&quot;utf8&quot;), s.encode(&quot;utf8&quot;), method).digest() return base64.b64encode(hmac_str) t1 = tenXunDDNS_Helper() t1.start()d = DDnsHelper()d.excute() 最后双击运行~ OK 5. 运行原理和注意事项 原理:该脚本是通过查询公网IP接口:https://www.hosix.cn/ip 来判断公网ip是否发生了改变, 如果发生了改变, 就会调用腾讯云API去动态更新域名. 非常简单….. 注意事项: 1.该脚本需要持续运行, 如果是Linux系统, 直接挂后台运行即可, 该脚本资源消耗不高2.如果提示没requests 运行下, 打开cmd窗口输入: pip install requests3.如运行闪退, 请检查域名等是否正确填写 如有问题请评论或留言: &#x35;&#52;&#52;&#48;&#x31;&#48;&#49;&#54;&#x35;&#64;&#x71;&#x71;&#46;&#x63;&#111;&#109;","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"访问家庭内网","slug":"访问家庭内网","permalink":"https://pdyun.cc/tags/%E8%AE%BF%E9%97%AE%E5%AE%B6%E5%BA%AD%E5%86%85%E7%BD%91/"},{"name":"动态DDNS","slug":"动态DDNS","permalink":"https://pdyun.cc/tags/%E5%8A%A8%E6%80%81DDNS/"}],"author":"Peilin Deng"},{"title":"MyBatis 缓存模块","slug":"MyBatis-缓存","date":"2021-08-10T11:35:00.000Z","updated":"2022-03-02T12:52:22.582Z","comments":true,"path":"2021/08/10/MyBatis-缓存/","link":"","permalink":"https://pdyun.cc/2021/08/10/MyBatis-%E7%BC%93%E5%AD%98/","excerpt":"","text":"目录结构MyBatis作为一个强大的持久层框架，缓存是其必不可少的功能之一，Mybatis中的缓存分为一级缓存和二级缓存。但本质上是一样的，都是使用Cache接口实现的。缓存位于 org.apache.ibatis.cache包下。 通过结构我们能够发现Cache其实使用到了装饰器模式来实现缓存的处理。首先来看看Cache中的基础类的API // 煎饼加鸡蛋加香肠 “装饰者模式（Decorator Pattern）是指在不改变原有对象的基础之上，将功能附加到对象上，提供了比 继承更有弹性的替代方案（扩展原有对象的功能）。” 1. Cache 接口Cache接口是缓存模块中最核心的接口，它定义了所有缓存的基本行为，Cache接口的定义如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface Cache&#123; /** * 缓存对象的 ID * @return The identifier of this cache */ String getId(); /** * 向缓存中添加数据，一般情况下 key是CacheKey value是查询结果 * @param key Can be any object but usually it is a &#123;@link CacheKey&#125; * @param value The result of a select. */ void putObject(Object key, Object value); /** * 根据指定的key，在缓存中查找对应的结果对象 * @param key The key * @return The object stored in the cache. */ Object getObject(Object key); /** * As of 3.3.0 this method is only called during a rollback * for any previous value that was missing in the cache. * This lets any blocking cache to release the lock that * may have previously put on the key. * A blocking cache puts a lock when a value is null * and releases it when the value is back again. * This way other threads will wait * available instead of hitting the * 删除key对应的缓存数据 * * @param key The key * @return Not used */ Object removeObject(Object key); /** * Clears this cache instance. * 清空缓存 */ void clear(); /** * Optional. This method * 缓存的个数。 * @return The number of */ int getSize(); /*** Optional. As of 3.2.6* &lt;p&gt;* Any locking needed byprovider.* 获取读写锁* @return A ReadWriteLock */ default ReadWriteLock getReadWriteLock() &#123; return null; &#125;&#125; Cache接口的实现类很多，但是大部分都是装饰器，只有PerpetualCache提供了Cache接口的基本实现。 2. PerpetualCachePerpetualCache在缓存模块中扮演了ConcreteComponent的角色，其实现比较简单，底层使用 HashMap记录缓存项，具体的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * 在装饰器模式用 用来被装饰的对象 * 缓存中的 基本缓存处理的实现 * 其实就是一个 HashMap 的基本操作 */public class PerpetualCache implements Cache&#123; private final String id; // Cache 对象的唯一标识 // 用于记录缓存的Map对象 private final Map &lt; Object, Object &gt; cache = new HashMap &lt; &gt; (); public PerpetualCache(String id) &#123; this.id = id; &#125; @Override public String getId() &#123; return id; &#125; @Override public int getSize() &#123; return cache.size(); &#125; @Override public void putObject(Object key, Object value) &#123; cache.put(key, value); &#125; @Override public Object getObject(Object key) &#123; return cache.get(key); &#125; @Override public Object removeObject(Object key) &#123; return cache.remove(key); &#125; @Override public void clear() &#123; cache.clear(); &#125; @Override public boolean equals(Object o) &#123; if(getId() == null) &#123; throw new CacheException(&quot;Cache instances require an ID.&quot;); &#125; if(this == o) &#123; return true; &#125; if(!(o instanceof Cache)) &#123; return false; &#125; Cache otherCache = (Cache) o; // 只关心ID return getId().equals(otherCache.getId()); &#125; @Override public int hashCode() &#123; if(getId() == null) &#123; throw new CacheException(&quot;Cache instances require an ID.&quot;); &#125; // 只关心ID return getId().hashCode(); &#125;&#125; 然后我们可以来看看cache.decorators包下提供的装饰器。他们都实现了Cache接口。这些装饰器 都在PerpetualCache的基础上提供了一些额外的功能，通过多个组合实现一些特殊的需求。 3. BlockingCache通过名称我们能看出来是一个阻塞同步的缓存，它保证只有一个线程到缓存中查找指定的key对应的 数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229public class BlockingCache implements Cache&#123; private long timeout; // 阻塞超时时长 private final Cache delegate; // 被装饰的底层 Cache 对象 // 每个key 都有对象的 ReentrantLock 对象 private final ConcurrentHashMap &lt; Object, ReentrantLock &gt; locks; public BlockingCache(Cache delegate) &#123; // 被装饰的 Cache 对象 this.delegate = delegate; this.locks = new ConcurrentHashMap &lt; &gt; (); &#125; @Override public String getId() &#123; return delegate.getId(); &#125; @Override public int getSize() &#123; return delegate.getSize(); &#125; @Override public void putObject(Object key, Object value) &#123; try &#123; // 执行 被装饰的 Cache 中的方法 delegate.putObject(key, value); &#125; finally &#123; // 释放锁 releaseLock(key); &#125; &#125; @Override public Object getObject(Object key) &#123; acquireLock(key); // 获取锁 Object value = delegate.getObject(key); // 获取缓存数据 if(value != null) &#123; // 有数据就释放掉锁，否则继续持有锁 releaseLock(key); &#125; return value; &#125; @Override public Object removeObject(Object key) &#123; // despite of its name, this method is called only to release locks releaseLock(key); return null; &#125; @Override public void clear() &#123; delegate.clear(); &#125; private ReentrantLock getLockForKey(Object key) &#123; return locks.computeIfAbsent(key, k - &gt; new ReentrantLock()); &#125; private void acquireLock(Object key) &#123; Lock lock = getLockForKey(key); if(timeout &gt; 0) &#123; try &#123; boolean acquired = lock.tryLock(timeout, TimeUnit.MILLISECONDS); if(!acquired) &#123; throw new CacheException(&quot;Couldn&#x27;t get a lock in &quot; + timeout + &quot; for the key &quot; + key + &quot; at the cache &quot; + delegate.getId()); &#125; &#125; catch(InterruptedException e) &#123; throw new CacheException(&quot;Got interrupted while trying to acquire lock for key &quot; + key, e); &#125; &#125; else &#123; lock.lock(); &#125; &#125; private void releaseLock(Object key) &#123; ReentrantLock lock = locks.get(key); if(lock.isHeldByCurrentThread()) &#123; lock.unlock(); &#125; &#125; public long getTimeout() &#123; return timeout; &#125; public void setTimeout(long timeout) &#123; this.timeout = timeout; &#125; &#125; public class BlockingCache implements Cache &#123; private long timeout; // 阻塞超时时长 private final Cache delegate; // 被装饰的底层 Cache 对象 // 每个key 都有对象的 ReentrantLock 对象 private final ConcurrentHashMap &lt; Object, ReentrantLock &gt; locks; public BlockingCache(Cache delegate) &#123; // 被装饰的 Cache 对象 this.delegate = delegate; this.locks = new ConcurrentHashMap &lt; &gt; (); &#125; @Override public String getId() &#123; return delegate.getId(); &#125; @Override public int getSize() &#123; return delegate.getSize(); &#125; @Override public void putObject(Object key, Object value) &#123; try &#123; // 执行 被装饰的 Cache 中的方法 delegate.putObject(key, value); &#125; finally &#123; // 释放锁 releaseLock(key); &#125; &#125; @Override public Object getObject(Object key) &#123; acquireLock(key); // 获取锁 Object value = delegate.getObject(key); // 获取缓存数据 if(value != null) &#123; // 有数据就释放掉锁，否则继续持有锁 releaseLock(key); &#125; return value; &#125; @Override public Object removeObject(Object key) &#123; // despite of its name, this method is called only to release locks releaseLock(key); return null; &#125; @Override public void clear() &#123; delegate.clear(); &#125; private ReentrantLock getLockForKey(Object key) &#123; return locks.computeIfAbsent(key, k - &gt; new ReentrantLock()); &#125; private void acquireLock(Object key) &#123; Lock lock = getLockForKey(key); if(timeout &gt; 0) &#123; try &#123; boolean acquired = lock.tryLock(timeout, TimeUnit.MILLISECONDS); if(!acquired) &#123; throw new CacheException(&quot;Couldn&#x27;t get a lock in &quot; + timeout + &quot; for the key &quot; + key + &quot; at the cache &quot; + delegate.getId()); &#125; &#125; catch(InterruptedException e) &#123; throw new CacheException(&quot;Got interrupted while trying to acquire lock for key &quot; + key, e); &#125; &#125; else &#123; lock.lock(); &#125; &#125; private void releaseLock(Object key) &#123; ReentrantLock lock = locks.get(key); if(lock.isHeldByCurrentThread()) &#123; lock.unlock(); &#125; &#125; public long getTimeout() &#123; return timeout; &#125; public void setTimeout(long timeout) &#123; this.timeout = timeout; &#125; &#125; 通过源码我们能够发现， BlockingCache本质上就是在我们操作缓存数据的前后通过ReentrantLock对象来实现了加锁和解锁操作。其他的具体实现类，大家可以自行查阅 缓存实现类 描述 作用 装饰条件 基本缓存 缓存基本实现类 默认是PerpetualCache ， 也可以 自定义比如RedisCache、EhCache等 ，具备基本功能的缓存类 无 LruCache LRU策略的缓存 当缓存到达上限时候 ， 删除最近最少使用的缓存 （ Least Recently Use） eviction=”LRU” （默认） FifoCache FIFO策略的缓存 当缓存到达上限时候 ，删除最先入队的缓存 eviction=”FIFO” SoftCacheWeakCache 带清理策略的缓存 通过JVM的软引用和弱引用来实现 缓存，当JVM内存不足时，会自动清理掉这些缓存，基于SoftReference和WeakReference eviction=”SOFT”eviction=”WEAK” LoggingCache 带日志功能的缓存 比如：输出缓存命中率 基本 SynchronizedCache 同步缓存 基于synchronized关键字实现，解决并发问题 基本 BlockingCache 阻塞缓存 通过在get/put方式中加锁，保证只有一个线程操作缓存，基于Java重入锁实现 blocking=true SerializedCache 支持序列化的缓存 将对象序列化以后存到缓存中，取出时反序列化 readOnly=false （默认） ScheduledCache 定时调度的缓存 在进行 get/put/remove/getSize 等操作前，判断缓存时间是否超过了设置的最长缓存时间（默认是一小时），如果是则清空缓存– 即每隔一段时间清空一次缓存 flush nterval不为空 TransactionalCache 事务缓存 在二级缓存中使用，可一次存入多个缓存，移除多个缓存 在TransactionalCacheManager 中用Map维护对应关系 4. 缓存的应用4.1 缓存对应的初始化在Configuration初始化的时候会为我们的各种Cache实现注册对应的别名 在解析settings标签的时候，设置的默认值有如下 cacheEnabled默认为true，localCacheScope默认为 SESSION 在解析映射文件的时候会解析我们相关的cache标签 然后解析映射文件的cache标签后会在Configuration对象中添加对应的数据在 12345678910111213141516171819private void cacheElement(XNode context)&#123; // 只有 cache 标签不为空才解析 if(context != null) &#123; String type = context.getStringAttribute(&quot;type&quot;, &quot;PERPETUAL&quot;); Class &lt;? extends Cache &gt; typeClass = typeAliasRegistry.resolveAlias(type); String eviction = context.getStringAttribute(&quot;eviction&quot;, &quot;LRU&quot;); Class &lt;? extends Cache &gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); Long flushInterval = context.getLongAttribute(&quot;flushInterval&quot;); Integer size = context.getIntAttribute(&quot;size&quot;); boolean readWrite = !context.getBooleanAttribute(&quot;readOnly&quot;, false); boolean blocking = context.getBooleanAttribute(&quot;blocking&quot;, false); Properties props = context.getChildrenAsProperties(); builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); &#125;&#125; 继续 然后我们可以发现 如果存储 cache 标签，那么对应的 Cache对象会被保存在 currentCache 属性中。 进而在 Cache 对象 保存在了 MapperStatement 对象的 cache 属性中。 然后我们再看看openSession的时候又做了哪些操作，在创建对应的执行器的时候会有缓存的操作 123456789101112131415161718192021222324252627public Executor newExecutor(Transaction transaction, ExecutorType executorType)&#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if(ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if(ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; // 默认 SimpleExecutor executor = new SimpleExecutor(this, transaction); &#125; // 二级缓存开关，settings 中的 cacheEnabled 默认是 true if(cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; // 植入插件的逻辑，至此，四大对象已经全部拦截完毕 executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 也就是如果 cacheEnabled 为 true 就会通过 CachingExecutor 来装饰executor 对象，然后就是在 执行SQL操作的时候会涉及到缓存的具体使用。这个就分为一级缓存和二级缓存，这个我们来分别介绍 4.2 一级缓存一级缓存也叫本地缓存（Local Cache）， MyBatis的一级缓存是在会话（SqlSession）层面进行缓 存的。 MyBatis的一级缓存是默认开启的，不需要任何的配置（如果要关闭， localCacheScope设置为 STATEMENT）。在BaseExecutor对象的query方法中有关闭一级缓存的逻辑 然后我们需要考虑下在一级缓存中的 PerpetualCache 对象在哪创建的，因为一级缓存是Session级 别的缓存，肯定需要在Session范围呢创建，其实PerpetualCache的实例化是在BaseExecutor的构造方法中创建的 12345678910protected BaseExecutor(Configuration configuration, Transaction transaction)&#123; this.transaction = transaction; this.deferredLoads = new ConcurrentLinkedQueue &lt; &gt; (); this.localCache = new PerpetualCache(&quot;LocalCache&quot;); this.localOutputParameterCache = new PerpetualCache(&quot;LocalOutputParameterCache&quot;); this.closed = false; this.configuration = configuration; this.wrapper = this;&#125; 一级缓存的具体实现也是在BaseExecutor的query方法中来实现的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public &lt; E &gt; List &lt; E &gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException&#123; // 异常体系之 ErrorContext ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId()); if(closed) &#123; throw new ExecutorException(&quot;Executor was closed.&quot;); &#125; if(queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; // flushCache=&quot;true&quot;时，即使是查询，也清空一级缓存 clearLocalCache(); &#125; List &lt; E &gt; list; try &#123; // 防止递归查询重复处理缓存 queryStack++; // 查询一级缓存 // ResultHandler 和 ResultSetHandler的区别 list = resultHandler == null ? (List &lt; E &gt; ) localCache.getObject(key) : null; if(list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; // 真正的查询流程 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if(queryStack == 0) &#123; for(DeferredLoad deferredLoad: deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); if(configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 clearLocalCache(); &#125; &#125; return list;&#125; 一级缓存的验证： 同一个Session中的多个相同操作 123456789101112131415161718192021@Testpublic void test1() throws Exception&#123; // 1.获取配置文件 InputStream in = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;); // 2.加载解析配置文件并获取SqlSessionFactory对象 SqlSessionFactory factory = new SqlSessionFactoryBuilder().build( in ); // 3.根据SqlSessionFactory对象获取SqlSession对象 SqlSession sqlSession = factory.openSession(); // 4.通过SqlSession中提供的 API方法来操作数据库 List &lt; User &gt; list = sqlSession.selectList(&quot;com.gupaoedu.mapper.UserMapper.selectUserList&quot;); System.out.println(list.size()); // 一级缓存测试 System.out.println(&quot;---------&quot;); list = sqlSession.selectList(&quot;com.gupaoedu.mapper.UserMapper.selectUserList&quot;); System.out.println(list.size()); // 5.关闭会话 sqlSession.close();&#125; 输出日志 1234567891011121314151617181920Setting autocommit to false on JDBC Connection[com.mysql.cj.jdbc.ConnectionImpl@477b4cdf]==&gt; Preparing: select * from t_user ==&gt; Parameters: &lt;== Columns: id, user_name, real_name, password, age, d_id&lt;== Row: 1, zhangsan, 张三 , 123456, 18, null&lt;== Row: 2, lisi, 李四 , 11111, 19, null&lt;== Row: 3, wangwu, 王五 , 111, 22, 1001&lt;== Row: 4, wangwu, 王五 , 111, 22, 1001&lt;== Row: 5, wangwu, 王五 , 111, 22, 1001&lt;== Row: 6, wangwu, 王五 , 111, 22, 1001&lt;== Row: 7, wangwu, 王五 , 111, 22, 1001&lt;== Row: 8, aaa, bbbb, null, null, null&lt;== Row: 9, aaa, bbbb, null, null, null&lt;== Row: 10, aaa, bbbb, null, null, null&lt;== Row: 11, aaa, bbbb, null, null, null&lt;== Row: 12, aaa, bbbb, null, null, null&lt;== Row: 666, hibernate, 持久层框架 , null, null, null&lt;== Total: 1313---------13 可以看到第二次查询没有经过数据库操作 不同Session的相同操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Setting autocommit to false on JDBC Connection[com.mysql.cj.jdbc.ConnectionImpl@477b4cdf]==&gt; Preparing: select * from t_user ==&gt; Parameters: &lt;== Columns: id, user_name, real_name, password, age, d_id&lt;== Row: 1, zhangsan, 张三 , 123456, 18, null&lt;== Row: 2, lisi, 李四 , 11111, 19, null&lt;== Row: 3, wangwu, 王五 , 111, 22, 1001&lt;== Row: 4, wangwu, 王五 , 111, 22, 1001&lt;== Row: 5, wangwu, 王五 , 111, 22, 1001&lt;== Row: 6, wangwu, 王五 , 111, 22, 1001&lt;== Row: 7, wangwu, 王五 , 111, 22, 1001&lt;== Row: 8, aaa, bbbb, null, null, null&lt;== Row: 9, aaa, bbbb, null, null, null&lt;== Row: 10, aaa, bbbb, null, null, null&lt;== Row: 11, aaa, bbbb, null, null, null&lt;== Row: 12, aaa, bbbb, null, null, null&lt;== Row: 666, hibernate, 持久层框架 , null, null, null&lt;== Total: 1313Resetting autocommit to true on JDBC Connection[com.mysql.cj.jdbc.ConnectionImpl@477b4cdf]Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@477b4cdf] Returned connection 1199262943 to pool.---------Opening JDBC ConnectionChecked out connection 1199262943 from pool.Setting autocommit to false on JDBC Connection[com.mysql.cj.jdbc.ConnectionImpl@477b4cdf]==&gt; Preparing: select * from t_user==&gt; Parameters:&lt;== Columns: id, user_name, real_name, password, age, d_id&lt;== Row: 1, zhangsan, 张三 , 123456, 18, null&lt;== Row: 2, lisi, 李四 , 11111, 19, null&lt;== Row: 3, wangwu, 王五 , 111, 22, 1001&lt;== Row: 4, wangwu, 王五 , 111, 22, 1001&lt;== Row: 5, wangwu, 王五 , 111, 22, 1001&lt;== Row: 6, wangwu, 王五 , 111, 22, 1001&lt;== Row: 7, wangwu, 王五 , 111, 22, 1001&lt;== Row: 8, aaa, bbbb, null, null, null&lt;== Row: 9, aaa, bbbb, null, null, null&lt;== Row: 10, aaa, bbbb, null, null, null&lt;== Row: 11, aaa, bbbb, null, null, null&lt;== Row: 12, aaa, bbbb, null, null, null&lt;== Row: 666, hibernate, 持久层框架 , null, null, null &lt;== Total: 13Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@477b4cdf] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@477b4cdf] Returned connection 1199262943 to pool.--------- Opening JDBC Connection Checked out connection 1199262943 from pool.Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@477b4cdf] ==&gt; Preparing: select * from t_user ==&gt; Parameters:&lt;== Columns: id, user_name, real_name, password, age, d_id &lt;== Row: 1, zhangsan, 张三, 123456, 18, null &lt;== Row: 2, lisi, 李四, 11111, 19, null &lt;== Row: 3, wangwu, 王五, 111, 22, 1001 &lt;== Row: 4, wangwu, 王五, 111, 22, 1001 &lt;== Row: 5, wangwu, 王五, 111, 22, 1001 &lt;== Row: 6, wangwu, 王五, 111, 22, 1001 &lt;== Row: 7, wangwu, 王五, 111, 22, 1001 &lt;== Row: 8, aaa, bbbb, null, null, null &lt;== Row: 9, aaa, bbbb, null, null, null &lt;== Row: 10, aaa, bbbb, null, null, null &lt;== Row: 11, aaa, bbbb, null, null, null &lt;== Row: 12, aaa, bbbb, null, null, null &lt;== Row: 666, hibernate, 持久层框架, null, null, null &lt;== Total: 13 13Resetting autocommit to true on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@477b4cdf] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@477b4cdf] Returned connection 1199262943 to pool. 通过输出我们能够发现，不同的Session中的相同操作，一级缓存是没有起作用的。 4.3 二级缓存二级缓存是用来解决一级缓存不能跨会话共享的问题的，范围是namespace级别的，可以被多个SqlSession共享（只要是同一个接口里面的相同方法，都可以共享），生命周期和应用同步。 二级缓存的设置，首先是settings中的cacheEnabled要设置为true，当然默认的就是为true，这个步骤决定了在创建Executor对象的时候是否通过CachingExecutor来装饰。 那么设置了cacheEnabled标签为true是否就意味着 二级缓存是否一定可用呢？当然不是，我们还需要在 对应的映射文件中添加 cache 标签才行。 123456&lt;!-- 声明这个namespace使用二级缓存 --&gt;&lt;cache type=&quot;org.apache.ibatis.cache.impl.PerpetualCache&quot; size=&quot;1024&quot; &lt;!—最多缓存对象个数，默认1024--&gt; eviction=&quot;LRU&quot; &lt;!— 回收策略--&gt; flushInterval=&quot;120000&quot; &lt;!— 自动刷新时间 ms，未配置时只有调用时刷新--&gt; readOnly=&quot;false&quot;/&gt; &lt;!—默认是false（安全） ，改为true可读写时，对象必须支持序列化 --&gt; cache属性详解： 属性 含义 取值 type 缓存实现类 需要实现Cache接口，默认是PerpetualCache，可以使用第三方缓存 size 最多缓存对象个数 默认1024 eviction 回收策略（缓存淘汰算法） LRU – 最近最少使用的：移除最长时间不被使用的对象（默认）。FIFO– 先进先出：按对象进入缓存的顺序来移除它们。SOFT – 软引用：移除基于垃圾回收器状态和软引用规则的对象。WEAK – 弱引用：更积极地移除基于垃圾收集器状态和弱引用规则的对象。 flushInterval 定时自动清空缓存间隔 自动刷新时间，单位 ms，未配置时只有调用时刷新 readOnly 是否只读 true：只读缓存；会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。false：读写缓存；会返回缓存对象的拷贝（通过序列化），不会共享。这会慢一些，但是安全，因此默认是 false。改为false可读写时，对象必须支持序列化。 blocking 启用阻塞缓存 通过在get/put方式中加锁，保证只有一个线程操作缓存，基于Java重入锁实现 再来看下cache标签在源码中的体现，创建cacheKey 12345678@Overridepublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; // 获取SQL BoundSql boundSql = ms.getBoundSql(parameterObject); // 创建CacheKey：什么样的SQL是同一条SQL？ &gt;&gt; CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125; createCacheKey自行进去查看 而这看到的和我们前面在缓存初始化时看到的 cache 标签解析操作是对应上的。所以我们要开启二级缓存两个条件都要满足 这样的设置表示当前的映射文件中的相关查询操作都会触发二级缓存，但如果某些个别方法我们不希望走二级缓存怎么办呢？ 我们可以在标签中添加一个 useCache=false 来实现的设置不使用二级缓存 还有就是当我们执行的对应的DML操作，在MyBatis中会清空对应的二级缓存和一级缓存。 12345678private void flushCacheIfRequired(MappedStatement ms) &#123; Cache cache = ms.getCache(); // 增删改查的标签上有属性： flushCache=&quot;true&quot; （select语句默认是false） // 一级二级缓存都会被清理 if (cache != null &amp;&amp; ms.isFlushCacheRequired()) &#123; tcm.clear(cache); &#125;&#125; 在解析映射文件的时候DML操作flushCacheRequired为true 4.4 第三方缓存在实际开发的时候我们一般也很少使用MyBatis自带的二级缓存，这时我们会使用第三方的缓存工具Ehcache获取Redis来实现,那么他们是如何来实现的呢？ https://github.com/mybatis/redis-cache 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-redis&lt;/artifactId&gt; &lt;version&gt;1.0.0-beta2&lt;/version&gt;&lt;/dependency&gt; 然后加上Cache标签的配置 12345&lt;cache type=&quot;org.mybatis.caches.redis.RedisCache&quot; eviction=&quot;FIFO&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot; readOnly=&quot;true&quot;/&gt; 然后添加redis的属性文件 12345host=192.168.100.120port=6379connectionTimeout=5000soTimeout=5000database=0 测试效果 数据存储到了Redis中 然后大家也可以自行分析下第三方的Cache是如何替换掉PerpetualCache的，因为PerpetualCache是基于HashMap处理的，而RedisCache是基于Redis来存储缓存数据的。 提示 缓存模块大概就介绍到此。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://pdyun.cc/tags/MyBatis/"},{"name":"缓存","slug":"缓存","permalink":"https://pdyun.cc/tags/%E7%BC%93%E5%AD%98/"}],"author":"Peilin Deng"},{"title":"Hello World","slug":"newpapername","date":"2021-08-06T05:06:24.000Z","updated":"2021-08-10T11:21:31.361Z","comments":true,"path":"2021/08/06/newpapername/","link":"","permalink":"https://pdyun.cc/2021/08/06/newpapername/","excerpt":"","text":"念两句诗 挑选中... jinrishici.load(function(result) { poem.innerHTML = result.data.content info.innerHTML = '【' + result.data.origin.dynasty + '】' + result.data.origin.author + '《' + result.data.origin.title + '》' document.getElementById(\"poem\").value(poem); document.getElementById(\"info\").value(info); });","categories":[],"tags":[]}],"categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"},{"name":"面试答疑","slug":"面试答疑","permalink":"https://pdyun.cc/categories/%E9%9D%A2%E8%AF%95%E7%AD%94%E7%96%91/"},{"name":"设计模式","slug":"摘抄笔记/设计模式","permalink":"https://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"算法小抄","slug":"算法小抄","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/"},{"name":"数据结构","slug":"算法小抄/数据结构","permalink":"https://pdyun.cc/categories/%E7%AE%97%E6%B3%95%E5%B0%8F%E6%8A%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://pdyun.cc/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"Spring","slug":"Spring","permalink":"https://pdyun.cc/tags/Spring/"},{"name":"行为型设计模式","slug":"行为型设计模式","permalink":"https://pdyun.cc/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型设计模式","slug":"结构型设计模式","permalink":"https://pdyun.cc/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"创建型设计模式","slug":"创建型设计模式","permalink":"https://pdyun.cc/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"数组","slug":"数组","permalink":"https://pdyun.cc/tags/%E6%95%B0%E7%BB%84/"},{"name":"排序","slug":"排序","permalink":"https://pdyun.cc/tags/%E6%8E%92%E5%BA%8F/"},{"name":"二叉树","slug":"二叉树","permalink":"https://pdyun.cc/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"https://pdyun.cc/tags/%E9%93%BE%E8%A1%A8/"},{"name":"队列","slug":"队列","permalink":"https://pdyun.cc/tags/%E9%98%9F%E5%88%97/"},{"name":"二叉堆","slug":"二叉堆","permalink":"https://pdyun.cc/tags/%E4%BA%8C%E5%8F%89%E5%A0%86/"},{"name":"位运算","slug":"位运算","permalink":"https://pdyun.cc/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://pdyun.cc/tags/SpringBoot/"},{"name":"MySql","slug":"MySql","permalink":"https://pdyun.cc/tags/MySql/"},{"name":"事务","slug":"事务","permalink":"https://pdyun.cc/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://pdyun.cc/tags/MyBatis/"},{"name":"插件","slug":"插件","permalink":"https://pdyun.cc/tags/%E6%8F%92%E4%BB%B6/"},{"name":"访问家庭内网","slug":"访问家庭内网","permalink":"https://pdyun.cc/tags/%E8%AE%BF%E9%97%AE%E5%AE%B6%E5%BA%AD%E5%86%85%E7%BD%91/"},{"name":"动态DDNS","slug":"动态DDNS","permalink":"https://pdyun.cc/tags/%E5%8A%A8%E6%80%81DDNS/"},{"name":"缓存","slug":"缓存","permalink":"https://pdyun.cc/tags/%E7%BC%93%E5%AD%98/"}]}