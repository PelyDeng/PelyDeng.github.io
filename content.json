{"meta":{"title":"牧场小站","subtitle":"","description":"IT 小站， 记录美好码园生活","author":"Peilin Deng","url":"http://pdyun.cc","root":"/"},"pages":[{"title":"所有分类","date":"2021-08-06T12:55:40.000Z","updated":"2021-08-07T05:19:51.774Z","comments":false,"path":"categories/index.html","permalink":"http://pdyun.cc/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2021-08-06T12:56:57.000Z","updated":"2021-08-07T08:23:50.870Z","comments":false,"path":"about/index.html","permalink":"http://pdyun.cc/about/index.html","excerpt":"","text":"正在播放《每天一遍，可莉完蛋》 ●━───────00:04 ⇆ ᐊ Ⅱ ᐅ ↻ 念两句诗 挑选中... jinrishici.load(function(result) { poem.innerHTML = result.data.content info.innerHTML = '【' + result.data.origin.dynasty + '】' + result.data.origin.author + '《' + result.data.origin.title + '》' document.getElementById(\"poem\").value(poem); document.getElementById(\"info\").value(info); });"},{"title":"标签页","date":"2021-08-06T12:56:28.000Z","updated":"2021-08-07T05:20:48.804Z","comments":false,"path":"tags/index.html","permalink":"http://pdyun.cc/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MySql 执行计划","slug":"MySql-执行计划","date":"2021-08-25T14:00:18.000Z","updated":"2021-08-25T14:02:04.819Z","comments":true,"path":"2021/08/25/MySql-执行计划/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/","excerpt":"执行计划类型const直接通过聚簇索引或者二级索引+聚簇索引回源，查询到想要的数据。这种根据索引可以直接快速查询到数据的过程，在执行计划里称之为const。二级索引必须是unique，才是const。否则就是ref ref一般走索引都是ref，如果是组合索引，则要求查询条件必须是从索引最左侧开始连续多列都是等值比较。 range对索引列使用范围查询。 index只需要遍历二级索引就可以拿到想要的数据，而不需要回源到聚簇索引的访问方式。索引：idx(S21,S22,S23,S24)；SQL：SELECT S21,S22,S23 FROM TABLE WHERE S22 = ‘X’ AND S23 = ‘Z’;第一反应：这个SQL无法直接从联合索引树的根节点进行二分查找。基于上面的索引以及SQL，可以直接遍历联合索引树的叶子节点，找到所需要的数据，不需要再回源到聚簇索引进行二次查询，这种方式就是使用的index访问。虽然遍历了叶子节点，但是叶子节点内容少。也比回表查询快。","text":"执行计划类型const直接通过聚簇索引或者二级索引+聚簇索引回源，查询到想要的数据。这种根据索引可以直接快速查询到数据的过程，在执行计划里称之为const。二级索引必须是unique，才是const。否则就是ref ref一般走索引都是ref，如果是组合索引，则要求查询条件必须是从索引最左侧开始连续多列都是等值比较。 range对索引列使用范围查询。 index只需要遍历二级索引就可以拿到想要的数据，而不需要回源到聚簇索引的访问方式。索引：idx(S21,S22,S23,S24)；SQL：SELECT S21,S22,S23 FROM TABLE WHERE S22 = ‘X’ AND S23 = ‘Z’;第一反应：这个SQL无法直接从联合索引树的根节点进行二分查找。基于上面的索引以及SQL，可以直接遍历联合索引树的叶子节点，找到所需要的数据，不需要再回源到聚簇索引进行二次查询，这种方式就是使用的index访问。虽然遍历了叶子节点，但是叶子节点内容少。也比回表查询快。 什么情况下一次查询用到多个索引现有索引：idx(x1)，idx(x2)现有SQL：SELECT * FROM TABLE WHERE X1 = XX AND X2 = ZZ；在一般情况下，查询优化器生成执行计划只会按照其中一个字段的索引树去查找，然后再回表到聚簇索引查完整数据，然后根据另一个字段的值过滤。当按照某个索引值查询之后得到了上万条的数据，此时就要考虑再通过另一个索引查询，将两个索引得到的结果的主键进行求交集，然后再去回表查询。 多表关联的SQL语句的执行计划驱动表与被驱动表在多表关联查询时，一般是通过部分条件先从一张表中取出符合条件的数据，然后再在这些数据中进行后续的条件匹配。先查询的表叫做驱动表，后查询的表就叫被驱动表。 内连接与外连接 内连接：INNER JOIN，连接条件写在WHERE中，并且按照表与表之间的字段关系严格判断，为空的不会显示 外连接：[LEFT | RIGHT] OUTER JOIN，连接条件写在ON中；如果是LEFT则表示左侧表中的数据不管右侧表里是否有关联都会返回出来，右侧大不了显示为NULL。 嵌套循环关联多表关联查询，往往都是利用驱动表的结果，去被驱动表中通过where条件，on条件进行遍历匹配。因此如果关联表很多，就会因为遍历的效率影响整个SQL的执行效率，所以要合理的在驱动表和被驱动表上建立合适的索引。 执行成本的计算成本的组成 IO成本 CPU成本 计算方式 MYSQL规定读取一页花费的成本默认是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。 不管读取到的记录需不需要检测是否符合搜索条件，其成本都是0.2 通过show table status like ‘表名’，可以查看指定表的一些信息 rows是表中的记录数（对于innodb来说这个是个估计值），data_length是聚簇索引的字节数大小。通过data_length/(1024*16)可以算出有多少页，就能算出全表扫描的成本。 IO成本=数据页数量*1+1.1 CPU成本=行记录数*0.2+1.0 总成本=IO成本+CPU成本 计算示例数据页数=(98304/1024)/16=6行记录数=603总成本=61+0.2603=126.6 二级索引要注意的点 二级索引在计算时要先计算二级索引根据条件查一波数据的IO成本，比如score between 25,200 or score between 250,300，这是2个范围，否则score=XX就是一个区间。 一般一个区间可以简单的认为是一个数据页，也可能是n个数据页，反正是个位数级别的。 二级索引得到的结果再回表，一条数据回表一次。 a104","categories":[],"tags":[],"author":"Peilin Deng"},{"title":"MySql 关于索引的一些特殊情况","slug":"MySql-关于索引的一些特殊情况","date":"2021-08-25T13:59:00.000Z","updated":"2021-08-25T13:59:36.508Z","comments":true,"path":"2021/08/25/MySql-关于索引的一些特殊情况/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5/","excerpt":"","text":"范围查询数据量过大导致索引失效存在索引idx_fk_customer_id(customer_id)，表中数据16000条。 12EXPLAIN SELECT * FROM rental WHERE customer_id&lt;102; # 使用索引EXPLAIN SELECT * FROM rental WHERE customer_id&lt;103; # 全表扫描 当范围查询时，如果符合条件的数据过多时，因为建立索引的字段虽然在索引树上有序，但是这一部分数据还要回源到聚簇索引中再次查询，并且得到的数据在磁盘上并不是连续的，这样会产生大量的随机IO，而随机IO是非常慢的，与其这样还不如全表扫描。全表扫描最起码是顺序IO。 Semi join半连接 explain列中filtered为什么有时候不准 Extra列中Using index condition都是索引下推吗？","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 索引机制","slug":"MySql-索引机制","date":"2021-08-25T13:55:00.000Z","updated":"2021-08-25T13:55:41.870Z","comments":true,"path":"2021/08/25/MySql-索引机制/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E7%B4%A2%E5%BC%95%E6%9C%BA%E5%88%B6/","excerpt":"主键索引的设计每个数据页中都有一个页目录，可以方便在当前数据页中进行数据的查询。但是如果有多个数据页的情况下，对于一个主键的查询，得知数据在哪个数据页显得尤为重要。因此针对主键设计了一个主键目录，就是把每个数据页的页号以及数据页中最小的主键放在一起，组成一个索引的目录，如下图：基于主键目录，先通过主键目录可以对比得到查询的数据可能在哪个数据页，然后到对应的数据页中基于二分法查找。 索引页","text":"主键索引的设计每个数据页中都有一个页目录，可以方便在当前数据页中进行数据的查询。但是如果有多个数据页的情况下，对于一个主键的查询，得知数据在哪个数据页显得尤为重要。因此针对主键设计了一个主键目录，就是把每个数据页的页号以及数据页中最小的主键放在一起，组成一个索引的目录，如下图：基于主键目录，先通过主键目录可以对比得到查询的数据可能在哪个数据页，然后到对应的数据页中基于二分法查找。 索引页 概念当数据量超级大的时候，数据页的数量也非常的多。主键目录就得存放大量的数据页和最小主键值。性能没有得到突破。此时，通过索引页来存放索引数据。需要注意的是，索引页中，出现了类型为1的行数据。表示的是B+树非叶子节点。虽然索引页多了，但是又应该到哪个索引页中去查主键数据，此时又可以把索引页进行一次“索引”，在更高层的索引层级中，保存了每个索引页里的最小主键值和索引页号。（如果跟高层的索引层级中数据也嫌多，那就继续套娃，这就形成了一个树结构） 基于索引页的查找如果要查询一个数据的主键为19，就应该先从顶层的索引页60里去找，通过二分法的方式得到下层要去索引页17中查找。然后一直找到了数据可能在数据页2中，然后去数据页2中，通过页目录，找到对应的槽位，读取数据。 索引分类聚簇索引如果在一个B+树索引数据结构中，叶子节点就是数据页本身，那么可以称这个B+数为聚簇索引。（innodb默认创建的一套基于主键的索引结构，表中的数据直接放在聚簇索引里，作为叶子节点的数据页） 二级索引如果要对非主键的字段创建索引，那么会重新生成一颗B+树，叶子节点也是数据页，但是数据页中只会存放主键字段和对应的索引字段。排序规则也是按照创建索引字段的顺序来严格排序的，也会有页分裂来保证顺序。 回表在二级索引上进行查询时，比如对name字段建立的二级索引，当select name from xxx where id = xxx时，通过叶子节点中的数据页内容就能直接返回。但是如果select * from xxx where name = xxx时，叶子节点的数据不足以返回，还得通过主键去聚簇索引中定位到主键对应的完整数据行，此时才能把select * 要查询的字段值全部拿出来。 联合索引多个字段建立二级索引，也是一颗独立的B+树，叶子节点的数据页中包含了id，colA，colB。然后按照colA排序，如果colA相同就按照colB排序。 插入数据时如何维护不同索引的B+树 创建表时，就一个数据页。目前为空 开始插入数据，这个初始的数据页就是根页。数据页内部有一个基于主键的页目录，此时通过页目录查询就行。 数据越来越多数据页满了，创建一个新的数据页，然后把根页中的数据拷贝过去，同时再搞一个新的数据页，根据主键值的大小进行挪动，让两个数据页根据主键值排序，使得第二个数据页的主键值都大于第一个数据页的主键值。此时根页就变成了索引页。根页中存放了两个数据页的页号和他们里面的最小的主键值。 随着不停的增加数据，数据页不断的页分裂。索引页中的数据页索引条目越来越多，索引页开始分裂成两个索引页，然后根页继续往上走一个层级，引用两个索引页。 然后开始套娃。 与聚簇索引不同的是，二级索引的B+树的索引页中，除了存放页号和最小的索引字段值外，还会额外存放最小索引字段对应的主键值。 使用索引的几个原则 索引idx_abc(a,b,c) 等值匹配原则where条件中字段采用等于连接，并且完全包含了索引中的所有字段。比如where a=1 and b=2 and c=3 最左侧列匹配采用索引中左侧的部分字段来查询，不能跳跃。比如where a=1 and b=2 可以使用索引。但是where a=1 and c=3 不行。 最左前缀匹配原则如果使用like查询，则最左侧不能出现通配符。比如where a like ‘1%’。 范围查找规则where语句里如果有范围查询，那只有对联合索引里最左侧的列进行范围查询才能用到索引！后续的字段无法使用到索引。比如where a &gt; 1 and a&lt;5 and b&lt;1只会使用a列的索引 等值匹配+范围匹配按照前面的列等值匹配，后面的列范围匹配，需要注意的是，如果多列范围匹配只会生效最靠左的那一列。比如where a=1 and b &gt;1 and b&lt;4 and c&lt;5只会使用a,b列的索引 利用索引优化查询SQL排序如何利用索引对语句SELECT * FROM TABLE ORDER BY TOTAL_SCORE DESC, NAME DESC LIMIT 20,10语句主要是把表根据总分降序，名字降序排序后从第20页取出10条数据，可以建立（TOTAL_SCORE,NAME）的一个索引，这样的话，直接从索引树中最大的数据开始进行偏移，然后读取10条数据就行。因为索引树本身自带排序。这样的索引建立有一个前提，就是ORDER BY后面要么都是升序，要么都是降序，不能出现部分升序，部分降序。 SQL分组如何利用索引通常而言，对于group by后的字段，最好也是按照联合索引里的最左侧的字段开始，按顺序排列开来，这样的话，其实就可以完美的运用上索引来直接提取一组一组的数据，然后针对每一组的数据执行聚合函数就可以了。 覆盖索引如果我们建立了一个索引idx_name_age，那么我们在执行select * from student where name = ‘张三’ and age &gt;5 时，会先扫描一次idx_name_age索引，拿到主键后再去聚簇索引中查询一次，这叫做回表。但是如果查询的字段恰好是索引中的一部分，比如select name，这样的话，直接通过索引树就能够直接返回，这叫做覆盖索引。 如何尽可能的减少回表在利用联合索引查询的实际情况下，往往可能因为回表到聚簇索引的次数太多，直接进行全表扫描。因此要尽可能的减少回表次数。 尽可能在SQL中指定要查询的字段名，尽量走覆盖索引 即便是要回表，尽可能使用limit，where等语句限定回表到聚簇索引的次数。 设计索引的考虑因素 实际查询中在where，group by,order by后面高频出现的字段 基数比较大的字段（基数：不同的数据对于同一个列的不同值，比如性别这一列的基数最大只能是2，而出生年月日因人而异就会很多） 字段类型比较小的字段 如果非得在varchar(255)这样的字段上建立索引，也可以考虑只建立前20个字符的一个索引。 对索引列使用函数会导致无法使用到索引 不要建立太多的索引，因为新增数据可能会导致多个索引树的页分裂，很费时间 一款交友软件，陌生人搜索相关的索引建立过程字段的确定 省份provice 城市city 性别sex 年龄age 如果where和order by中的字段不同，建立谁的索引？对于SQL：SELECT * FROM USER WHERE provice = ‘四川’ order by age = 24WHERE条件和ORDER BY使用了不同的字段；建立PROVINCE的索引，ORDER BY利用不到索引；建立age的索引，WHERE条件利用不到索引；如果建立联合索引Idx(province,age)也解决不了问题，只能二选一建立索引。以where条件中的字段建立索引，因为基于where筛选可以最快速度筛选出所需要的少量数据。如果数据量不是特别大的情况下，order by的成本也不会太大 如何跳过基数很小的字段在索引中的位置对于建立了索引idx(provice,city,sex,age)的SQL：SELECT * FROM USER WHERE provice = xx and city = xx and age = 15 上面的SQL，说明了对于sex的条件没有勾选；因为sex的基数最大是2。上面的SQL在已有的索引下，是无法通过age在索引中进行筛选的。但是可以通过添加上sex in (‘male’,’female’) 这个等值条件，使得索引生效。 根据七天内是否在线作为过滤条件原始字段：latest_login_time如果添加了这个字段，势必会利用latest_login_time的一个大于或者小于操作来筛选数据，但是在idx(provice,city,sex,age)的情况下，修改索引为(provice,city,sex,latest_login_time,age)也会导致age使用不到索引。新增字段：does_login_in_latest_7_days（基数为2，原理同sex，利用等值查询） 通过对基数很小的字段进行索引的创建对于SQL：SELECT * FROM USER WHERE SEX = ‘female’ ORDER BY VIP_SCORE DESC LIMIT 0,10如果只是建立索引idx(sex)，上面的SQL经过索引后依然有海量的数据，再进行磁盘文件排序，性能很低。再这样的情况下，可以针对于基数很低的字段再加上一个排序字段单独设计一个辅助索引，idx(sex,score)。此时依然可以使用到索引来排序。因为sex=’female’的数据在磁盘上是排在一起的。找到这一部分数据后，他们肯定都是按照score排序的，此时根据score字段值的顺序去读取limit语句指定的数据就行。 区间查询的字段一定要放在索引的最右边","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 索引引入的前提","slug":"MySql-索引引入的前提","date":"2021-08-25T13:53:00.000Z","updated":"2021-08-25T13:54:55.013Z","comments":true,"path":"2021/08/25/MySql-索引引入的前提/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E7%B4%A2%E5%BC%95%E5%BC%95%E5%85%A5%E7%9A%84%E5%89%8D%E6%8F%90/","excerpt":"","text":"磁盘数据页的存储结构特性 数据页是按顺序一页一页的存放的，两两相邻的数据页之间会采用双向链表的格式相互引用。 数据页内部多个数据行通过主键顺序形成单向链表 每个数据页都有一个页目录，根据数据行的主键存放了一个目录，同时数据行是被分散存储到不同的槽位里去的。所以每个数据页的目录里，就是这个页里没个主键跟所在槽位的映射关系。 主键查询通过传入的主键到页目录中根据主键进行二分查找，通过二分查找在目录中定位到数据的槽位，到对应的槽位遍历每一行数据进行对比 非主键查询进入数据页里，根据单向链表依次遍历查找数据，性能很差 全表扫描在没有任何索引数据结构的时候，无论如何查询数据，都是一个全表扫描的过程。根据双向链表依次把磁盘上的数据页加载到缓存页里去，然后在缓存页内部来查找那条数据。 页分裂数据页中包含了一个起始行，行类型是2；包含了一个行类型为3的结束行（具体可以看03.数据在磁盘上的存储，里面有提到行格式）。其他行都是普通行，类型为0；当不停的插入数据时，最开始在第一个数据页。当第一个数据页满了，就创建了第二个数据页。但是有时候主键不一定是自增长的，所以会出现第二页中的数据的主键大于第一页中的数据的主键；为了避免这种情况，在新增一个数据页的时候，会把前一个数据页中主键值较大的，挪动到新的数据页中来。然后把新插入的主键较小的数据挪到上一个数据页中，保证新数据页中的主键值一定比上一个数据页里的主键值大（索引的一个核心基础），这就是页分裂","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 锁机制","slug":"MySql-锁","date":"2021-08-25T13:32:00.000Z","updated":"2021-08-25T13:42:26.704Z","comments":true,"path":"2021/08/25/MySql-锁/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E9%94%81/","excerpt":"前情提要当多个事务同时更新一条数据的时候，如何防止脏写的问题 锁机制的引入依靠锁机制让多个事务更新同一行数据的时候串行化，避免同时更新。 锁机制下的更新步骤 事务A要更新一条数据，先判断当前数据是否有锁。没锁则当前事务创建一个锁，其中包含了自己的trx_id和等待状态，然后把锁和数据关联起来。 此时数据和锁都是在内存中。 事务B也要更新这条数据，检查数据是否有锁时发现存在着事务A创建的锁。则创建了属于自己的一个锁，其中等待状态为true。表示正在等待 事务A更新完后，释放锁，然后寻找到事务B对这条数据加锁了。此时就会把事务B的锁中的等待状态修改为false，然后唤醒事务B。 行锁独占锁","text":"前情提要当多个事务同时更新一条数据的时候，如何防止脏写的问题 锁机制的引入依靠锁机制让多个事务更新同一行数据的时候串行化，避免同时更新。 锁机制下的更新步骤 事务A要更新一条数据，先判断当前数据是否有锁。没锁则当前事务创建一个锁，其中包含了自己的trx_id和等待状态，然后把锁和数据关联起来。 此时数据和锁都是在内存中。 事务B也要更新这条数据，检查数据是否有锁时发现存在着事务A创建的锁。则创建了属于自己的一个锁，其中等待状态为true。表示正在等待 事务A更新完后，释放锁，然后寻找到事务B对这条数据加锁了。此时就会把事务B的锁中的等待状态修改为false，然后唤醒事务B。 行锁独占锁 简介又叫X锁，Exclude锁。当有一个事务加了独占锁后，其他事务再来更新当前数据，都是要加独占锁的，但是只能在独占锁后面等待。 备注说明当多事务更新同一行数据时，其他事物是能够直接读取这行数据的，并不需要加锁。因为默认开启mvcc机制可以基于ReadView去undo log版本链中找到一个能够读取的版本。 共享锁简介又叫S锁。语法是：SELECT * FROM TABLE LOCK IN SHARE MODE；意思是在查询的时候对一行数据加共享锁。 备注说明当一行数据加了X锁后，S锁是无法添加的，因为两者互斥。当一行数据加了S锁后，其他事物也能添加S锁，因为S锁不互斥。 其他情况查询操作通过LOCK IN SHARE 添加共享锁；查询操作通过FOR UPDATE 添加互斥锁； 表锁语法LOCK TABLES xxx READ；加表级共享锁（很少用）LOCK TABLES xxx WRITE；加表级独占锁（很少用） 其他加锁的操作 如果有事务在表里执行增删改操作，就会在行级加独占锁。还会在表级加一个意向独占锁。 如果事务在表里执行查询操作，那么会在表级添加一个意向共享锁。 备注说明 意向独占锁和意向共享锁不互斥 互斥关系 锁类型 独占锁 意向独占锁 共享锁 意向共享锁 独占锁 互斥 互斥 互斥 互斥 意向独占锁 互斥 不互斥 互斥 不互斥 共享锁 互斥 互斥 不互斥 不互斥 意向共享锁 互斥 不互斥 不互斥 不互斥 独占锁与其他锁都互斥 意向XX锁与意向XX锁之间不互斥 共享锁，意向共享锁之间不互斥 意向共享锁只与独占锁互斥 不确定性的性能抖动脏页刷盘原因分析当一个查询语句，加载了大量的数据到缓存页中，导致内存中大量的缓存页被淘汰然后刷回磁盘。 解决方案减少缓存页刷盘的频率：增加buffer pool分配的内存空间 Redolog刷盘原因分析redolog不断的写入，当日志文件写满了，就会对第一个日志文件进行覆盖写入，此时如果第一个日志文件中的一些redolog对应的内存里的缓存页的数据如果还没有被刷回磁盘的话。也会触发脏页回盘的过程。 解决方案提升缓存页刷盘的速度 因为刷盘是典型的随机IO，所以要提升随机IO的性能，使用SSD固态硬盘。 配置参数innodb_io_capacity：采用多大的IO速率刷盘（每秒随机IO的次数） 配置参数innodb_flush_neighbors：刷盘时把缓存页临近的其他缓存页也刷盘，但是这样刷回的缓存页就会变多，如果是SSD，把这个设置为0就行。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql MVCC机制","slug":"MySql-MVCC机制","date":"2021-08-25T13:21:00.000Z","updated":"2021-08-25T13:31:39.331Z","comments":true,"path":"2021/08/25/MySql-MVCC机制/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-MVCC%E6%9C%BA%E5%88%B6/","excerpt":"MVCC：Multi-Version Concurrent Control，多版本并发控制。 前情提要 当多个线程执行事务的时候，对同一个缓存页里的一行数据进行更新。这个冲突如何处理 当一个事务更新一条数据时，另一个事务在查询这条数据。 常见问题脏写&amp;脏读因为一个事务去更新或者查询了另一个没有提交的事务更新过去的数据。因为另一个事务还没提交，所以随时可能回滚。导致自己更新的数据或者查询的数据没了。 不可重复读在一个事务开始之后，多次读取同一条数据的结果因为其他事务修改的提交，显示为多次读取到不同的值。 幻读","text":"MVCC：Multi-Version Concurrent Control，多版本并发控制。 前情提要 当多个线程执行事务的时候，对同一个缓存页里的一行数据进行更新。这个冲突如何处理 当一个事务更新一条数据时，另一个事务在查询这条数据。 常见问题脏写&amp;脏读因为一个事务去更新或者查询了另一个没有提交的事务更新过去的数据。因为另一个事务还没提交，所以随时可能回滚。导致自己更新的数据或者查询的数据没了。 不可重复读在一个事务开始之后，多次读取同一条数据的结果因为其他事务修改的提交，显示为多次读取到不同的值。 幻读 在一个是事务开始后，多次读取一组数据的结果因为其他事务的新增或者删除的提交，显示为新增了数据或者减少了数据。 四种隔离级别读未提交read uncommitted能够解决脏写，因为一个事务对同一条数据进行操作时（更新，删除），其他对该条数据的操作的事务将会卡住。当第一个事务提交后第二个事务才会执行。否则第二个事务等待一段时间后报错。一般没人用这个。 读已提交read committed能够解决脏读和脏写，只会读取到其他事物已经提交的数据。ORACLE的默认隔离级别 可重复读repeatable read能够解决脏读，脏写和不可重复读。但是会出现幻读。事务一旦开始，多次查询一个值，会一直读取到同一个值。MYSQL的默认隔离级别，MYSQL中RR级别不存在幻读。 串行化serializable基本解决以上所有问题，因为事务是串行进行，不存在并发的情况。 隔离级别的修改set [global | session] transaction_isolation level xxxxxx：REPEATABLE READ，READ COMMITTED，READ UNCOMMITTED，SERIALIZABLE 基于undo多版本链表实现的ReadView机制在MYSQL中，事务的ID是自增的，这是一个重点！！！在执行一个事务的时候，会生成一个ReadView，其中包括了以下4个（不仅仅是4个）关键内容： m_ids：在生成readview时，当前系统中==活跃的读写事务==的事务id列表【当前事务（新建事务）与正在内存中commit的事务不在活跃事务列表中】 min_trx_id：表示在生成readview时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值 max_trx_id：生成readview时系统中==应该分配给下一个事务的id值== creator_trx_id：生成readview的事务的事务id通过这些信息，在Readview生成后，当前事务更新的数据可以被自身读到，或者是在Readview生成前提交的事务修改的值，也是可以读到的。但是在生成ReadView的时候就已经活跃的事务，或者是ReadView生成后再开启的事务，修改的数据也是读不到的。 举个栗子（RR） 数据库中存在一条数据，事务id是32，是初始值。 事务A（trx=36）和事务B（trx=39）同时开启，事务A查询，事务B更新。 事务A根据min_trx=36&gt;trx_id=32，知道这个数据在事务开启前就已经提交过了。所以可以查询到该条数据。事务B同理也能查询到，然后事务B把值改成了值B。 事务A再次查询的时候，此时数据中的trx_id=39处于[min_trx_id,max_trx_id]，说明更新数据的事务是和自己差不多同时开启的，并且trx_id=39∈[36,39]。所以就不能查询这条数据了 虽然事务A不能查询trx_id=39这条数据，但是可以顺着roll_ptr找下去，能找到最近的一条trx_id=32&lt;36的数据。说明这一个undo log版本是在事务A开启之前就提交过的。所以查询得到的是原始值。 如果此时事务A更新该数据为值A，trx_id修改为36，同时保存之前事务B修改的值的快照，如下图 当事务A来查询数据时，发现trx_id=45刚好和自己Read_View中的creator_trx_id一致，说明数据是自己修改的，自己可以直接读取到。 当事务C来进行一次更新操作后。事务A再去读取，发现trx_id=41&gt;max_trx_id，说明在自己开启事务后有一个事务去更新了这笔数据，自己也不能去查询。然后顺着roll_ptr刚好找到一个trx_id=36的undo日志，说明是自己修改过的，直接拿到了值A READ COMMITTED是如何基于READ VIEW实现的核心点在于：每次发起的查询，都生成一个新的Read View上面的例子中，第2步事务B提交后，事务A查询时，创建新的Read View，此时活跃的事务就只有事务A（trx_id=36）了，查询到的数据trx_id=39，在min_trx_id和max_trx_id这个区间内，并且不在m_ids列表中，说明已经提交了，所以可以读取到这个值。 REPEATABLE READ是如何基于READ VIEW实现的核心点在于：每次发起的查询，使用的Read View仍然是第一次SELECT生成的。所以即便其他的事务提交了，m_ids中的内容也不会发生变化。 RR如何基于READ VIEW解决幻读在事务A开启后，进行了一次范围查询；之后事务C插入了符合范围查询的数据，但是这些数据的DB_TRX_ID是事务C的ID，因为Read View只会创建一次，事务C大于事务A的ReadView中的max_trx_id，所以事务A的再次查询是获取不到新增的数据的。 A57","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql Undolog（回滚日志）","slug":"MySql-Undolog（回滚日志）","date":"2021-08-25T13:18:00.000Z","updated":"2021-08-25T13:20:09.454Z","comments":true,"path":"2021/08/25/MySql-Undolog（回滚日志）/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-Undolog%EF%BC%88%E5%9B%9E%E6%BB%9A%E6%97%A5%E5%BF%97%EF%BC%89/","excerpt":"前情提要为了在事务提交前，随时能够回滚缓存页中已经修改的数据，就需要用undolog来记录之前的改动情况。新增操作就对应着一个删除操作来回滚，删除操作也有对应的一个新增操作。更新操作也有对应的更新操作。 回滚类型undolog根据操作类型分为3种类型。 新增类型：TRX_UNDO_INSERT_REC内容： 日志开始位置 主键的各列长度和值（可能是联合主键） 表id undolog日志编号 undolog日志类型 日志结束位置操作：在回滚时，通过获取主键的值以及表id可以直接定位到对应的缓存页，从里面删除之前插入的数据","text":"前情提要为了在事务提交前，随时能够回滚缓存页中已经修改的数据，就需要用undolog来记录之前的改动情况。新增操作就对应着一个删除操作来回滚，删除操作也有对应的一个新增操作。更新操作也有对应的更新操作。 回滚类型undolog根据操作类型分为3种类型。 新增类型：TRX_UNDO_INSERT_REC内容： 日志开始位置 主键的各列长度和值（可能是联合主键） 表id undolog日志编号 undolog日志类型 日志结束位置操作：在回滚时，通过获取主键的值以及表id可以直接定位到对应的缓存页，从里面删除之前插入的数据 删除更新如果更新的条件是主键列，则删除行然后添加一条记录。如果更新的条件不是主键列，则进行反向更新。 undolog版本链在03.数据在磁盘上的存储中，说到了数据在磁盘上的存储格式，其中就包含了隐藏字段：DB_TRX_ID和DB_ROLL_PTR。 DB_TRX_ID：最近一次更新这条数据事务的ID DB_ROLL_PTR：更新这个事务之前生成的undolog通过这2个隐藏字段，就可以在多事务并发访问下，保证数据的串行修改。 示例","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql Redolog（重做日志）","slug":"MySql-Redolog（重做日志）","date":"2021-08-25T13:11:00.000Z","updated":"2021-08-25T13:14:30.300Z","comments":true,"path":"2021/08/25/MySql-Redolog（重做日志）/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-Redolog%EF%BC%88%E9%87%8D%E5%81%9A%E6%97%A5%E5%BF%97%EF%BC%89/","excerpt":"前情提要在执行增删改操作的时候，是基于Buffer Pool中的缓存页中的数据的。更新了缓存页中的数据后，会写入一条数据到Redo Log中。在提交事务的时候，会立马把Redo Log刷入磁盘（推荐方式），然后在RedoLog中写入binlog信息和一个commit标记，事务至此提交完毕。 FAQRedoLog保障了什么当更新了缓存中的数据页后，缓存页还没有刷到磁盘上。MYSQL宕机，那么MYSQL重启后，会直接读取RedoLog中的内容，重做到Buffer Pool中，然后在刷到磁盘。因为RedoLog是顺序读写，所以效率很高。并且为了保证数据的不丢失，RedoLog也要设置成不经过OS Cache。 为什么要写入RedoLog，直接刷到磁盘的缺点在哪里？ 一个缓存页是16KB，刷盘比较耗时。而且你可能只修改了几个字节的数据。 缓存页刷入磁盘是随机读写。效率很低。而RedoLog是顺序读写，效率高","text":"前情提要在执行增删改操作的时候，是基于Buffer Pool中的缓存页中的数据的。更新了缓存页中的数据后，会写入一条数据到Redo Log中。在提交事务的时候，会立马把Redo Log刷入磁盘（推荐方式），然后在RedoLog中写入binlog信息和一个commit标记，事务至此提交完毕。 FAQRedoLog保障了什么当更新了缓存中的数据页后，缓存页还没有刷到磁盘上。MYSQL宕机，那么MYSQL重启后，会直接读取RedoLog中的内容，重做到Buffer Pool中，然后在刷到磁盘。因为RedoLog是顺序读写，所以效率很高。并且为了保证数据的不丢失，RedoLog也要设置成不经过OS Cache。 为什么要写入RedoLog，直接刷到磁盘的缺点在哪里？ 一个缓存页是16KB，刷盘比较耗时。而且你可能只修改了几个字节的数据。 缓存页刷入磁盘是随机读写。效率很低。而RedoLog是顺序读写，效率高 详细介绍RedoLog的类型根据数据页修改的字节数划分了不同的类型 MLOG_1BYTE：修改了1个字节 MLOG_2BYTE：修改了2个字节 MLOG_4BYTE：修改了4个字节 MLOG_WRITE_STRING：修改了一大串的值 RedoLog的大致内容MLOG_NBYTE，表空间ID，数据页号，数据页中的偏移量，具体修改的值MLOG_WRITE_STRING，表空间ID，数据页号，数据页中的偏移量，修改的长度，具体修改的值 RedoLog BlockRedoLog中，包含着多个RedoLog Block。每个RedoLog大小是512KB；在写入Redolog之前先写入内存中的RedoLog Block，然后再把RedoLog Block写入磁盘文件。具体的结构见图。 RedoLog buffer好比Buffer Pool，基于内存中的一块连续空间。里面分配了多个空的RedoLog block。用来存放redolog。 在一个事务中，多个操作对应多个redo Log，对应着一组redolog，现在别的地方暂存，执行完了再把一组的redolog写入到内存中的redolog buffer中的block中 如果一个事务对应的redoLog太多，就会放到两个甚至多个redolog block中。 如果一个redolog group比较小，也可能会把多个redolog group合并在一个redolog block中。 刷盘时机 写入redolog buffer的日志占用了总容量（innodb_log_buffer_size）的50%。 事务提交的时候 后台线程定时刷新 MYSQL关闭的时候 RedoLog的一些默认处理磁盘上默认redolog数量：2个(innodb_log_files_in_group)磁盘上默认redolog大小：48MB(innodb_log_file_size)磁盘上的默认名：ib_logfile0，ib_logfile1一般情况是向一个redolog中写，写满了就换下一个。所以redolog最多保存96MB的redolog，如果第二个写满了，就覆盖第一个日志文件里面原来的redolog","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 数据在磁盘上的存储","slug":"MySql-数据在磁盘上的存储","date":"2021-08-25T13:09:00.000Z","updated":"2021-08-25T13:16:03.393Z","comments":true,"path":"2021/08/25/MySql-数据在磁盘上的存储/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E6%95%B0%E6%8D%AE%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E7%9A%84%E5%AD%98%E5%82%A8/","excerpt":"物理数据存储格式行格式 COMPACT格式 大致格式：变长字段的长度列表，null值列表（长度为8n），数据头[隐藏字段]，col1的值，col2的值。。。 xxx格式 变长字段的存储因为变长字段的内容不固定，所以无法判断数据要从何处截断，因此在数据的头部保存了变长字段的长度列表。多个变长字段按照字段顺序逆序放入变长字段的长度列表中。不考虑为null的列。","text":"物理数据存储格式行格式 COMPACT格式 大致格式：变长字段的长度列表，null值列表（长度为8n），数据头[隐藏字段]，col1的值，col2的值。。。 xxx格式 变长字段的存储因为变长字段的内容不固定，所以无法判断数据要从何处截断，因此在数据的头部保存了变长字段的长度列表。多个变长字段按照字段顺序逆序放入变长字段的长度列表中。不考虑为null的列。 NULL值的存储对于所有的NULL值，是通过二进制的bit位来存储，一行数据如果有多个字段的值为NULL，那么这些字段的NULL会以bit位的形式存放在NULL值列表中。0表示不是NULL，1表示是NULL，同样也是逆序存放.==需要注意的是，不允许为NULL的列是不考虑的==。 数据头 bit位 名称 作用 1 预留位 无 1 预留位 无 1 delete_mask 删除标志位 1 min_rec_mask B+树的每一层非叶子节点的最小值会有这个标志 4 n_owned 拥有的记录数 13 heap_no 当前记录在记录堆的位置信息 3 record_type 当前记录的类型，0：普通；1：B+树非叶子节点；2：最小值数据；3：最大值数据 16 next_record 下一条数据的指针 隐藏字段 DB_ROW_ID：行唯一标识，在没有指定主键和Unique key唯一索引的时候，会以他作为主键 DB_TRX_ID：事务相关 DB_ROLL_PTR：回滚指针，用于事务回滚 示例 红色的列表示不允许为空 varchar(10) varchar(20) varchar(5) char(2) char(3) 可能格式 hello nice a zx cc [0x01,0x04,0x05][00000000][头字段]hello nice a zx cc ppt word flash d z [0x05,0x04,0x03][00000000][头字段]ppt wprd flash d z jack NULL cc ps NULL [0x02,0x04][00001001][头字段]jack cc ps tom 3 mg NULL KG [0x02,0x01,0x03][00000100][头字段]tom 3 mg KG 紧凑的意义节省空间？ 读取的过程 示例样本(选自上方)[0x02,0x01,0x03][00000100][010000001000011111]tom 3 mg KG 先读取出变长字段长度列表和NULL值列表，分析得到几个变长字段以及哪几个字段是NULL。因为MYSQL自己定义的列以及类型自己最清楚哪些列是变长哪些列允许NULL 第一个字段不允许为空所以不会出现在NULL值列表中，是变长类型所以从变长列表中取出0x03，就去字段列表中读取3个字符的长度，得到tom 第二个字段为变长允许为空，所以读取NULL值列表知道不为空，在读取变长列表得到长度为0x01,所以读取1个字符的长度得到3 第三个字段为变长允许为空，所以读取NULL值列表知道不为空，在读取变长列表得到长度为0x02,所以读取2个字符的长度得到mg 第四个字段为定长允许为空，所以直接读取NULL值列表知道为空，所以直接为null 第五个字段为定长允许为空，直接读取NULL值列表知道不为空，所以直接读取固定的3个长度得到KG 。（这里KG后面还有一个空格补充长度） 行溢出因为每行数据都是存放在一个数据页中的，一个数据页是16KB，如果一行数据的大小超过了数据页的大小。比如一个字段是VARCHAR(65532),最多可以放65532个字符，65532个字符至少也是65532b≈64kb&gt;&gt;16kb。这个时候就会在那一页存放你的数据，然后特别长的字段中，只会包含部分数据，同时还==包含一个20个字节的指针，指向其他的数据页==，用于把这些数据页用链表串联起来，存放超大数据。 数据页的拆分数据页16kb的大小实际上被拆分成了多个部分，包括 文件头（38b） 数据页头（56b） 最小记录和最大记录（26b） 多个数据行 空闲空间 数据页目录 文件尾部（8b） 数据区与数据组在磁盘上，一个表空间的数据文件中可能包含多个数据页，为了便于管理，引入了数据区的概念。一个数据区对应着64个连续的数据页，每页16kb，所以一个数据区是1MB。256个数据区划分为1组(extent)。所以1组是256MB。 第一个数据区特殊的3页一个表空间的第一个数据区的前3个数据页是固定的，存放描述性信息。 FSP_HDR IBUF_BITMAP INODE 其他数据区特殊的2页同理也是存放描述性信息 XDES 未知 一个口述的数据插入流程 根据表名找到对应的表空间，定位到对应的磁盘文件 从磁盘文件中拿到一个extent组，从里面找出一页数据页 加载数据页到Buffer Pool","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql Buffer Pool 与数据页","slug":"ySql-Buffer-Pool-与数据页","date":"2021-08-25T13:03:00.000Z","updated":"2021-08-25T13:17:03.892Z","comments":true,"path":"2021/08/25/ySql-Buffer-Pool-与数据页/","link":"","permalink":"http://pdyun.cc/2021/08/25/ySql-Buffer-Pool-%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%A1%B5/","excerpt":"Buffer Pool在对数据库执行增删改查操作的时候，因为对磁盘的随机读写操作速度非常慢。所以通过Buffer Pool缓存磁盘的真实数据。 数据页MYSQL中抽象出来的数据单位，MYSQL把很多行数据放在一个数据页里。实际上我们更新一行数据的时候，是通过数据库找到这行数据所在的数据页，然后加载到Buffer Pool中。默认情况下，一个数据页是16KB 缓存页因为在Buffer Pool中存放的也是一个一个的数据页，也叫作缓存页。在默认情况下，是和磁盘上的数据页一一对应的，所以也是16KB。","text":"Buffer Pool在对数据库执行增删改查操作的时候，因为对磁盘的随机读写操作速度非常慢。所以通过Buffer Pool缓存磁盘的真实数据。 数据页MYSQL中抽象出来的数据单位，MYSQL把很多行数据放在一个数据页里。实际上我们更新一行数据的时候，是通过数据库找到这行数据所在的数据页，然后加载到Buffer Pool中。默认情况下，一个数据页是16KB 缓存页因为在Buffer Pool中存放的也是一个一个的数据页，也叫作缓存页。在默认情况下，是和磁盘上的数据页一一对应的，所以也是16KB。 缓存页的描述信息用于描述缓存页的一些基本信息，比如数据页所属表空间、数据页的编号、在Buffer Pool中的地址等。每个缓存页都有对应的一个描述信息，在Buffer Pool中，每个缓存页的描述信息在最前面，然后各个缓存页放在后面描述数据大概相当于缓存页是5%。 free链表概念引入当读取数据页放入Buffer Pool的时候，怎么知道哪些缓存页是空闲的？free链表是一个双向链表，每个节点是一个空闲的缓存页的描述块地址。 空间占用 free链表只是一个逻辑上的概念，因为每个缓存页的描述数据块中维护了两个指针，free_prev和free_next，分别指向free链表的上一个节点和下一个节点，这样就串成了一个free链表。 free链表还有一个基础节点（但是不在链表中，链表头结点的prev=null，尾结点的next=null），40个字节，存放了free链表的头结点的地址、尾结点的地址以及free链表里当前还有多少个节点。 数据页读取到Buffer Pool的过程 从free链表里获取一个描述数据块，获取到对应的空闲缓存页 把数据页读取到对应的缓存页，写入相关的描述信息到描述数据块中 从free链表中移除 flush链表在执行增删改的时候，都是基于内存中的缓存页进行操作的，一旦更新了缓存页中的数据，使得和磁盘上的数据页里的数据不一致。那么这就是脏数据页。类似于free链表，通过缓存页描述数据块中的两个指针来将脏数据页串起来。组成一个双向链表，也有一个基础节点存放头结点尾结点的地址等。 MYSQL预读机制当从磁盘上加载一个数据页的时候，可能会连带把这个数据页相邻的其他数据页也加载到缓存中去。分为以下两种预读方式，暂时不做说明 线性预读 顺序访问了一个区里的多个数据页（默认56页），就会把下一个相邻区中的所有数据页加载到缓存中 随机预读 如果Buffer Pool中缓存了一个区的13个随机数据页，而且这些数据页是比较频繁被访问的，就会把这个区的其他数据页都加载到缓存中 LRU链表简化版 当free链表已经没有空闲页的时候，所有的缓存页都塞了数据库，此时就要淘汰掉一些缓存页。 此时可以将一个脏数据页刷到磁盘，然后清空这个缓存页，就有了一个空闲的缓存页。但是选择哪一个脏数据页去清空，此时就要用到LRU链表。 当把一个数据页加载到缓存页的时候，把对应的描述数据块放到LRU链表头部。后续查询了或者修改了某个缓存页，也会把这个缓存页挪动到LRU链表头部。 但是MYSQL的预读机制可能会加载没人访问的数据页，如下图。 基于冷热分离的LRU链表 将链表按照5:3的比例分割，63%的热数据，37%的冷数据。 数据页第一次加载到缓存的时候，放入冷数据头部。在1s后（参数配置）访问这个缓存页，就会被加入热数据头部。 在热数据区域的前1/4部分缓存页被访问后不会移动到链表头部，避免浪费性能 有一个后台线程会定时把冷数据区域的尾部缓存页刷回磁盘，清空加入回free链表。 热数据区域也会在MYSQL闲暇的时候刷回磁盘 无空闲缓存页时从冷数据区域尾部找到一个缓存页刷回磁盘并清空成为空闲页。 Buffer Pool并发访问Buffer Pool的性能问题 多线程同时访问Buffer Pool，就会同时操作同一个free链表、flush链表和lru链表。那必然要进行加锁 因为是基于内存的操作，所以很快。其次这些链表的操作，也是基于指针的操作，也不存在性能低下的可能。多个Buffer Pool优化并发能力给Buffer Pool分配比较大的内存，则可以设置多个Buffer Pool.如果给分配的内存小于1G，最多就只有1个Buffer Pool。 innodb_buffer_pool_instances=8 基于chunk机制动态调整Buffer Pool的大小 Buffer Pool是由多个chunk组成的，默认一个chunk的大小是128M。 分配Buffer Pool的内存8G，4个Buffer Pool实例，那么每个Buffer Pool是2G，拥有16个chunk。 需要动态扩容的话只需要申请一系列128MB大小的chunk就行，然后分配给buffer pool就行。 内存的分配 Buffer Pool总共占用机器内存的50%-60% buffer Pool总大小 = (chunk size * buffer pool instance) * chunk count总结 根据机器的内存设置合理的buffer pool的大小，然后设置buffer pool的数量，使得chunk数量*chunk size 接近单个buffer pool的内存。充分利用内存减少内存碎片 每个buffer pool里的多个chunk共用一套链表数据结构。 后台线程定时根据lru链表和flush链表，去把一批缓存页刷入磁盘并释放，同时更新free链表 如果缓存页满了，无法加载自己的缓存页，就把lru链表冷数据区域的缓存页刷盘","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql 基础","slug":"MySql-基础","date":"2021-08-25T12:58:00.000Z","updated":"2021-08-25T13:17:44.357Z","comments":true,"path":"2021/08/25/MySql-基础/","link":"","permalink":"http://pdyun.cc/2021/08/25/MySql-%E5%9F%BA%E7%A1%80/","excerpt":"名词说明MYSQL驱动在底层跟数据库建立网络连接 系统连接池建立数据库连接是一个非常耗时的操作，而实际业务中往往会有很多请求去访问数据库，所以要使用一个数据库连接池来维护多个数据库连接。线程使用完连接后不用销毁，直接放回连接池以便后续使用。 MYSQL连接池维护了与系统之间的多个数据库连接。除此之外，系统每次与MYSQL建立连接的时候，还会进行账户信息验证，库表权限验证。 SQL接口MYSQL内部提供的一个组件，负责执行线程传递过来的SQL语句","text":"名词说明MYSQL驱动在底层跟数据库建立网络连接 系统连接池建立数据库连接是一个非常耗时的操作，而实际业务中往往会有很多请求去访问数据库，所以要使用一个数据库连接池来维护多个数据库连接。线程使用完连接后不用销毁，直接放回连接池以便后续使用。 MYSQL连接池维护了与系统之间的多个数据库连接。除此之外，系统每次与MYSQL建立连接的时候，还会进行账户信息验证，库表权限验证。 SQL接口MYSQL内部提供的一个组件，负责执行线程传递过来的SQL语句 查询解析器负责对SQL语句进行解析，知道做什么操作，对哪张表操作，操作哪些数据，怎么操作等 查询优化器得到一个效率最高的执行计划 执行器根据查询优化器选择的一套执行计划，不停的调用存储引擎的各种接口去完成SQL语句的执行计划。 比如执行器可能先会调用存储引擎的一个接口去获取user表的第一行数据，判断id是否为我们期望的一个值，如果不是就继续调用接口获取下一行数据继续判断 存储引擎接口执行SQL语句，按照一定的步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等。 流程图 InnoDB内存结构缓冲池缓冲池（Buffer Pool），方便查询的时候，直接可以从内存缓冲池中获取，减少对磁盘的查询 undo日志用于回滚数据 更新缓存数据流程 记录加载到缓冲池 加锁 旧值写入undo日志文件 更新缓冲池中的记录，此时这个数据就是脏数据了（和磁盘数据不一致） redo日志记录内存中的数据修改，避免内存修改后没有同步到磁盘上。InnoDB存储引擎特有的一个东西。在mysql重启时会加载redo日志中的修改到内存里去，然后等适当时机通过IO线程把修改后的数据同步到磁盘上。 RedoLog Buffer内存中的一个缓冲区。暂时存放redo日志。 binlog归档日志，偏向物理性质的重做日志，类似于，对XX表中某一行数据进行了修改，修改后的值是XXX；在提交事务的时候，还会把binlog的文件名，位置以及commit标记写入对应的redo日志中。 事务提交流程1.根据策略(innodb_flush_log_at_trx_commit)，把redo日志从redo log buffer刷到磁盘文件。 0：不管事务，每一秒都会把日志写入，并且刷到磁盘。事务提交时不会主动触发写磁盘的操作。1：只要事务提交成功，redo log就必然在磁盘里（建议）2：提交事务的时候，把redo日志写入磁盘对应的os cache缓存，而不是直接进入磁盘文件，可能要过一段时间再写入磁盘 根据策略(sync_binlog)，把binlog日志写入磁盘 0：写入os cache，一段时间后写入磁盘（默认）1：强制在提交事务的时候，直接写入到磁盘文件 把写入磁盘的binlog日志的文件名，位置以及一个commit标记写入到redo日志 至此，事务才算提交完成。只要redo日志中不存在commit标记则认为提交失败。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"MySql8.0新特性","slug":"MySQL8-0新特性","date":"2021-08-23T03:56:00.000Z","updated":"2021-08-25T13:02:58.079Z","comments":true,"path":"2021/08/23/MySQL8-0新特性/","link":"","permalink":"http://pdyun.cc/2021/08/23/MySQL8-0%E6%96%B0%E7%89%B9%E6%80%A7/","excerpt":"MySql 8.0新特性MySQL从5.7一跃直接到8.0，这其中的缘由，咱就不关心那么多了，有兴趣的朋友自行百度，本次的版本更新，在功能上主要有以下6点： 账户与安全 优化器索引 通用表表达式 窗口函数 InnoDB 增强 JSON 增强","text":"MySql 8.0新特性MySQL从5.7一跃直接到8.0，这其中的缘由，咱就不关心那么多了，有兴趣的朋友自行百度，本次的版本更新，在功能上主要有以下6点： 账户与安全 优化器索引 通用表表达式 窗口函数 InnoDB 增强 JSON 增强 一、账户与安全123456789101112131.用户的创建与授权 在MySQL5.7的版本： &gt; grant all privileges on *.* to &#x27;用户名&#x27;@&#x27;主机&#x27; identified by &#x27;密码&#x27;； 在MySQL8.0需要分开执行： &gt;create user &#x27;用户名&#x27;@&#x27;主机&#x27; identified by &#x27;密码&#x27;； &gt;grant all privileges on *.* to &#x27;用户名&#x27;@&#x27;主机&#x27;； 用以前的一条命令在8.0里面创建用户，会出现sql语法错误 12345678910111213142.认证插件更新 MySQL5.7默认身份插件是mysql_native_password MySQL8.0默认的身份插件是caching_sha2_password 查看身份认证插件命令：show variables like &#x27;default_authentication_plugin%&#x27;; 身份认证插件可以通过以下2中方式改变： 1）系统变量default_authentication_plugin去改变，在my.ini文件的[mysqld]下面设置default_authentication_plugin=mysql_native_password即可 2）如果希望只是某一个用户通过mysql_native_password的方式认证，可以修改数据库mysql下面的user表的字段，执行以下命令： &gt;alter user &#x27;用户名&#x27;@&#x27;主机&#x27; identified width mysql_native_password by &#x27;密码&#x27;; 1234567891011121314151617181920212223242526272829303.密码管理 MySQL8.0的密码管理策略有3个变量 password_history 修改密码不允许与最近几次使用或的密码重复，默认是0，即不限制 password_reuse_interval 修改密码不允许与最近多少天的使用过的密码重复，默认是0,即不限制 password_require_current 修改密码是否需要提供当前的登录密码，默认是OFF,即不需要；如果需要，则设置成ON 查询当前MySQL密码管理策略相关变量，使用以下命令： &gt;show variables like &#x27;password%&#x27;; 1)设置全局的密码管理策略，在my.ini配置文件中，设置以上3个变量的值这种设置方式，需要重启mysql服务器；某些生产环境不允许重启，MySQL8.0提供了关键字persist,持久化，执行以下命令： &gt;set persist password_history=6; 这条命令会在数据目录下生成新的配置文件（/var/lib/mysql/mysqld-auto.cnf），下次服务器重启的时候除了读取全局配置文件，还会读取这个配置文件,这条配置就会被读入从而达到持久化的目的 2)针对某一个用户单独设置密码管理策略 &gt;alter user &#x27;用户名&#x27;@&#x27;主机&#x27; password history 5; 这样，这个用户的password_history 就被设置成了5,查看一下： &gt;show user,host,Password_reuse_history from user; 查看某一张的字段的所有字段，使用以下命令: &gt;desc 表名; 12345678910111213141516171819202122232425262728293031323334353637383940414.角色管理 角色：一组权限的集合 一组权限赋予某个角色，再把某个角色赋予某个用户，那用户就拥有角色对应的权限 1)创建一个角色 &gt;create role &#x27;角色1&#x27;; 2)为这个角色赋予相应权限 &gt;grant insert,update on *.* to &#x27;角色1&#x27;; 3)创建一个用户 &gt;create user &#x27;用户1&#x27; identified by &#x27;用户1的密码&#x27;; 4)为这个用户赋予角色的权限 &gt;grant &#x27;角色1&#x27; on *.* to &#x27;用户1&#x27;； 执行完上面4步，用户1就拥有了插入与更新的权限 5)再创建1个用户 &gt;create user &#x27;用户2&#x27; identified by &#x27;用户2的密码&#x27;; 6)为这个用户赋予同样的角色 &gt;grant &#x27;角色1&#x27; on *.* to &#x27;用户2&#x27;; 执行完上面2步，用户2也用了角色1的权限，即插入与更新 查看用户权限，执行以下命令： &gt;show grants for &#x27;用户名&#x27;; 7)启用角色,设置了角色，如果不启用，用户登录的时候，依旧没有该角色的权限 &gt;set default role &#x27;角色名&#x27; to &#x27;用户名&#x27;; 8)如果一个用户有多个角色，使用以下命令 &gt;set default role all to &#x27;用户名&#x27;; MySQL中与用户角色相关的表：mysql.default_roles、mysql.role_edges,有兴趣的朋友可以进去查看下。 9)撤销权限 &gt;revoke insert,update on *.* from &#x27;角色名&#x27;; 二、优化器索引12345678910111213141516171819202122232425262728293031323334351.隐藏索引（invisible index） 隐藏索引不会被优化器使用，但仍需要维护 应用场景： 1）软删除 删除索引，在线上，如果删除错了索引，只能通过创建索引的方式将其添加回来，对于一些大的数据库而言，是比较耗性能的；为了避免删错，可以先将其设置为不可见，优化器这时候就不会使用它，但是后台仍然在维护，确定后，再删除。 2）灰度发布 与软删除差不多，如果想要测试一些索引的功能或者随后可能会使用到这个索引，可以先将其设置为隐藏索引，对于现有的查询不会产生影响，测试后，确定需要该索引，可以将其设置成可见索引。 创建隐藏索引，执行如下命令（如果是不隐藏，则不需要后面的invisible关键字）： &gt;create index 索引名称 on 表名(字段名) invisible; 查询某一张表的索引，执行如下命令： &gt;show index from 表名； 使用explain语句查看查询优化器对索引的使用情况 &gt;explain select * from 表名 where 条件; 查询优化器有很多开关，有一个是use_invisible_indexes(是否使用隐藏索引),默认是off(不适用)，将其设置成on,即可使用隐藏索引。查看当前查询优化器的所有开关变脸，执行如下命令： &gt;select @@optimizer_switch; 设置已经存在的索引为可见或者隐藏，执行如下命令： &gt;alter table 表名 alter index 索引名 visible; &gt;alter table 表名 alter index 索引名 invisible; 主键不可以设置为隐藏索引。 1232.降序索引（descending index） MySQL8.0开始真正支持降序索引，只有InnoDB引擎支持降序所以，且必须是BTREE降序索引，MySQL8.0不在对group by操作进行隐式排序。 1234567891011121314151617183.函数索引 索引中使用函数表达式 支持JSON数据节点的索引 函数索引是基于虚拟列的功能实现的假设用户表（tb_user）的的用户登录账号(username)不需要区分大小写，则可以创建一个函数索引&gt;create index username_upper_index on tb_user((upper(username)));这样在查询的时候 SELECT * FROM tb_user WHERE upper(username) = &#x27;ABD123DSJ&#x27;; 就会使用索引。上面的函数索引，也可以通过MySQL5.7已有的虚拟计算列来模拟，为用户表（tb_user）创建新的一列（new_column）,这一列是计算列，不需要赋值，它的值就是username的大写。&gt;alter tbale tb_user add column new_column varchar(10) generated always as (upper(username));然后给new_column创建一个索引，可以达到模拟MySQL8.0中的函数索引的效果。 三、通用表表达式12345671.非递归 CTE 派生表：select * from (select 1) as dt; 通用表表达式：with cte as (select 1) select * from cte; with cte1(id) as (select 1),cte2 as (select id+1 from cte1) select * from cte1 join cte2; 12.递归 CTE 四、窗口函数五、InnoDB增强11.集成数据字段 12345672.原子ddl操作 MySQL5.7执行drop命令 drop table t1,t2; 如果t1存在，t2不存在，会提示t2表不存在，但是t1表仍然会被删除。 MySQL8.0执行同样的drop命令，会提示t2表不存在，而且t1表不会被删除，保证了原子性。 ddl操作（针对表）的原子性前提是该表使用的存储引擎是InnoDB 12345673.自增列持久化 解决了之前的版本，主键重复的问题。 MySQL5.7及其以前的版本，MySQL服务器重启，会重新扫描表的主键最大值，如果之前已经删除过id=100的数据，但是表中当前记录的最大值如果是99，那么经过扫描，下一条记录的id是100，而不是101。 MySQL8.0则是每次在变化的时候，都会将自增计数器的最大值写入redo log,同时在每次检查点将其写入引擎私有的系统表。则不会出现自增主键重复的问题。 14.死锁检查控制 15.锁定语句选项 六、JSON增强1234567891.内联路径操作符 column-&gt;&gt;path等价于之前的：JSON_UNQUOTE(column -&gt; path)JSON_UNQUOTE(JSON_EXTRACT(column,path)) 1232.JSON聚合函数MySQL8.0和MySQL5.7.22增加了2个聚合函数 121)JSON_ARRAYAGG(),将多行数据组合成json数组 示例：select o_id,json_arrayagg(attribute) as attributes from t group by o_id; 122)JSON_OBJECTAGG()，用于生成json对象 示例：select o_id json_objectagg(attribute,value) as attributes from t group by o_id; 注意：json的聚合函数针对重复key,会使用最后的覆盖前面已有的值，如果下面的o_id=3，它的color有2个值，一个green,一个yellow,使用生成json的聚合函数的时候，前面的green会被覆盖掉。 123453.JSON实用函数 1)JSON_PRETTY() 输出json数据的时候，格式化。 select json_object(&#x27;id&#x27;,3,&#x27;name&#x27;,&#x27;Barney&#x27;); 1 select json_pretty(json_object(&#x27;id&#x27;,3,&#x27;name&#x27;,&#x27;Barney&#x27;)); 123 2)JSON_STORAGE_SIZE() json数据所占用的存储空间（单位：字节） 3)JSON_STORAGE_FREE() json数据更新后所释放的空间（单位：字节） 1234567894.JSON合并函数MySQL8.0废弃了JSON_MERGE()函数，推荐使用以下两个函数合并JSON数据 1)JSON_MERGE_PATCH() 2)JSON_MERGE_PRESERV()上面两个函数都是JSON数据合并，最大的区别就是前者遇到相同key的时候会用后面的覆盖前面的，后者会都保留，看下面的截图： 1235.JSON表函数 MySQL8.0新增了JSON_TABLE()函数，将JSON数据转换成关系表，可以将该函数的返回结果当做一个普通的临时表进行sql查询。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"}],"author":"Peilin Deng"},{"title":"Spring 循环依赖及三级缓存","slug":"Spring-循环依赖及三级缓存","date":"2021-08-20T10:42:00.000Z","updated":"2021-08-20T11:09:17.630Z","comments":true,"path":"2021/08/20/Spring-循环依赖及三级缓存/","link":"","permalink":"http://pdyun.cc/2021/08/20/Spring-%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%8F%8A%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98/","excerpt":"Spring 循环依赖及三级缓存 Spring 在启动过程中，使用到了三个map，称为三级缓存。 Spring启动过程大致如下： 1.加载配置文件2.解析配置文件转化beanDefination，获取到bean的所有属性、依赖及初始化用到的各类处理器等3.创建beanFactory并初始化所有单例bean4.注册所有的单例bean并返回可用的容器，一般为扩展的applicationContext","text":"Spring 循环依赖及三级缓存 Spring 在启动过程中，使用到了三个map，称为三级缓存。 Spring启动过程大致如下： 1.加载配置文件2.解析配置文件转化beanDefination，获取到bean的所有属性、依赖及初始化用到的各类处理器等3.创建beanFactory并初始化所有单例bean4.注册所有的单例bean并返回可用的容器，一般为扩展的applicationContext 一级缓存 在第三步中，所有单例的bean初始化完成后会存放在一个Map(singletonObjects)中，beanName为key，单例bean为value。第三步单例bean的初始化过程大致如下： 0.标记bean为创建中1.new出bean对象2.如果支持循环依赖则生成三级缓存，可以提前暴露bean3.填充bean属性，解决属性依赖4.初始化bean，处理Aware接口并执行各类bean后处理器，执行初始化方法，如果需要生成aop代理对象5.如果存在循环依赖，解决之 – 这里有点问题，这一步是如果之前解决了aop循环依赖，则缓存中放置了提前生成的代理对象，然后使用原始bean继续执行初始化，所以需要再返回最终bean前，把原始bean置换为代理对象返回。6.此时bean已经可以被使用，进行bean注册(标记)并注册销毁方法。7.将bean放入容器中(一级缓存)，移除创建中标记及二三级缓存(后面再具体分析) 循环依赖及三级缓存 根据以上步骤可以看出bean初始化是一个相当复杂的过程，假如初始化A bean时，发现A bean依赖B bean,即A初始化执行到了第2步，此时B还没有初始化，则需要暂停A，先去初始化B，那么此时new出来的A对象放哪里，直接放在容器Map里显然不合适，半残品怎么能用，所以需要提供一个可以标记创建中bean(A)的Map，可以提前暴露正在创建的bean供其他bean依赖，如果在初始化A所依赖的bean B时，发现B也需要注入一个A的依赖，则B可以从创建中的beanMap中直接获取A对象（创建中）注入A，然后完成B的初始化，返回给正在注入属性的A，最终A也完成初始化，皆大欢喜。 如果配置不允许循环依赖，则上述缓存就用不到了，A 依赖B，就是创建B，B依赖C就去创建C，创建完了逐级返回就行，所以，一级缓存之后的其他缓存(二三级缓存)就是为了解决循环依赖！而配置支持循环依赖后，就一定要解决循环依赖吗？肯定不是！循环依赖在实际应用中也有，但不会太多，简单的应用场景是： controller注入service，service注入mapper，只有复杂的业务，可能service互相引用，有可能出现循环依赖，所以为了出现循环依赖才去解决，不出现就不解决，虽然支持循环依赖，但是只有在出现循环依赖时才真正暴露早期对象，否则只暴露个获取bean的方法，并没有真正暴露bean，因为这个方法不会被执行到，这块的实现就是三级缓存（singletonFactories），只缓存了一个单例bean工厂。 这个bean工厂不仅可以暴露早期bean还可以暴露代理bean，如果存在aop代理，则依赖的应该是代理对象，而不是原始的bean。而暴露原始bean是在单例bean初始化的第2步，填充属性第3步，生成代理对象第4步，这就矛盾了，A依赖到B并去解决B依赖时，要去初始化B，然后B又回来依赖A，而此时A还没有执行代理的过程，所以，需要在填充属性前就生成A的代理并暴露出去，第2步时机就刚刚好。 三级缓存的bean工厂getObject方式，实际执行的是getEarlyBeanReference，如果对象需要被代理(存在beanPostProcessors -&gt; SmartInstantiationAwareBeanPostProcessor)，则提前生成代理对象。 二级缓存 根据以上步骤可以看出bean初始化是一个相当复杂的过程，但是貌似三级缓存已经解决所有问题了，二级缓存用来做什么呢？为什么三级缓存不直接叫做二级缓存?这个应该是在缓存使用时决定的： 三级缓存中提到出现循环依赖才去解决，也就是说出现循环依赖时，才会执行工厂的getObject生成(获取)早期依赖，这个时候就需要给它挪个窝了，因为真正暴露的不是工厂，而是对象，所以需要使用一个新的缓存保存暴露的早期对象(earlySingletonObjects)，同时移除提前暴露的工厂，也不需要在多重循环依赖时每次去执行getObject(虽然个人觉得不会出问题，因为代理对象不会重复生成，详细可以了解下代理里面的逻辑，如wrapIfNecessary)。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 启动流程简述","slug":"Spring-启动流程","date":"2021-08-20T05:47:00.000Z","updated":"2021-08-20T07:10:45.327Z","comments":true,"path":"2021/08/20/Spring-启动流程/","link":"","permalink":"http://pdyun.cc/2021/08/20/Spring-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","excerpt":"beanDefinitionMap -&gt; 用来存储 BeanDefinition(Bean 的配置信息)factoryBeanObjectCache -&gt; 用来存储原生 Bean 对象的Map, 指反射创建出的实际对象factoryBeanInstanceCache -&gt; 用来存储 BeanWrapper 的Map, 指原生 Bean 的包装类 Spring 启动流程简述一. 配置阶段 web.xml1234DispatcherServlet 路径设定 init-param ( contextConfigLocation = classPath:application.xml )设定 url-pattern ( /* )配置 Annotation 等","text":"beanDefinitionMap -&gt; 用来存储 BeanDefinition(Bean 的配置信息)factoryBeanObjectCache -&gt; 用来存储原生 Bean 对象的Map, 指反射创建出的实际对象factoryBeanInstanceCache -&gt; 用来存储 BeanWrapper 的Map, 指原生 Bean 的包装类 Spring 启动流程简述一. 配置阶段 web.xml1234DispatcherServlet 路径设定 init-param ( contextConfigLocation = classPath:application.xml )设定 url-pattern ( /* )配置 Annotation 等 appication.xml1配置 包扫描路径、Bean定义、视图解析配置等...... …… 二. 初始化阶段 Servlet.init() 12Spring 是 servlet 编程模型, 容器启动时会调用 servlet 的 init() 方法, 在该方法中会读取配置进行 IoC 容器及 MVC 组件的初始化. IoC 部分 (定位、加载、注册) 1234初始化 IoC 容器 1. 通过 web.xml 的配置定位 application .xml配置文件. 2. 使用 BeanDefinitionReader 读取配置文件, 扫描类并封装成 BeanDefinition 3. 创建 BeanFatory, 将 *beanDefinition 注册到 DefalutListableBeanFactory 的 beanDefinitionMap 中 DI 、 AOP 部分 123456784. 初始化非延迟加载的 bean0). 标记 bean 为创建中 1). 通过反射 new 出 bean 对象, 封装成 BeanWrapper 对象 2). 如果 bean 为单例且支持循环依赖则生成三级缓存 singletonFactories, 可提前暴露 bean 3). 填充bean属性，解决属性依赖 4). 初始化bean的各个Aware接口(各个Aware接口能让bean获取到部分属性: ApplicationContextAware-能获取到ApplicationContex; BeanFactoryAware 能获取到 BeanFactory) 并执行各类 bean 的后处理器, 执行初始化方法, 如果有 AOP 配置需要生成 AOP 代理对象 5). 如果存在循环依赖，解决之 – 这里有点问题，这一步是如果之前解决了aop循环依赖，则缓存中放置了提前生成的代理对象，然后使用原始bean继续执行初始化，所以需要再返回最终bean前，把原始bean置换为代理对象返回。 6). 此时 bean 已经可以使用, 将 bean 放入一级缓存 singletonObjects , 移除创建中标记以及二三级缓存 MVC 部分 12345678910111213141516171819205. 初始化 MVC 九大组件// 1). 初始化文件上传解析器initMultipartResolver(context);// 2). 初始化本地语言环境initLocaleResolver(context);// 3). 初始化模板处理器initThemeResolver(context);// 4). 初始化 HandlerMapping 组件initHandlerMappings(context);// 5). 初始化参数适配器initHandlerAdapters(context);// 6). 初始化异常拦截器initHandlerExceptionResolvers(context);// 7). 初始化视图预处理器initRequestToViewNameTranslator(context);// 8). 初始化视图解析器initViewResolvers(context);// 9). 初始化 FlashMap 管理器( 为了解决请求转发和重定向过程中参数的丢失问题: redirect-&gt;重定向, request 参数会丢失 ; forward-&gt;转发, 自动将 request 参数系诶带到下一个请求 )initFlashMapManager(context); 三. 运行阶段 从页面点击按钮或者 url 访问资源请求会先到 DispatcherServlet 的 doDispatch() 方法, 该方法会从 HandlerMapping 中通过 url 去匹配对应的控制器及方法 通过参数解析器解析参数并反射执行方法, 返回一个 ModelAndView 通过视图解析器解析 ModelAndView, 决定返回页面或者输出数据 前端根据对应结果来展示","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"Spring 基础认知与技术架构","slug":"Spring-基础认知与技术架构","date":"2021-08-19T15:10:00.000Z","updated":"2021-08-20T11:19:52.620Z","comments":true,"path":"2021/08/19/Spring-基础认知与技术架构/","link":"","permalink":"http://pdyun.cc/2021/08/19/Spring-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5%E4%B8%8E%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/","excerpt":"Spring Spring 是一个轻量级Java开发框架，最早有Rod Johnson创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的JavaSE/JavaEE full-stack（一站式）轻量级开源框架，为开发Java应用程序提供全面的基础架构支持。Spring负责基础架构，因此Java开发者可以专注于应用程序的开发。 Spring最根本的使命是解决企业级应用开发的复杂性，即简化Java开发。 1. Spring 简化开发的四个基本策略 基于POJO 的轻量级和最小侵入性编程. 通过依赖注入和面向接口松耦合. 基于切面和惯性进行声明式编程. 通过切面和模板减少样版式代码.","text":"Spring Spring 是一个轻量级Java开发框架，最早有Rod Johnson创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的JavaSE/JavaEE full-stack（一站式）轻量级开源框架，为开发Java应用程序提供全面的基础架构支持。Spring负责基础架构，因此Java开发者可以专注于应用程序的开发。 Spring最根本的使命是解决企业级应用开发的复杂性，即简化Java开发。 1. Spring 简化开发的四个基本策略 基于POJO 的轻量级和最小侵入性编程. 通过依赖注入和面向接口松耦合. 基于切面和惯性进行声明式编程. 通过切面和模板减少样版式代码. 2. Spring 中的编程思想 Spring思想 应用场景 (特点) 一句话归纳 OOP Object Oriented Programming (面向对象编程) 用程序归纳总结生活中一切事物 封装、继承、多态. BOP Bean Oriented Programming (面向Bean编程) 面向Bean (普通Java类) 设计程序, 解放程序员. 一切从Bean开始. AOP Aspect Oriented Programming (面向切面编程) 找出多个类中有一定规律的代码, 开发时拆开, 应运行时再合并. 面向切面编程, 及面向规则编程. 解耦, 专人做专事. IoC Inversion of Control (控制反转) 将new对象的动作交给Spring管理, 并由Spring保存已创建的对象 (IOC容器). 转交控制权(即控制权反转). DI/DL Dependency Injection (依赖注入) 或者Dependency Lookup (依赖查找) , Spring不仅保存自己创建的对象, 而且保存对象与对象之间的关系. 注入即赋值, 主要三种方式 — 构造方法、set方法、直接赋值. 自动赋值. 3. Spring 注解编程演化V1.X | V2.0 | V2.5 | V3.X | V4.X | V5.X— | — | — | — | — | — | —注解驱动启蒙时代 | 注解驱动过渡时代 | 引入新的骨架式Annotation | 注解驱动黄金时代 | 注解驱动完善时代 | 注解驱动成熟时代 4. Spring 模块结构 Spring 总共大约有 20 个模块， 由 1300 多个不同的文件构成。 而这些组件被分别整合在核心容器（Core Container） 、 AOP（Aspect Oriented Programming）和设备支持（Instrmentation） 、数据访问与集成（Data Access/Integeration） 、 Web、 消息（Messaging） 、 Test等 6 个模块中。 5. Spring 系统架构模块功能介绍Spring 核心模块 模块名称 主要功能 spring-core IoC控制反转与DI依赖注入的最基本实现 spring-beans Bean工厂与Bean的装配 spring-context 定义基础的Spring的Context上下文即IoC容器 spring-context-support 对Spring IoC的扩展支持, 以及IoC子容器 spring-context-indexer Spring的类管理组件和Classpath扫描 spring-expression Spring表达式语言 Spring 面向切面编程模块 模块名称 主要功能 spring-aop 面向切面编程的引用模块, 整合Asm, CGLib、JDKProxy spring-aspects 继承AspectJ, AOP应用框架 spring-instrument 动态Class Loading模块 Spring 数据访问与继承模块 模块名称 主要功能 spring-jdbc Spring 提供的JDBC抽象框架的组要实现模块, 用于简化 Spring JDBC 操作 spring-tx Spring JDBC 事务控制实现模块 spring-orm 主要继承 Hibernate, Java Persitence API (JPA) 和 Java Data Object (JDO) spring-oxm 将Java对象映射成XML数据, 或者将XML数据映射成Java对象 spring-jms Java Messaging Service 能够发送和接收信息 Spring Web 模块 模块名称 主要功能 spring-web 提供了最基础Web支持, 主要建立于核心容器之上, 通过 Servlet 或者 Listeners 来初始化 IoC 容器 spring-webmvc 实现了 Spring-MVC (model-view-controller) 的 Web 应用 spring-websokect 主要是与 Web 前端的全双工通讯的协议 spring-webflux 一个新的非阻塞函数式 Reactive Web 框架, 可以用来建立异步的. 非阻塞, 事件驱动的服务 Spring 通信报文 模块 模块名称 主要功能 spring-messaging 从 Spring4 开始新加入的一个模块, 主要职责是为 Spring 框架继承一些基础的报文传输应用 Spring 集成测试 模块 模块名称 主要功能 spring-test 主要为测试提供支持的 Spring 集成兼容 模块 模块名称 主要功能 spring-framwork-bom Bill of Materials. 解除 Spring 的不同模块依赖版本不同问题 6. Spring 模块之依赖关系图 7. 版本命名规则Spring 版本命名规则 其他常见软件版本命名规则 语义化版本命名通用规则 商业软件中常见的修饰词","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://pdyun.cc/tags/Spring/"}],"author":"Peilin Deng"},{"title":"外网访问家庭网络小记","slug":"外网访问家庭网络小记","date":"2021-08-13T16:16:00.000Z","updated":"2021-08-13T16:44:04.286Z","comments":true,"path":"2021/08/14/外网访问家庭网络小记/","link":"","permalink":"http://pdyun.cc/2021/08/14/%E5%A4%96%E7%BD%91%E8%AE%BF%E9%97%AE%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E5%B0%8F%E8%AE%B0/","excerpt":"记录一次家庭内网使用DDNS让外网访问, 同时动态更新域名123此篇文章献给&#x27;懒人&#x27;同学~ 相信很多同学在自己家里学习啥的搞些小网站小程序, 比如部署一些在线看视频丶个人网盘丶个人博客等的网站, 但是在公司时想访问记录或查询一些资料, 但是又因为访问不了家庭网络而烦躁... 在此分享能使用任意外网访问家庭内网, 同时动态更新域名的方法.当然在此之前我使用过花生壳、公云等一些软件, 他也可以让你从外网访问家庭内网, 但是别的不说, 他限速而且收费呀… 自己搭建可以全速使用家里的带宽步骤如下: 一. 外网访问","text":"记录一次家庭内网使用DDNS让外网访问, 同时动态更新域名123此篇文章献给&#x27;懒人&#x27;同学~ 相信很多同学在自己家里学习啥的搞些小网站小程序, 比如部署一些在线看视频丶个人网盘丶个人博客等的网站, 但是在公司时想访问记录或查询一些资料, 但是又因为访问不了家庭网络而烦躁... 在此分享能使用任意外网访问家庭内网, 同时动态更新域名的方法.当然在此之前我使用过花生壳、公云等一些软件, 他也可以让你从外网访问家庭内网, 但是别的不说, 他限速而且收费呀… 自己搭建可以全速使用家里的带宽步骤如下: 一. 外网访问 1. 申请公网IP 想访问家庭网络必定需要找家里开网络的运营商, 让他们给开公网IP, 我家里使用的是电信宽带, 电话直接打 10000 号人工服务让他们帮忙开通, 理由嘛很简单( 找个借口说家里安装监控就给你开了 ) , 电信现在默认都是给的私网IP. 2. 光猫改为桥接模式 申请完公网IP先别急着挂, 还需要让他们把宽带网络改成桥接模式, 后面我们路由器使用拨号上网 3. 查询宽带账号和密码 由于路由器现在是使用拨号上网, 所以还需要找他运营商拿到宽带的账户和密码, 这些都是必要条件 4. 设备网线连接 我们使用网线连接 光猫的网口 和 路由器WAN口, 主机的网线则联通路由器的LAN口, ( WAN口是连接外部网络, LAN口是连接内部网络, 家里的电脑网线都可以用LAN接口连接, 并且此时我们电脑是没有网络的 ) 12graph LR光猫网口 --&gt; 路由器WAN口 12graph LR路由器LAN口 --&gt; 电脑网口 5. 设置路由器 此时已经具备的条件:公网ip, 宽带改为桥接模式, 宽带账号和密码, 设备网线正确连接 开始设置路由器: 我的路由器设备使用的小米路由器, 暂以小米路由器为例, 路由器网关是 192.168.31.1 , 自己的路由器网关自己搜一下, 然后输入路由器用户名密码 上网设置如图, 上网方式选择PPPOE手动拨号, 然后输入宽带的账号和密码即可 拨号成功应该就可以上网了~~~ 6. 检查IP地址 百度查询自己本机的IP是否与路由器拨号成功获得的IP地址相同.++如果不同, 那一般都是私网ip 没有申请公网ip的.++ 7. 路由转发 一般路由器都拥有路由转发功能, 可以自己配置转发规则. 端口转发: 映射端口, 访问外网 ip:端口, 会直接映射到内网的ip:端口如: **访问外网地址 22.135.173.55:8848, 会被转发到内网 192.168.31.26:8000 ** 8. 测试 我本地电脑随便开启一个服务部署成功, 内网ip:port 192.168.31.26:8401 接着使用外网ip访问, 注意自己映射的端口哦访问成功~~ 二. 设置动态更新域名12由于电信给的公网IP是动态IP, 每次关闭重启光猫都会更换公网IP地址, 所以这也是个很头疼的事情... 个人方案解决了该情况 1. 准备域名 ( 本方案只支持腾讯云域名, 对接腾讯云API ) 我使用的方法, 使用Python写了一个脚本, 动态去更新域名, 需要准备一个腾讯云的域名。提供购买链接 https://buy.cloud.tencent.com/domain?from=console 2. 开通腾讯云 API 密钥 API 密钥代表你的账号身份和所拥有的权限，使用腾讯云 API 可以操作您名下的所有腾讯云资源。给上链接 https://console.cloud.tencent.com/cam/capi 开通完后新建密钥( 单机即可, 自动创建 ): 3. 安装Python3 由于使用的 Python 写的脚本, 需要环境拥有Python, 版本 3 及以上.安装方法参考 https://www.cnblogs.com/weven/p/7252917.html安装完成后查看Python版本: 4. 献上脚本 复制以下代码 保存为 xxx.py 格式就行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197VERSION = 1from hashlib import sha1import jsonimport timeimport base64import hmacclass DDnsHelper(): def __init__(self, mid=0, params=&#123;&#125;): pass def excute(self): import requests SecretId = &#x27;*需要填写*&#x27; SecretKey = &#x27;*需要填写*&#x27; runningPause = 20 domainName = &#x27;pelyhome.cc&#x27; # *需要填写你自己的域名* ddnsDomains = [ &#123; # *需要填写你自己的域名* &#x27;name&#x27;: &#x27;@.pelyhome.cc&#x27;, &#x27;value&#x27;: &#x27;&#x27;, # &#x27;always&#x27;: False, # DNS生存时间 &#x27;ttl&#x27;: 600, # 主机记录, 即域名前缀 &#x27;subDomain&#x27;: &#x27;@&#x27;, &#x27;recordId&#x27;: &#x27;&#x27;, # 记录类型 &#x27;recordType&#x27;: &#x27;A&#x27;, # 线路类型, 指定细分解析线路 &#x27;recordLine&#x27;: &#x27;默认&#x27;, &#x27;description&#x27;: &#x27;本地提供api服务的地址&#x27;, # 查看本地域名的接口, 这是自己写的接口, 仅仅返回一个纯粹的本地外网IP地址 &#x27;localDomain&#x27;: &#x27;https://www.hosix.cn/ip&#x27;, &#x27;localValue&#x27;: &#x27;&#x27; &#125; ] class tenXunDDNS_Helper(): def __init__(self): self.running = True self.action = &quot;&quot; self.secretId = SecretId self.nonce = 38651 self.region = &#x27;ap-guangzhou&#x27; self.secretKey = SecretKey self.version = &#x27;2017-03-12&#x27; self.domain = domainName self.url = &#x27;cns.api.qcloud.com/v2/index.php&#x27; self.httpType = &#x27;https://&#x27; self.endpoint = self.httpType + self.url self.ddnsDomain = ddnsDomains self.runningPause = runningPause self.remoteRecords = [] def getServerIp(self): timeStamp = int(time.time()) params = &#123;&#125; params[&#x27;Action&#x27;] = &#x27;RecordList&#x27; params[&#x27;domain&#x27;] = self.domain params[&#x27;Nonce&#x27;] = self.nonce params[&#x27;SecretId&#x27;] = self.secretId params[&#x27;Timestamp&#x27;] = timeStamp s = self.get_string_to_sign(&quot;GET&quot;, self.url, params) Signature = self.sign_str(self.secretKey, s, sha1) params[&#x27;Signature&#x27;] = Signature response = requests.get(self.endpoint, params=params) result = json.loads(response.text) if int(result[&#x27;code&#x27;]) != 0: raise Exception(&#x27;获取域名失败&#x27; + &#x27;:&#x27; + str(result[&#x27;code&#x27;]) + &#x27;:&#x27; + result[&#x27;message&#x27;]) data = result[&#x27;data&#x27;] self.remoteRecords = data[&#x27;records&#x27;] # print(self.remoteRecords) def postServerIp(self, domain): timeStamp = int(time.time()) params = &#123;&#125; params[&#x27;Action&#x27;] = &#x27;RecordCreate&#x27; params[&#x27;domain&#x27;] = self.domain params[&#x27;Nonce&#x27;] = self.nonce params[&#x27;SecretId&#x27;] = self.secretId params[&#x27;Timestamp&#x27;] = timeStamp params[&#x27;subDomain&#x27;] = domain[&#x27;subDomain&#x27;] params[&#x27;recordType&#x27;] = domain[&#x27;recordType&#x27;] params[&#x27;recordLine&#x27;] = domain[&#x27;recordLine&#x27;] params[&#x27;value&#x27;] = domain[&#x27;value&#x27;] params[&#x27;ttl&#x27;] = domain[&#x27;ttl&#x27;] s = self.get_string_to_sign(&quot;GET&quot;, self.url, params) Signature = self.sign_str(self.secretKey, s, sha1) params[&#x27;Signature&#x27;] = Signature response = requests.get(self.endpoint, params=params) result = json.loads(response.text) if int(result[&#x27;code&#x27;]) != 0: raise Exception(&#x27;添加域名失败&#x27; + &#x27;:&#x27; + str(result[&#x27;code&#x27;]) + &#x27;:&#x27; + result[&#x27;message&#x27;]) data = result[&#x27;data&#x27;] print(&#x27;添加域名成功ip:%s,本地ip:%s,域名:%s&#x27; % (domain[&#x27;value&#x27;], domain[&#x27;localValue&#x27;], domain[&#x27;name&#x27;])) def updateServerIp(self, domain): timeStamp = int(time.time()) params = &#123;&#125; params[&#x27;Action&#x27;] = &#x27;RecordModify&#x27; params[&#x27;domain&#x27;] = self.domain params[&#x27;Nonce&#x27;] = self.nonce params[&#x27;SecretId&#x27;] = self.secretId params[&#x27;Timestamp&#x27;] = timeStamp params[&#x27;subDomain&#x27;] = domain[&#x27;subDomain&#x27;] params[&#x27;recordId&#x27;] = domain[&#x27;recordId&#x27;] params[&#x27;recordType&#x27;] = domain[&#x27;recordType&#x27;] params[&#x27;recordLine&#x27;] = domain[&#x27;recordLine&#x27;] params[&#x27;value&#x27;] = domain[&#x27;localValue&#x27;] params[&#x27;ttl&#x27;] = domain[&#x27;ttl&#x27;] s = self.get_string_to_sign(&quot;GET&quot;, self.url, params) Signature = self.sign_str(self.secretKey, s, sha1) params[&#x27;Signature&#x27;] = Signature response = requests.get(self.endpoint, params=params) result = json.loads(response.text) if int(result[&#x27;code&#x27;]) != 0: raise Exception(&#x27;更新域名失败&#x27; + &#x27;:&#x27; + str(result[&#x27;code&#x27;]) + &#x27;:&#x27; + result[&#x27;message&#x27;]) data = result[&#x27;data&#x27;] print(&#x27;更新域名成功源ip:%s,本地ip:%s,域名:%s&#x27; % (domain[&#x27;value&#x27;], domain[&#x27;localValue&#x27;], domain[&#x27;name&#x27;])) def deleteServerIp(self): pass def getLocalDomain(self, domain): res = requests.get(domain[&#x27;localDomain&#x27;]) ip = res.content.decode(&quot;utf-8&quot;).strip() return ip def clearDnsRecord(self): for domain in self.ddnsDomain: if not domain[&#x27;always&#x27;]: domain[&#x27;value&#x27;] = &#x27;&#x27; domain[&#x27;localValue&#x27;] = &#x27;&#x27; def run(self): self.getServerIp() for domain in self.ddnsDomain: if (not domain[&#x27;always&#x27;]): # 获取本地ip try: domain[&#x27;localValue&#x27;] = self.getLocalDomain(domain) except Exception as e: print(&quot;获取本地ip失败 不更新:%s,本地ip:%s,域名:%s&quot; % ( domain[&#x27;value&#x27;], domain[&#x27;localValue&#x27;], domain[&#x27;name&#x27;])) else: continue flag = False for remoteDomain in self.remoteRecords: if (domain[&#x27;subDomain&#x27;] == remoteDomain[&#x27;name&#x27;]): domain[&#x27;recordId&#x27;] = remoteDomain[&#x27;id&#x27;] domain[&#x27;value&#x27;] = remoteDomain[&#x27;value&#x27;] flag = True break if flag: if (domain[&#x27;value&#x27;] == domain[&#x27;localValue&#x27;]): pass # print(&quot;无需更新ip:%s,本地ip:%s,域名:%s&quot; % (domain[&#x27;value&#x27;],domain[&#x27;localValue&#x27;],domain[&#x27;name&#x27;])) else: self.updateServerIp(domain) continue else: domain[&#x27;value&#x27;] = domain[&#x27;localValue&#x27;] self.postServerIp(domain) self.clearDnsRecord() def start(self): start_time = int(time.time()) while self.running: next_time = int(time.time()) + self.runningPause if (next_time - start_time) &gt; self.runningPause: try: self.run() except Exception as e: print(e.__str__()) start_time = start_time + self.runningPause else: time.sleep(self.runningPause / 10) def get_string_to_sign(self, method, endpoint, params): s = method + endpoint + &quot;?&quot; query_str = &quot;&amp;&quot;.join(&quot;%s=%s&quot; % (k, params[k]) for k in sorted(params)) # print(s + query_str) return s + query_str def sign_str(self, key, s, method): hmac_str = hmac.new(key.encode(&quot;utf8&quot;), s.encode(&quot;utf8&quot;), method).digest() return base64.b64encode(hmac_str) t1 = tenXunDDNS_Helper() t1.start()d = DDnsHelper()d.excute() 最后双击运行~ OK 5. 运行原理和注意事项 原理:该脚本是通过查询公网IP接口:https://www.hosix.cn/ip 来判断公网ip是否发生了改变, 如果发生了改变, 就会调用腾讯云API去动态更新域名. 非常简单….. 注意事项: 1.该脚本需要持续运行, 如果是Linux系统, 直接挂后台运行即可, 该脚本资源消耗不高2.如果提示没requests 运行下, 打开cmd窗口输入: pip install requests3.如运行闪退, 请检查域名等是否正确填写 如有问题请评论或留言: &#53;&#52;&#x34;&#x30;&#49;&#x30;&#x31;&#54;&#53;&#64;&#x71;&#113;&#x2e;&#99;&#x6f;&#x6d;","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"访问家庭内网","slug":"访问家庭内网","permalink":"http://pdyun.cc/tags/%E8%AE%BF%E9%97%AE%E5%AE%B6%E5%BA%AD%E5%86%85%E7%BD%91/"},{"name":"动态DDNS","slug":"动态DDNS","permalink":"http://pdyun.cc/tags/%E5%8A%A8%E6%80%81DDNS/"}],"author":"Peilin Deng"},{"title":"MyBatis 运行时序图","slug":"MyBatis-运行时序图","date":"2021-08-10T11:22:00.000Z","updated":"2021-08-10T12:13:29.943Z","comments":true,"path":"2021/08/10/MyBatis-运行时序图/","link":"","permalink":"http://pdyun.cc/2021/08/10/MyBatis-%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BA%8F%E5%9B%BE/","excerpt":"架构分层","text":"架构分层 1. 创建会话工厂类 2. 创建会话 3. 获取代理对象 4. 调用代理对象方法, 执行SQL","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://pdyun.cc/tags/MyBatis/"}],"author":"Peilin Deng"},{"title":"MyBatis 整合到 Spring 原理","slug":"A","date":"2021-08-07T07:41:00.000Z","updated":"2021-08-10T12:10:57.727Z","comments":true,"path":"2021/08/07/A/","link":"","permalink":"http://pdyun.cc/2021/08/07/A/","excerpt":"1. xml 配置 通过在Spring的 applicationContext.xml文件中做以下配置, 指定MyBatis 的mapper.xml 文件扫描路径, MapperScannerConfigurer 是 Mybatis 用于整合 Spring 的核心对象.","text":"1. xml 配置 通过在Spring的 applicationContext.xml文件中做以下配置, 指定MyBatis 的mapper.xml 文件扫描路径, MapperScannerConfigurer 是 Mybatis 用于整合 Spring 的核心对象. 1234567&lt;!--配置扫描器，将mybatis的接口实现加入到 IOC容器中 --&gt;&lt;!-- &lt;mybatis-spring:scan #base-package=&quot;com.dpl.crud.dao&quot;/&gt;--&gt; &lt;bean id=&quot;mapperScanner&quot; class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.gupaoedu.crud.dao&quot;/&gt; &lt;/bean&gt; 2. MapperScannerConfigurer 对象12345public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware &#123; ...... ......&#125; 该对象实现了几个接口: BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware 1). BeanDefinitionRegistryPostProcessor: 如下, 重写了 ++postProcessBeanDefinitionRegistry++(…) 方法, 在该方法中进行扫描对应的 Mapper 文件 12345678910111213141516171819202122232425@Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123; if (this.processPropertyPlaceHolders) &#123; processPropertyPlaceHolders(); &#125; ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass); if (StringUtils.hasText(lazyInitialization)) &#123; scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization)); &#125; scanner.registerFilters(); // *重点在这里 scanner.scan( StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS)); &#125; 重点在 scanner.scan(…)方法 123456789101112public int scan(String... basePackages) &#123; int beanCountAtScanStart = this.registry.getBeanDefinitionCount(); // 继续进入该方法 this.doScan(basePackages); if (this.includeAnnotationConfig) &#123; AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); &#125; return this.registry.getBeanDefinitionCount() - beanCountAtScanStart; &#125; 该方法有两个实现, 首先进入 ClassPathMapperScanner 实现 12345678910111213@Override public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; // *这里调了父类 ClassPathBeanDefinitionScanner 的doScan 方法, 进入该方法实现 Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) &#123; LOGGER.warn(() -&gt; &quot;No MyBatis mapper was found in &#x27;&quot; + Arrays.toString(basePackages) + &quot;&#x27; package. Please check your configuration.&quot;); &#125; else &#123; processBeanDefinitions(beanDefinitions); &#125; return beanDefinitions; &#125; 这里调了父类 ClassPathBeanDefinitionScanner 的 doScan() 方法, 进入该方法实现 123456789101112131415161718192021222324252627282930313233343536373839404142protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Assert.notEmpty(basePackages, &quot;At least one base package must be specified&quot;); // *创建 BeanDefinitionHolder 集合, 里面封装的是 BeanDefinition 和 beanName Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet(); String[] var3 = basePackages; int var4 = basePackages.length; for(int var5 = 0; var5 &lt; var4; ++var5) &#123; String basePackage = var3[var5]; Set&lt;BeanDefinition&gt; candidates = this.findCandidateComponents(basePackage); Iterator var8 = candidates.iterator(); while(var8.hasNext()) &#123; BeanDefinition candidate = (BeanDefinition)var8.next(); ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate); candidate.setScope(scopeMetadata.getScopeName()); String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry); if (candidate instanceof AbstractBeanDefinition) &#123; this.postProcessBeanDefinition((AbstractBeanDefinition)candidate, beanName); &#125; if (candidate instanceof AnnotatedBeanDefinition) &#123; AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition)candidate); &#125; // 检查每个 BeanDefinition 是否在容器中存在, 不存在则返回true if (this.checkCandidate(beanName, candidate)) &#123; // 创建 BeanDefinitionHolder 对象封装 BeanDefinition BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); beanDefinitions.add(definitionHolder); // *将创建好的对象注册到 BeanDefinitionRegistry 容器中交由Spring管理 this.registerBeanDefinition(definitionHolder, this.registry); &#125; &#125; &#125; return beanDefinitions; &#125; 上面将mapper对象封装好了注册到 BeanDefinitionRegistry 容器中交由Spring管理, 接着返回 BeanDefinitionHolder 集合继续处理 123456789101112131415@Override public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) &#123; LOGGER.warn(() -&gt; &quot;No MyBatis mapper was found in &#x27;&quot; + Arrays.toString(basePackages) + &quot;&#x27; package. Please check your configuration.&quot;); &#125; else &#123; // *接下来处理BeanDefinition processBeanDefinitions(beanDefinitions); &#125; return beanDefinitions; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123; GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) &#123; definition = (GenericBeanDefinition) holder.getBeanDefinition(); String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -&gt; &quot;Creating MapperFactoryBean with name &#x27;&quot; + holder.getBeanName() + &quot;&#x27; and &#x27;&quot; + beanClassName + &quot;&#x27; mapperInterface&quot;); definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // issue #59 // mapper接口是Bean的原始类，但是Bean的实际类被替换成了 MapperFactoryBean // 这里的 this.mapperFactoryBeanClass 是 MapperFactoryBean.class 对象 // private Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = MapperFactoryBean.class; definition.setBeanClass(this.mapperFactoryBeanClass); definition.getPropertyValues().add(&quot;addToConfig&quot;, this.addToConfig); boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) &#123; definition.getPropertyValues().add(&quot;sqlSessionFactory&quot;, new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionFactory != null) &#123; definition.getPropertyValues().add(&quot;sqlSessionFactory&quot;, this.sqlSessionFactory); explicitFactoryUsed = true; &#125; if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn( () -&gt; &quot;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.&quot;); &#125; definition.getPropertyValues().add(&quot;sqlSessionTemplate&quot;, new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; &#125; else if (this.sqlSessionTemplate != null) &#123; if (explicitFactoryUsed) &#123; LOGGER.warn( () -&gt; &quot;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.&quot;); &#125; definition.getPropertyValues().add(&quot;sqlSessionTemplate&quot;, this.sqlSessionTemplate); explicitFactoryUsed = true; &#125; if (!explicitFactoryUsed) &#123; LOGGER.debug(() -&gt; &quot;Enabling autowire by type for MapperFactoryBean with name &#x27;&quot; + holder.getBeanName() + &quot;&#x27;.&quot;); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); &#125; definition.setLazyInit(lazyInitialization); &#125; &#125; 这里 mapper接口是Bean的原始类，但是Bean的实际类被替换成了 MapperFactoryBean, MapperFactoryBean 对象又是什么东西? 3. MapperFactoryBean 对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// *要点一: 该类继承了 SqlSessionDaoSupport, SqlSessionDaoSupport 对象里面可以获取 SqlSessionTemplate 对象// SqlSessionTemplate 对象是 DefaultSqlSession 的替代品, 实现同一事务的情况下保证线程安全的, 每次请求的时候都会创建一个新的 SqlSessionpublic class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; &#123; private Class&lt;T&gt; mapperInterface; private boolean addToConfig = true; public MapperFactoryBean() &#123; // intentionally empty &#125; public MapperFactoryBean(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; @Override protected void checkDaoConfig() &#123; super.checkDaoConfig(); notNull(this.mapperInterface, &quot;Property &#x27;mapperInterface&#x27; is required&quot;); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123; try &#123; configuration.addMapper(this.mapperInterface); &#125; catch (Exception e) &#123; logger.error(&quot;Error while adding the mapper &#x27;&quot; + this.mapperInterface + &quot;&#x27; to configuration.&quot;, e); throw new IllegalArgumentException(e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; &#125; // *要点二: 该类实现了 FactoryBean&lt;T&gt; 接口, 重写 getObject() 方法, // 从 SqlSessionTemplate 对象中获取 Mapper 接口的代理对象 // 后面的逻辑与之前未整合 Spring 的逻辑一致了..... @Override public T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface); &#125; @Override public Class&lt;T&gt; getObjectType() &#123; return this.mapperInterface; &#125; @Override public boolean isSingleton() &#123; return true; &#125; public void setMapperInterface(Class&lt;T&gt; mapperInterface) &#123; this.mapperInterface = mapperInterface; &#125; public Class&lt;T&gt; getMapperInterface() &#123; return mapperInterface; &#125; public void setAddToConfig(boolean addToConfig) &#123; this.addToConfig = addToConfig; &#125; public boolean isAddToConfig() &#123; return addToConfig; &#125;&#125; 允许注入MyBatis映射器接口的BeanFactory。 可以使用SqlSessionFactory或预配置的SqlSessionTemplate进行设置。*要点一: 该类继承了 SqlSessionDaoSupport, SqlSessionDaoSupport 对象里面可以获取 SqlSessionTemplate 对象 SqlSessionTemplate 对象是 DefaultSqlSession 的替代品, 实现同一事务的情况下还保证线程安全的, 每次请求的时候都会创建一个新的 DefualtSqlSession *要点二: 该类实现了 FactoryBean 接口, 重写 getObject() 方法, 从 SqlSessionTemplate 对象中获取 Mapper 接口的代理对象 后面的逻辑与之前未整合 Spring 的逻辑一致了….. 4. SqlSessionTemplate 对象为什么说 SqlSessionTemplate 在实现同一事务的情况下还保证线程安全的?12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class SqlSessionTemplate implements SqlSession, DisposableBean &#123; private final SqlSessionFactory sqlSessionFactory; private final ExecutorType executorType; private final SqlSession sqlSessionProxy; private final PersistenceExceptionTranslator exceptionTranslator; ...... public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sqlSessionFactory, &quot;Property &#x27;sqlSessionFactory&#x27; is required&quot;); notNull(executorType, &quot;Property &#x27;executorType&#x27; is required&quot;); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; // 1. 在初始化的时候通过这里创建 SqlSessionFactory 代理类, // 该代理类实现SqlSession接口，定义了方法拦截器，如果调用代理类实例中实现SqlSession接口定义的方法， // 该调用则被导向 SqlSessionInterceptor 的invoke方法 this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor() ); &#125; ...... private class SqlSessionInterceptor implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 2. 为什么说 SqlSessionTemplate 在实现同一事务的情况下还保证线程安全的? // 此处则是关键, 进入该方法 getSqlSession(...) SqlSession sqlSession = getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try &#123; // 调用从Spring的事物上下文获取事物范围内的sqlSession对象 Object result = method.invoke(sqlSession, args); //然后判断一下当前的sqlSession是否被Spring托管 如果未被Spring托管则自动commit if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) &#123; // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() sqlSession.commit(true); &#125; return result; &#125; catch (Throwable t) &#123; Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) &#123; // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator .translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) &#123; unwrapped = translated; &#125; &#125; throw unwrapped; &#125; finally &#123; if (sqlSession != null) &#123; closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); &#125; &#125; &#125; &#125;&#125; 在初始化的时候在构造方法中创建 SqlSessionFactory 代理类, 该代理类实现SqlSession接口，定义了方法拦截器，如果调用代理类实例中实现SqlSession接口定义的方法，该调用则被导向 SqlSessionInterceptor 的invoke方法 (代理对象的 InvocationHandler 就是 SqlSessionInterceptor，如果把它命名为SqlSessionInvocationHandler则更好理解！） 为什么说 SqlSessionTemplate 在实现同一事务的情况下还保证线程安全的? 此处则是关键, 进入该方法 SqlSession sqlSession = getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); 123456789101112131415161718192021222324252627public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sessionFactory, NO_SQL_SESSION_FACTORY_SPECIFIED); notNull(executorType, NO_EXECUTOR_TYPE_SPECIFIED); // 进入 TransactionSynchronizationManager.getResource(...) 方法 // 根据sqlSessionFactory从当前线程对应的资源map中获取SqlSessionHolder， // 当sqlSessionFactory创建了sqlSession， // 就会在事务管理器中添加一对映射：key为sqlSessionFactory，value为SqlSessionHolder，该类保存sqlSession及执行方式 SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); //从SqlSessionHolder中提取SqlSession对象 SqlSession session = sessionHolder(executorType, holder); if (session != null) &#123; return session; &#125; LOGGER.debug(() -&gt; &quot;Creating a new SqlSession&quot;); // 如果当前事物管理器中获取不到SqlSessionHolder对象就重新创建一个 session = sessionFactory.openSession(executorType); registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session; &#125; 进入 TransactionSynchronizationManager.getResource(…) 方法 SqlSessionHolder holder = (SqlSessionHolder) TransactionSynchronizationManager.getResource(sessionFactory); 123456789101112@Nullable public static Object getResource(Object key) &#123; Object actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key); // 这里 value 为返回结果, 可以进去看这个 value 是什么对象, 进入 doGetResource() 方法 Object value = doGetResource(actualKey); if (value != null &amp;&amp; logger.isTraceEnabled()) &#123; logger.trace(&quot;Retrieved value [&quot; + value + &quot;] for key [&quot; + actualKey + &quot;] bound to thread [&quot; + Thread.currentThread().getName() + &quot;]&quot;); &#125; return value; &#125; 这里 value 为返回结果, 可以进去看这个 value 是什么对象, 进入 doGetResource() 方法 Object value = doGetResource(actualKey); 1234567891011121314151617181920@Nullable private static Object doGetResource(Object actualKey) &#123; // 最后从 resources 这个集合中获取的对象, 然而这个 resources 就是一个 ThreadLocal 对象, 保证了线程安全 Map&lt;Object, Object&gt; map = (Map)resources.get(); if (map == null) &#123; return null; &#125; else &#123; Object value = map.get(actualKey); if (value instanceof ResourceHolder &amp;&amp; ((ResourceHolder)value).isVoid()) &#123; map.remove(actualKey); if (map.isEmpty()) &#123; resources.remove(); &#125; value = null; &#125; return value; &#125; &#125; 最后从 resources 这个集合中获取的对象, 然而这个 resources 就是一个 ThreadLocal 对象, 保证了线程安全 Map&lt;Object, Object&gt; map = (Map)resources.get(); 1234567public abstract class TransactionSynchronizationManager &#123; ...... private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal(&quot;Transactional resources&quot;); ......&#125; 5. Mybatis 不是有 SqlSessionManager 了吗？为什么又提供了 SqlSessionTemplate？ SqlSessionManager: SqlSessionManager 是由开发者自身决定如何使用 SqlSession 的, 是适合在不整合 Spring 框架的时候使用。 SqlSessionTemplate: SqlSessionTemplate 是 MyBatis 专门为 Spring 提供的，支持 Spring 框架的一个 SqlSession 获取接口。主要是为了继承 Spring，并同时将是否共用 SqlSession 的权限交给 Spring 去管理。","categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://pdyun.cc/tags/MyBatis/"}],"author":"Peilin Deng"},{"title":"Hello World","slug":"newpapername","date":"2021-08-06T05:06:24.000Z","updated":"2021-08-10T11:21:31.361Z","comments":true,"path":"2021/08/06/newpapername/","link":"","permalink":"http://pdyun.cc/2021/08/06/newpapername/","excerpt":"","text":"念两句诗 挑选中... jinrishici.load(function(result) { poem.innerHTML = result.data.content info.innerHTML = '【' + result.data.origin.dynasty + '】' + result.data.origin.author + '《' + result.data.origin.title + '》' document.getElementById(\"poem\").value(poem); document.getElementById(\"info\").value(info); });","categories":[],"tags":[]}],"categories":[{"name":"摘抄笔记","slug":"摘抄笔记","permalink":"http://pdyun.cc/categories/%E6%91%98%E6%8A%84%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://pdyun.cc/tags/MySql/"},{"name":"Spring","slug":"Spring","permalink":"http://pdyun.cc/tags/Spring/"},{"name":"访问家庭内网","slug":"访问家庭内网","permalink":"http://pdyun.cc/tags/%E8%AE%BF%E9%97%AE%E5%AE%B6%E5%BA%AD%E5%86%85%E7%BD%91/"},{"name":"动态DDNS","slug":"动态DDNS","permalink":"http://pdyun.cc/tags/%E5%8A%A8%E6%80%81DDNS/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://pdyun.cc/tags/MyBatis/"}]}